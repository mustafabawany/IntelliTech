{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsmnJMDu5TmT"
      },
      "source": [
        "# **Installing Packages**\n",
        "\n",
        "Note: Use Neptune Packages to Log Results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKIwkKP45Snj",
        "outputId": "bcff135a-57cd-40a8-a18b-0160fa587d98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.29.2-py3-none-any.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.29.2\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers\n",
        "# !pip install neptune\n",
        "# !pip install neptune-contrib"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: Restart Runtime After Successfull Installation"
      ],
      "metadata": {
        "id": "i18n8UFYCfq2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKAm8_BBJBif"
      },
      "source": [
        "# **Importing Packages**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJhhDUJNIl-t",
        "outputId": "49c05dd1-019c-4247-dce8-350a758d7c68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import warnings\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import multiprocessing\n",
        "import collections\n",
        "import nltk\n",
        "import re\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "from nltk.corpus import stopwords\n",
        "import transformers as ppb\n",
        "from gensim.models import Word2Vec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.manifold import TSNE\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Embedding, Input, LSTM, Dense, Dropout, Lambda, Flatten, Bidirectional, Conv2D, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
        "from keras.models import Sequential,Model, load_model, model_from_config\n",
        "import keras.backend as K\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib notebook\n",
        "\n",
        "# import neptune\n",
        "# from neptunecontrib.monitoring.keras import NeptuneMonitor\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neptune AI**"
      ],
      "metadata": {
        "id": "9OftPjcQrS2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run = neptune.init_run(\n",
        "    project=\"YOUR PROJECT NAME\",\n",
        "    api_token=\"YOUR API TOKEN\"\n",
        ")  "
      ],
      "metadata": {
        "id": "rdfrKy6prV8R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Visualisations**"
      ],
      "metadata": {
        "id": "ke7J9hxW-S8m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "v0M_OpuPJKN2"
      },
      "outputs": [],
      "source": [
        "def plot_accuracy_curve(history):\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['mae'])\n",
        "  plt.title('Model loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Train', 'Test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "def plot_acrchitecture(filename, model):\n",
        "  from keras.utils import plot_model\n",
        "  plot_model(model, to_file=str(filename) + '.png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mounting Google Drive**"
      ],
      "metadata": {
        "id": "6p2yQyF5AQMi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kh0vjFcNKAS7",
        "outputId": "18a0917b-6b5c-44d2-c9b9-e48285b5b94d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FH6NXR25JPtu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "1d23560b-f226-4e35-e5cb-7c7d532f56ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0         1          1  Dear local newspaper, I think effects computer...   \n",
              "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
              "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
              "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
              "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
              "\n",
              "   rater1_domain1  rater2_domain1  rater3_domain1  domain1_score  \\\n",
              "0               4               4             NaN              8   \n",
              "1               5               4             NaN              9   \n",
              "2               4               3             NaN              7   \n",
              "3               5               5             NaN             10   \n",
              "4               4               4             NaN              8   \n",
              "\n",
              "   rater1_domain2  rater2_domain2  domain2_score  ...  rater2_trait3  \\\n",
              "0             NaN             NaN            NaN  ...            NaN   \n",
              "1             NaN             NaN            NaN  ...            NaN   \n",
              "2             NaN             NaN            NaN  ...            NaN   \n",
              "3             NaN             NaN            NaN  ...            NaN   \n",
              "4             NaN             NaN            NaN  ...            NaN   \n",
              "\n",
              "   rater2_trait4  rater2_trait5  rater2_trait6  rater3_trait1  rater3_trait2  \\\n",
              "0            NaN            NaN            NaN            NaN            NaN   \n",
              "1            NaN            NaN            NaN            NaN            NaN   \n",
              "2            NaN            NaN            NaN            NaN            NaN   \n",
              "3            NaN            NaN            NaN            NaN            NaN   \n",
              "4            NaN            NaN            NaN            NaN            NaN   \n",
              "\n",
              "   rater3_trait3  rater3_trait4  rater3_trait5  rater3_trait6  \n",
              "0            NaN            NaN            NaN            NaN  \n",
              "1            NaN            NaN            NaN            NaN  \n",
              "2            NaN            NaN            NaN            NaN  \n",
              "3            NaN            NaN            NaN            NaN  \n",
              "4            NaN            NaN            NaN            NaN  \n",
              "\n",
              "[5 rows x 28 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2deeff80-4c73-4401-a657-07a02b8f26d8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>rater1_domain1</th>\n",
              "      <th>rater2_domain1</th>\n",
              "      <th>rater3_domain1</th>\n",
              "      <th>domain1_score</th>\n",
              "      <th>rater1_domain2</th>\n",
              "      <th>rater2_domain2</th>\n",
              "      <th>domain2_score</th>\n",
              "      <th>...</th>\n",
              "      <th>rater2_trait3</th>\n",
              "      <th>rater2_trait4</th>\n",
              "      <th>rater2_trait5</th>\n",
              "      <th>rater2_trait6</th>\n",
              "      <th>rater3_trait1</th>\n",
              "      <th>rater3_trait2</th>\n",
              "      <th>rater3_trait3</th>\n",
              "      <th>rater3_trait4</th>\n",
              "      <th>rater3_trait5</th>\n",
              "      <th>rater3_trait6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>8</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 28 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2deeff80-4c73-4401-a657-07a02b8f26d8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2deeff80-4c73-4401-a657-07a02b8f26d8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2deeff80-4c73-4401-a657-07a02b8f26d8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/IntelliTech-DataSet/training_set_rel3.tsv\"\n",
        "data = pd.read_csv(dataset_path, sep=\"\\t\", encoding=\"ISO-8859-1\")\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Preprocessing**"
      ],
      "metadata": {
        "id": "r_z2NvM7-cKe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5Psxv7jbJTh1"
      },
      "outputs": [],
      "source": [
        "cap = ['@CAPS'+str(i) for i in range(100)]\n",
        "loc = ['@LOCATION'+str(i) for i in range(100)]\n",
        "org =['@ORGANIZATION'+str(i) for i in range(100)]\n",
        "per = ['@PERSON'+str(i) for i in range(100)]\n",
        "date = ['@DATE'+str(i) for i in range(100)]\n",
        "time = ['@TIME'+str(i) for i in range(100)]\n",
        "money = ['@MONEY'+str(i) for i in range(100)]\n",
        "ner =  cap + loc + org + per + date + time + money"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HsXxoMDIJXG1"
      },
      "outputs": [],
      "source": [
        "top10 = collections.defaultdict(int)\n",
        "def essay_to_wordlist(Essay):\n",
        "    \"\"\"\n",
        "      Removes Named Entity Recognition (NER), Special Characters, and Stop Words.\n",
        "      Also word tokenizes the essay.\n",
        "\n",
        "      Args:\n",
        "        Essay: Essay of each student \n",
        "      \n",
        "      Returns: \n",
        "        Set<String>\n",
        "\n",
        "    \"\"\"\n",
        "    Essay = re.sub(\"[^a-zA-Z]\", \" \", Essay)\n",
        "    words = Essay.lower().split()\n",
        "    \n",
        "    stops = stopwords.words(\"english\")\n",
        "    stops.extend(ner)\n",
        "    for word in words:\n",
        "      if word not in stops:\n",
        "        top10[word]+=1\n",
        "    words = [w for w in words if not w in stops]\n",
        "    return (words)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Feature Vector Creation**"
      ],
      "metadata": {
        "id": "KkpCGIrF-sR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeFeatureVec(words, model, num_features):\n",
        "    \"\"\"\n",
        "      Make Feature Vector from the words list of an Essay.\n",
        "\n",
        "      Args:\n",
        "        words: Words of each essay\n",
        "        model: Trained word2vec model\n",
        "        params['num_features']: Number of features to be extracted \n",
        "      \n",
        "      Returns: \n",
        "        numpy.array\n",
        "\n",
        "    \"\"\"\n",
        "    featureVec = np.zeros((num_features,), dtype=\"float32\")\n",
        "    num_words = 0.\n",
        "    index2word_set = set(model.wv.index_to_key)\n",
        "    for word in words:\n",
        "        if word in index2word_set:\n",
        "            num_words += 1\n",
        "            if word in model.wv:\n",
        "                featureVec = np.add(featureVec, model.wv[word])\n",
        "    if num_words > 0:\n",
        "        featureVec = np.divide(featureVec, num_words)\n",
        "    return featureVec\n",
        "\n",
        "def getAvgFeatureVecs(essays, model, num_features):\n",
        "    \"\"\"\n",
        "      Main function to generate the word vectors for word2vec model.\n",
        "\n",
        "      Args:\n",
        "        essays: Essay of each student\n",
        "        model: Trained word2vec model\n",
        "        params['num_features']: Number of features to be extracted \n",
        "      \n",
        "      Returns: \n",
        "        numpy.array\n",
        "\n",
        "    \"\"\"\n",
        "    counter = 0\n",
        "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
        "    for essay in essays:\n",
        "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
        "        counter = counter + 1\n",
        "    return essayFeatureVecs"
      ],
      "metadata": {
        "id": "pDLYRxjR-lwY"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bi-LSTM and LSTM Model Architecture**"
      ],
      "metadata": {
        "id": "jQ9L_pT3-o3-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9bLjXyD1JaMF"
      },
      "outputs": [],
      "source": [
        "def get_model(Hidden_dimension1=400, Hidden_dimension2=128, return_sequences = True, dropout=0.5, recurrent_dropout=0.4, input_size=768, activation='relu', bidirectional = False):\n",
        "    \"\"\"\n",
        "      Defines the architecture for LSTM and Bi-LSTM Model\n",
        "\n",
        "      Args:\n",
        "        Hidden_dim1: \n",
        "        Hidden_dim2: \n",
        "        return_sequences:\n",
        "        dropout: \n",
        "        recurrent_dropout: \n",
        "        input_size:\n",
        "        activation: \n",
        "        bidirectional:\n",
        "      \n",
        "      Returns: \n",
        "        keras.model\n",
        "\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "    if bidirectional:\n",
        "        model.add(Bidirectional(LSTM(Hidden_dimension1,return_sequences=return_sequences , dropout=0.4, recurrent_dropout=recurrent_dropout), input_shape=[1, input_size]))\n",
        "        model.add(Bidirectional(LSTM(Hidden_dimension1, recurrent_dropout=recurrent_dropout)))\n",
        "    else:\n",
        "        model.add(LSTM(Hidden_dimension1, dropout=0.4, recurrent_dropout=recurrent_dropout, input_shape=[1, input_size], return_sequences=return_sequences))\n",
        "        model.add(LSTM(Hidden_dimension2, recurrent_dropout=recurrent_dropout))\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Dense(1, activation=activation))\n",
        "\n",
        "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae'])\n",
        "    model.summary()\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word2Vec Model Architecture**"
      ],
      "metadata": {
        "id": "Q92LtGne-y7N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mnv9HkSGNBu7"
      },
      "outputs": [],
      "source": [
        "def build_word2vec(train_sentences, num_workers, num_features, min_word_count, context,epochs):\n",
        "    \"\"\"\n",
        "      Defines the architecture for Word2vec Model\n",
        "\n",
        "      Args:\n",
        "        train_sentences: \n",
        "        num_workers: \n",
        "        params['num_features']:\n",
        "        min_word_count: \n",
        "        context: \n",
        "      \n",
        "      Returns: \n",
        "        word2vec model\n",
        "        collections.dictionary\n",
        "\n",
        "    \"\"\"\n",
        "    model = Word2Vec(workers=num_workers, vector_size=num_features, min_count=min_word_count, window=context)\n",
        "    cores = multiprocessing.cpu_count()\n",
        "    model.build_vocab(train_sentences, progress_per=10000)\n",
        "    model.train(train_sentences, total_examples=model.corpus_count, epochs=epochs, report_delay=1)\n",
        "    model.init_sims(replace=True)\n",
        "    sorted_dic = sorted(top10.items(), key=lambda k: k[1], reverse=True)\n",
        "    return model,sorted_dic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = data\n",
        "y = data['domain1_score']"
      ],
      "metadata": {
        "id": "U_fTarTZ_n-j"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparameters for word2vec\n"
      ],
      "metadata": {
        "id": "sS15Et6L_tqD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_word2vec= {  \n",
        "                    \"num_features\": 400,\n",
        "                    \"min_word_count\": 40,\n",
        "                    \"num_workers\": 4,\n",
        "                    \"context\": 10,\n",
        "                    \"epochs\":30\n",
        "                  }"
      ],
      "metadata": {
        "id": "kKn7vET0_smV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperpaprameters for LSTM"
      ],
      "metadata": {
        "id": "5Nnjis0N_xVL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_lstm = { \n",
        "                \"Hidden_dim1\":300,\n",
        "                \"Hidden_dim2\": 100,\n",
        "                \"return_sequences\": True,\n",
        "                \"dropout\":0.5,\n",
        "                \"recurrent_dropout\":0.4,\n",
        "                \"input_size\":400,\n",
        "                \"activation\":'relu',\n",
        "                \"bidirectional\":  True,\n",
        "                \"batch_size\" : 64,\n",
        "                \"epoch\": 70 \n",
        "              }"
      ],
      "metadata": {
        "id": "YZtw53RL_wiD"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Neptune Logger**"
      ],
      "metadata": {
        "id": "zwpbNKDdw0jB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "run[\"parameters_lstm\"] = params_lstm\n",
        "run[\"parameters_word2vec\"] = params_word2vec\n",
        "neptune_callback = NeptuneMonitor()  \n",
        "\n",
        "class NeptuneLogger(keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        for log_name, log_value in logs.items():\n",
        "            run['logs/{}'.format(log_name)].log(log_value)"
      ],
      "metadata": {
        "id": "n-hLjI77xOAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jagYU1h2I-kf"
      },
      "source": [
        "# **Model Training**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8whCaYQbI9dH",
        "outputId": "3d71a648-cdbd-460b-d5f6-ecb770470752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(12976, 28)\n",
            "(12976,)\n",
            "\n",
            "--------Fold 1--------\n",
            "\n",
            "Converting sentences to word2vec model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional (Bidirectiona  (None, 1, 600)           1682400   \n",
            " l)                                                              \n",
            "                                                                 \n",
            " bidirectional_1 (Bidirectio  (None, 600)              2162400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 600)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,845,401\n",
            "Trainable params: 3,845,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "102/102 [==============================] - 16s 75ms/step - loss: 49.9114 - mae: 3.9376\n",
            "Epoch 2/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 22.3207 - mae: 3.0944\n",
            "Epoch 3/70\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 18.4592 - mae: 2.9442\n",
            "Epoch 4/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 17.7764 - mae: 2.9274\n",
            "Epoch 5/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 17.1116 - mae: 2.8347\n",
            "Epoch 6/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 16.1905 - mae: 2.7447\n",
            "Epoch 7/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 16.1068 - mae: 2.7214\n",
            "Epoch 8/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 15.3505 - mae: 2.6195\n",
            "Epoch 9/70\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 15.2176 - mae: 2.5397\n",
            "Epoch 10/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 15.0541 - mae: 2.4999\n",
            "Epoch 11/70\n",
            "102/102 [==============================] - 9s 86ms/step - loss: 14.6885 - mae: 2.4261\n",
            "Epoch 12/70\n",
            "102/102 [==============================] - 9s 83ms/step - loss: 13.9506 - mae: 2.3004\n",
            "Epoch 13/70\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 13.4274 - mae: 2.1903\n",
            "Epoch 14/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 13.0679 - mae: 2.1264\n",
            "Epoch 15/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 12.4237 - mae: 2.0656\n",
            "Epoch 16/70\n",
            "102/102 [==============================] - 8s 82ms/step - loss: 11.6387 - mae: 2.0112\n",
            "Epoch 17/70\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 11.7991 - mae: 1.9962\n",
            "Epoch 18/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 11.4620 - mae: 1.9809\n",
            "Epoch 19/70\n",
            "102/102 [==============================] - 7s 68ms/step - loss: 10.6264 - mae: 1.9187\n",
            "Epoch 20/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 10.6575 - mae: 1.8930\n",
            "Epoch 21/70\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 10.0560 - mae: 1.8404\n",
            "Epoch 22/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 10.2037 - mae: 1.8293\n",
            "Epoch 23/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 10.0282 - mae: 1.8275\n",
            "Epoch 24/70\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 9.2564 - mae: 1.7330\n",
            "Epoch 25/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 9.1734 - mae: 1.7357\n",
            "Epoch 26/70\n",
            "102/102 [==============================] - 8s 77ms/step - loss: 8.9248 - mae: 1.7003\n",
            "Epoch 27/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 8.8580 - mae: 1.6826\n",
            "Epoch 28/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 8.5848 - mae: 1.6482\n",
            "Epoch 29/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 8.4035 - mae: 1.6307\n",
            "Epoch 30/70\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 8.4856 - mae: 1.6383\n",
            "Epoch 31/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 7.6622 - mae: 1.5837\n",
            "Epoch 32/70\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 7.4760 - mae: 1.5580\n",
            "Epoch 33/70\n",
            "102/102 [==============================] - 8s 73ms/step - loss: 7.3312 - mae: 1.5375\n",
            "Epoch 34/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 7.3823 - mae: 1.5364\n",
            "Epoch 35/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 7.1261 - mae: 1.5080\n",
            "Epoch 36/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 7.2043 - mae: 1.5269\n",
            "Epoch 37/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 6.9839 - mae: 1.4883\n",
            "Epoch 38/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 6.9664 - mae: 1.5049\n",
            "Epoch 39/70\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 7.1460 - mae: 1.4942\n",
            "Epoch 40/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 6.7090 - mae: 1.4629\n",
            "Epoch 41/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 6.3817 - mae: 1.4349\n",
            "Epoch 42/70\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 6.1306 - mae: 1.4373\n",
            "Epoch 43/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 5.9605 - mae: 1.4147\n",
            "Epoch 44/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 6.1969 - mae: 1.4267\n",
            "Epoch 45/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 6.0957 - mae: 1.4117\n",
            "Epoch 46/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 6.1898 - mae: 1.4156\n",
            "Epoch 47/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 5.9234 - mae: 1.3944\n",
            "Epoch 48/70\n",
            "102/102 [==============================] - 7s 68ms/step - loss: 5.9758 - mae: 1.3972\n",
            "Epoch 49/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 5.9143 - mae: 1.3952\n",
            "Epoch 50/70\n",
            "102/102 [==============================] - 10s 95ms/step - loss: 5.8996 - mae: 1.3678\n",
            "Epoch 51/70\n",
            "102/102 [==============================] - 8s 76ms/step - loss: 5.7974 - mae: 1.3708\n",
            "Epoch 52/70\n",
            "102/102 [==============================] - 9s 86ms/step - loss: 5.6990 - mae: 1.3728\n",
            "Epoch 53/70\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 5.3803 - mae: 1.3495\n",
            "Epoch 54/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 5.2886 - mae: 1.3315\n",
            "Epoch 55/70\n",
            "102/102 [==============================] - 7s 69ms/step - loss: 5.2622 - mae: 1.3288\n",
            "Epoch 56/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 5.4169 - mae: 1.3520\n",
            "Epoch 57/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 5.2849 - mae: 1.3446\n",
            "Epoch 58/70\n",
            "102/102 [==============================] - 8s 80ms/step - loss: 5.0504 - mae: 1.3034\n",
            "Epoch 59/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 5.2520 - mae: 1.3226\n",
            "Epoch 60/70\n",
            "102/102 [==============================] - 7s 72ms/step - loss: 5.2161 - mae: 1.3360\n",
            "Epoch 61/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 5.0195 - mae: 1.3035\n",
            "Epoch 62/70\n",
            "102/102 [==============================] - 7s 71ms/step - loss: 4.8514 - mae: 1.2988\n",
            "Epoch 63/70\n",
            "102/102 [==============================] - 9s 86ms/step - loss: 5.1173 - mae: 1.3140\n",
            "Epoch 64/70\n",
            "102/102 [==============================] - 7s 72ms/step - loss: 4.9522 - mae: 1.2981\n",
            "Epoch 65/70\n",
            "102/102 [==============================] - 9s 86ms/step - loss: 4.8474 - mae: 1.2907\n",
            "Epoch 66/70\n",
            "102/102 [==============================] - 8s 82ms/step - loss: 4.8551 - mae: 1.2904\n",
            "Epoch 67/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 4.8967 - mae: 1.2818\n",
            "Epoch 68/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 4.7345 - mae: 1.2642\n",
            "Epoch 69/70\n",
            "102/102 [==============================] - 7s 70ms/step - loss: 4.7851 - mae: 1.2738\n",
            "Epoch 70/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 4.5715 - mae: 1.2584\n",
            "203/203 [==============================] - 3s 12ms/step\n",
            "Kappa Score: 0.9632798715120408\n",
            "\n",
            "--------Fold 2--------\n",
            "\n",
            "Converting sentences to word2vec model\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.keyedvectors:destructive init_sims(replace=True) deprecated & no longer required for space-efficiency\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " bidirectional_2 (Bidirectio  (None, 1, 600)           1682400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_3 (Bidirectio  (None, 600)              2162400   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 600)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 601       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,845,401\n",
            "Trainable params: 3,845,401\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/70\n",
            "102/102 [==============================] - 17s 88ms/step - loss: 50.1775 - mae: 4.0266\n",
            "Epoch 2/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 20.3262 - mae: 3.0685\n",
            "Epoch 3/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 17.3867 - mae: 2.9314\n",
            "Epoch 4/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 16.3479 - mae: 2.8446\n",
            "Epoch 5/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 16.1247 - mae: 2.7986\n",
            "Epoch 6/70\n",
            "102/102 [==============================] - 9s 91ms/step - loss: 16.1572 - mae: 2.7597\n",
            "Epoch 7/70\n",
            "102/102 [==============================] - 10s 99ms/step - loss: 15.0357 - mae: 2.6640\n",
            "Epoch 8/70\n",
            "102/102 [==============================] - 8s 75ms/step - loss: 15.0411 - mae: 2.6420\n",
            "Epoch 9/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 15.0726 - mae: 2.5980\n",
            "Epoch 10/70\n",
            "102/102 [==============================] - 8s 75ms/step - loss: 14.6350 - mae: 2.5567\n",
            "Epoch 11/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 14.1964 - mae: 2.4585\n",
            "Epoch 12/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 13.6256 - mae: 2.3292\n",
            "Epoch 13/70\n",
            "102/102 [==============================] - 8s 76ms/step - loss: 12.8642 - mae: 2.2017\n",
            "Epoch 14/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 12.1817 - mae: 2.0923\n",
            "Epoch 15/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 11.9094 - mae: 2.0100\n",
            "Epoch 16/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 11.1125 - mae: 1.9520\n",
            "Epoch 17/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 10.6471 - mae: 1.9233\n",
            "Epoch 18/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 10.2638 - mae: 1.8813\n",
            "Epoch 19/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 9.6804 - mae: 1.8299\n",
            "Epoch 20/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 9.6055 - mae: 1.8299\n",
            "Epoch 21/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 8.8202 - mae: 1.7333\n",
            "Epoch 22/70\n",
            "102/102 [==============================] - 8s 80ms/step - loss: 8.4477 - mae: 1.7036\n",
            "Epoch 23/70\n",
            "102/102 [==============================] - 8s 83ms/step - loss: 8.6538 - mae: 1.7086\n",
            "Epoch 24/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 8.2455 - mae: 1.6671\n",
            "Epoch 25/70\n",
            "102/102 [==============================] - 8s 75ms/step - loss: 7.6710 - mae: 1.6167\n",
            "Epoch 26/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 7.7830 - mae: 1.6125\n",
            "Epoch 27/70\n",
            "102/102 [==============================] - 8s 80ms/step - loss: 7.3507 - mae: 1.5632\n",
            "Epoch 28/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 7.0852 - mae: 1.5431\n",
            "Epoch 29/70\n",
            "102/102 [==============================] - 9s 87ms/step - loss: 7.2065 - mae: 1.5477\n",
            "Epoch 30/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 6.9516 - mae: 1.5233\n",
            "Epoch 31/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 6.6586 - mae: 1.5019\n",
            "Epoch 32/70\n",
            "102/102 [==============================] - 10s 100ms/step - loss: 6.7442 - mae: 1.4947\n",
            "Epoch 33/70\n",
            "102/102 [==============================] - 8s 82ms/step - loss: 6.5788 - mae: 1.4833\n",
            "Epoch 34/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 6.5191 - mae: 1.4707\n",
            "Epoch 35/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 6.6545 - mae: 1.4734\n",
            "Epoch 36/70\n",
            "102/102 [==============================] - 11s 107ms/step - loss: 6.4215 - mae: 1.4689\n",
            "Epoch 37/70\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 6.2244 - mae: 1.4516\n",
            "Epoch 38/70\n",
            "102/102 [==============================] - 9s 85ms/step - loss: 6.0582 - mae: 1.4265\n",
            "Epoch 39/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 6.1818 - mae: 1.4350\n",
            "Epoch 40/70\n",
            "102/102 [==============================] - 8s 76ms/step - loss: 6.3014 - mae: 1.4387\n",
            "Epoch 41/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 5.8701 - mae: 1.4140\n",
            "Epoch 42/70\n",
            "102/102 [==============================] - 8s 77ms/step - loss: 5.9464 - mae: 1.4034\n",
            "Epoch 43/70\n",
            "102/102 [==============================] - 9s 86ms/step - loss: 5.8561 - mae: 1.3941\n",
            "Epoch 44/70\n",
            "102/102 [==============================] - 9s 90ms/step - loss: 6.0124 - mae: 1.4034\n",
            "Epoch 45/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 5.6299 - mae: 1.3821\n",
            "Epoch 46/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 5.6124 - mae: 1.3763\n",
            "Epoch 47/70\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 5.4432 - mae: 1.3588\n",
            "Epoch 48/70\n",
            "102/102 [==============================] - 9s 87ms/step - loss: 5.6421 - mae: 1.3647\n",
            "Epoch 49/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 5.3064 - mae: 1.3514\n",
            "Epoch 50/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 5.0636 - mae: 1.3334\n",
            "Epoch 51/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 5.2323 - mae: 1.3363\n",
            "Epoch 52/70\n",
            "102/102 [==============================] - 7s 73ms/step - loss: 5.3101 - mae: 1.3441\n",
            "Epoch 53/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 5.0660 - mae: 1.3210\n",
            "Epoch 54/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 5.0948 - mae: 1.3266\n",
            "Epoch 55/70\n",
            "102/102 [==============================] - 7s 72ms/step - loss: 5.0813 - mae: 1.3284\n",
            "Epoch 56/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 5.1943 - mae: 1.3347\n",
            "Epoch 57/70\n",
            "102/102 [==============================] - 9s 92ms/step - loss: 5.3834 - mae: 1.3304\n",
            "Epoch 58/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 5.0328 - mae: 1.3250\n",
            "Epoch 59/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 4.9042 - mae: 1.3036\n",
            "Epoch 60/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 5.2799 - mae: 1.3336\n",
            "Epoch 61/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 4.9117 - mae: 1.3062\n",
            "Epoch 62/70\n",
            "102/102 [==============================] - 8s 74ms/step - loss: 4.8621 - mae: 1.2966\n",
            "Epoch 63/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 4.8907 - mae: 1.2947\n",
            "Epoch 64/70\n",
            "102/102 [==============================] - 9s 84ms/step - loss: 5.2031 - mae: 1.3187\n",
            "Epoch 65/70\n",
            "102/102 [==============================] - 8s 78ms/step - loss: 4.7772 - mae: 1.2991\n",
            "Epoch 66/70\n",
            "102/102 [==============================] - 9s 89ms/step - loss: 5.0695 - mae: 1.3090\n",
            "Epoch 67/70\n",
            "102/102 [==============================] - 7s 72ms/step - loss: 4.8579 - mae: 1.3064\n",
            "Epoch 68/70\n",
            "102/102 [==============================] - 9s 88ms/step - loss: 4.5588 - mae: 1.2653\n",
            "Epoch 69/70\n",
            "102/102 [==============================] - 8s 81ms/step - loss: 4.6878 - mae: 1.2837\n",
            "Epoch 70/70\n",
            "102/102 [==============================] - 8s 79ms/step - loss: 4.9236 - mae: 1.3062\n",
            "203/203 [==============================] - 3s 12ms/step\n",
            "Kappa Score: 0.9615792874313214\n",
            "Average kappa score value is : 0.9624295794716811\n"
          ]
        }
      ],
      "source": [
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "cv = KFold(n_splits=2, shuffle=True)\n",
        "cv_data = cv.split(X)\n",
        "results = []\n",
        "fold_count = 1\n",
        "\n",
        "print(X.shape)\n",
        "print(y.shape)\n",
        "\n",
        "for traincv, testcv in cv_data:\n",
        "    print(\"\\n--------Fold {}--------\\n\".format(fold_count))\n",
        "    # get the train and test from the dataset.\n",
        "    X_train, X_test, y_train, y_test = X.iloc[traincv], X.iloc[testcv], y.iloc[traincv], y.iloc[testcv]\n",
        "    train_essays = X_train['essay']\n",
        "    test_essays = X_test['essay']\n",
        "    train_sentences = []\n",
        "    for essay in train_essays:\n",
        "        train_sentences.append(essay_to_wordlist(essay))\n",
        "\n",
        "    print(\"Converting sentences to word2vec model\")\n",
        "    model,_ = build_word2vec(train_sentences, params_word2vec['num_workers'], params_word2vec['num_features'], params_word2vec['min_word_count'], params_word2vec['context'], params_word2vec['epochs'])\n",
        "    top10 = collections.defaultdict(int)\n",
        "\n",
        "    trainDataVecs = np.array(getAvgFeatureVecs(train_sentences, model, params_word2vec['num_features']))\n",
        "    test_sentences = []\n",
        "    \n",
        "    for essay_v in test_essays:\n",
        "        test_sentences.append(essay_to_wordlist(essay_v))\n",
        "\n",
        "    testDataVecs = np.array(getAvgFeatureVecs(test_sentences, model, params_word2vec['num_features']))\n",
        "\n",
        "    trainDataVectors = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
        "    \n",
        "    testDataVectors = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
        "    \n",
        "    lstm_model = get_model(Hidden_dimension1=params_lstm['Hidden_dim1'], Hidden_dimension2=params_lstm['Hidden_dim2'], return_sequences=params_lstm['return_sequences'],\n",
        "                            dropout=params_lstm['dropout'], recurrent_dropout = params_lstm['recurrent_dropout'], input_size=params_lstm['input_size'],\n",
        "                            activation=params_lstm['activation'], bidirectional=True )\n",
        "    \n",
        "    # Use this if you want to log your results on Neptune. \n",
        "    # history = lstm_model.fit(trainDataVectors, y_train, batch_size=params_lstm['batch_size'], epochs=params_lstm['epoch'], callbacks= [NeptuneLogger()])\n",
        "    \n",
        "    history = lstm_model.fit(trainDataVectors, y_train, batch_size=params_lstm['batch_size'], epochs=params_lstm['epoch'])\n",
        "\n",
        "    y_pred = lstm_model.predict(testDataVectors)\n",
        "    y_pred = np.around(y_pred)\n",
        "    np.nan_to_num(y_pred)\n",
        "    result = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
        "    \n",
        "    print(\"Kappa Score: {}\".format(result))\n",
        "    results.append(result)\n",
        "    fold_count += 1\n",
        "\n",
        "print(\"Average kappa score value is : {}\".format(np.mean(np.asarray(results))))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if 'mae' in lstm_model.metrics_names:\n",
        "    print(\"MAE metric is included in the model.\")\n",
        "else:\n",
        "    print(\"MAE metric is NOT included in the model.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mX5-ebEOnu8r",
        "outputId": "4f8b4b6f-283a-4602-8e40-b18ce3a6dced"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MAE metric is included in the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run['BiLSTM_train/mae'] = history.history['mae'][-1]\n",
        "run['BiLSTM_train/loss'] = history.history['loss'][-1]\n",
        "run['BiLSTM_train/cohen_kappa'] = result"
      ],
      "metadata": {
        "id": "KuafXR9TL9-j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving Models**"
      ],
      "metadata": {
        "id": "77Z2cFjhyj4D"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvtLWcuFplxj"
      },
      "source": [
        "# **Testing Model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YoMYiKaQrUMP"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_excel(\"/content/drive/MyDrive/IntelliTech-DataSet/Testing_Material/Testing_Dataset.xlsx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "wnQ0JE-nsF7j",
        "outputId": "26e523c2-4751-47d9-dd3b-6bcbf790ea93"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   essay_id  essay_set                                              essay  \\\n",
              "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
              "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
              "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
              "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
              "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
              "\n",
              "   predicted_score  grade                           essay_type  \n",
              "0                7      8  persuasive / narrative / expository  \n",
              "1                8      8  persuasive / narrative / expository  \n",
              "2                9      8  persuasive / narrative / expository  \n",
              "3                9      8  persuasive / narrative / expository  \n",
              "4                9      8  persuasive / narrative / expository  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2989eeb4-f0ae-411a-abab-7db6311b8dad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>essay_id</th>\n",
              "      <th>essay_set</th>\n",
              "      <th>essay</th>\n",
              "      <th>predicted_score</th>\n",
              "      <th>grade</th>\n",
              "      <th>essay_type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1788</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>persuasive / narrative / expository</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1789</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>persuasive / narrative / expository</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1790</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>persuasive / narrative / expository</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1791</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>persuasive / narrative / expository</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1792</td>\n",
              "      <td>1</td>\n",
              "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
              "      <td>9</td>\n",
              "      <td>8</td>\n",
              "      <td>persuasive / narrative / expository</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2989eeb4-f0ae-411a-abab-7db6311b8dad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2989eeb4-f0ae-411a-abab-7db6311b8dad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2989eeb4-f0ae-411a-abab-7db6311b8dad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIf2v7WosD-7",
        "outputId": "3819ea81-68fa-4394-f346-34a6696bf214"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 3s 22ms/step\n"
          ]
        }
      ],
      "source": [
        "test_essays = df_test['essay']\n",
        "y_test = df_test['predicted_score']\n",
        "test_essay_sentences = []\n",
        "for each_essay in test_essays:\n",
        "  test_essay_sentences.append(essay_to_wordlist(each_essay))\n",
        "\n",
        "test_features = np.array(getAvgFeatureVecs(test_essay_sentences, model, params_word2vec['num_features']))\n",
        "test_features = np.reshape(test_features, (test_features.shape[0], 1, test_features.shape[1]))\n",
        "y_predicted = lstm_model.predict(test_features)\n",
        "y_predicted = np.around(y_predicted)\n",
        "np.nan_to_num(y_predicted)\n",
        "y_predicted_df = pd.DataFrame(y_predicted)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = lstm_model.evaluate(test_features, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_twQM_Fot274",
        "outputId": "3f422e76-0830-48dc-d42c-9a69604ee0b3"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "132/132 [==============================] - 3s 15ms/step - loss: 5.2850 - mae: 1.2144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gjNzo6zRtALS",
        "outputId": "21d187b4-1529-413e-e9ab-d9393ab7c0bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kappa Score: 0.9648363724072312\n"
          ]
        }
      ],
      "source": [
        "output_df = pd.DataFrame()\n",
        "output_df['y_test'] = df_test.predicted_score\n",
        "output_df[\"y_pred\"] = y_predicted_df\n",
        "result = cohen_kappa_score(df_test.predicted_score, y_predicted, weights='quadratic')\n",
        "print(\"Kappa Score: {}\".format(result))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "run['test/loss'] = test_loss\n",
        "run['test/mae'] = test_mae\n",
        "run['test/cohen_kappa_score'] = result"
      ],
      "metadata": {
        "id": "8Yj-kkkDuX7k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "lgIqUEGb1QnP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "161de6d1-dfc1-4eef-af92-636508b781ce"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      y_test  y_pred                                              essay\n",
              "0          7     9.0  Dear @ORGANIZATION1, @CAPS1 more and more peop...\n",
              "1          8     8.0  Dear @LOCATION1 Time @CAPS1 me tell you what I...\n",
              "2          9     8.0  Dear Local newspaper, Have you been spending a...\n",
              "3          9     9.0  Dear Readers, @CAPS1 you imagine how life woul...\n",
              "4          9     7.0  Dear newspaper, I strongly believe that comput...\n",
              "...      ...     ...                                                ...\n",
              "4213      33    39.0   Have you ever noticed that if two little kids...\n",
              "4214      35    40.0                              Laughter @CAPS1 I ...\n",
              "4215      38    37.0   Laughter in @CAPS1 A laugh is not just an act...\n",
              "4216      32    37.0    LAUGHTER @CAPS1 i was younger my friend live...\n",
              "4217      39    35.0   You know how the saying goes live, laugh, lov...\n",
              "\n",
              "[4218 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e92af11f-9d32-483e-8166-50ec8eb58ed8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>y_test</th>\n",
              "      <th>y_pred</th>\n",
              "      <th>essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>8</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4213</th>\n",
              "      <td>33</td>\n",
              "      <td>39.0</td>\n",
              "      <td>Have you ever noticed that if two little kids...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4214</th>\n",
              "      <td>35</td>\n",
              "      <td>40.0</td>\n",
              "      <td>Laughter @CAPS1 I ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4215</th>\n",
              "      <td>38</td>\n",
              "      <td>37.0</td>\n",
              "      <td>Laughter in @CAPS1 A laugh is not just an act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4216</th>\n",
              "      <td>32</td>\n",
              "      <td>37.0</td>\n",
              "      <td>LAUGHTER @CAPS1 i was younger my friend live...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4217</th>\n",
              "      <td>39</td>\n",
              "      <td>35.0</td>\n",
              "      <td>You know how the saying goes live, laugh, lov...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4218 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e92af11f-9d32-483e-8166-50ec8eb58ed8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e92af11f-9d32-483e-8166-50ec8eb58ed8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e92af11f-9d32-483e-8166-50ec8eb58ed8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "output_df['essay'] = df_test['essay']\n",
        "output_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "wqUajzdZ1SAA"
      },
      "outputs": [],
      "source": [
        "output_df.to_csv('test_results.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Saving Models**"
      ],
      "metadata": {
        "id": "haGzyRaNmSHV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('BiLstm_model.pkl', 'wb') as writer:\n",
        "  pickle.dump(lstm_model, writer)\n",
        "\n",
        "with open('Word2Vec_model.pkl', 'wb') as writer:\n",
        "  pickle.dump(model, writer)"
      ],
      "metadata": {
        "id": "lAqDbIcjmRee"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Query Testing**"
      ],
      "metadata": {
        "id": "3LNQsHt7d4oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_features = 400\n",
        "\n",
        "def Load_Model():\n",
        "    lstm_model = pickle.load(open('/content/BiLstm_model.pkl', 'rb'))\n",
        "    word2vec_model = pickle.load(open('/content/Word2Vec_model.pkl', 'rb'))\n",
        "    return lstm_model, word2vec_model;\n",
        "\n",
        "def predict_score(query_essay):\n",
        "  lstm_model,word2vec_model = Load_Model()\n",
        "  query_essay_sentences = []\n",
        "  query_essay_sentences.append(essay_to_wordlist(query_essay))\n",
        "  query_data_Vecs = np.array(getAvgFeatureVecs(query_essay_sentences, word2vec_model, num_features))\n",
        "  query_data_Vectors = np.reshape(query_data_Vecs, (query_data_Vecs.shape[0], 1, query_data_Vecs.shape[1]))\n",
        "  y_predicted = lstm_model.predict(query_data_Vectors)\n",
        "  y_predicted = np.around(y_predicted)\n",
        "  np.nan_to_num(y_predicted)\n",
        "  return y_predicted[0][0]"
      ],
      "metadata": {
        "id": "Be2VJR46d7rm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "essay = \"My name is sara\"\n",
        "predict_score(essay)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wj33qNLmw3zL",
        "outputId": "2211e671-12d2-48a1-cce9-5ada3f86e0d9"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 903ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}