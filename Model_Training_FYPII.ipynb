{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rough Notes: 1-Combined Approach\n",
        "2- Ensemble of models\n",
        "3-Inter Intra Class Approach"
      ],
      "metadata": {
        "id": "0SGsTWX1Sg5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToDo:<br/>  1- Add TfIdf scores for prompt relevancy in dataset\n",
        "            2- Change Scaling to a better type\n",
        "            3- Log Model "
      ],
      "metadata": {
        "id": "t1f-zzGbm9t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reverse Scaling: X = (X_norm * (max_val - min_val)) + min_val"
      ],
      "metadata": {
        "id": "Kv46EDuSIeUL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training error NaN loss:**\n",
        "<br/>1. Increased Dropout,\n",
        "<br/>2. Decreased LR, Batchsize\n",
        "<br/>3. Removed NaN values\n",
        "<br/>4. clipvalue\n",
        "\n"
      ],
      "metadata": {
        "id": "GuNp96kBbIJ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Packages**"
      ],
      "metadata": {
        "id": "Rvwsev4BDu3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7jZwjcsWDnp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ply\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Masking,LSTM, GRU, Conv1D, Dropout, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import concatenate\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, SimpleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "MEeJW8ffGVER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train01 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet01_Features.csv\", index_col =0)\n",
        "df_train02 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet02_Features.csv\", index_col =0)\n",
        "df_train03 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet03_Features.csv\", index_col =0)\n",
        "df_train04 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet04_Features.csv\", index_col =0)\n",
        "df_train05 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet05_Features.csv\", index_col =0)\n",
        "df_train06 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet06_Features.csv\", index_col =0)\n",
        "df_train07 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet07_Features.csv\", index_col =0)\n",
        "df_train08 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet08_Features.csv\", index_col =0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_DM_p6nGTLn",
        "outputId": "051f7ed1-9f21-475f-f1e0-36391c9f15a3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for i in range(1, 9):\n",
        "    df = pd.read_csv(f'/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet0{i}_Features.csv')  # assuming the dataframes are stored as CSV files\n",
        "    scores_2d = [[score] for score in df['Total Score']]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    df['Total Score'] = scaler.fit_transform(scores_2d)   #Changed from z-score to Minmax, z-score was giving negative range\n",
        "    df['Essay Set'] = i\n",
        "    dfs.append(df[['ID', 'Essay Set', 'Total Score', 'Preprocessed_Essay']])  # extract only the ID and Score columns and append to the list\n",
        "\n",
        "# concatenate the dataframes using pd.concat() and the loc accessor\n",
        "df_train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
        "df_train['Grade'] = df_train['Essay Set'].apply(lambda x: 8 if x == 1 or x == 5 else (7 if x == 7 else 10))\n",
        "df_train['Essay Type'] = df_train['Essay Set'].apply(lambda x: 'source dependent responses' if x in range(3,7) else 'persuasive / narrative  / expository')\n"
      ],
      "metadata": {
        "id": "DVhSCld-OivX"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') \n",
        "#df_train['tokenized_text'] = df_train['Preprocessed_Essay'].apply(lambda x: [word_tokenize(sent.lower()) for sent in sent_tokenize(x)])\n",
        "# df_train['tokenized_text'] = df_train['tokenized_text'].apply(lambda x: ' '.join(x))\n",
        "df_train['tokenized_text'] = df_train['Preprocessed_Essay'].apply(lambda x: word_tokenize(x.lower()))\n",
        "df_train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "r2voIZhUmKR_",
        "outputId": "815dbab5-727f-4106-d7e7-9c5a79edaf54"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID  Essay Set  Total Score  \\\n",
              "4999  7398          3     0.333333   \n",
              "6319  9876          4     0.333333   \n",
              "4606  7004          3     0.666667   \n",
              "4393  6790          3     0.666667   \n",
              "3404  4599          2     0.400000   \n",
              "\n",
              "                                     Preprocessed_Essay  Grade  \\\n",
              "4999  in the towns that the cyclist arrived at were ...     10   \n",
              "6319  the author concludes in the story that saeng f...     10   \n",
              "4606  the features of the setting affected the cycli...     10   \n",
              "4393  in the story ‘do not exceed posted speed limit...     10   \n",
              "3404  should materials  such as books  music  movies...     10   \n",
              "\n",
              "                                Essay Type  \\\n",
              "4999            source dependent responses   \n",
              "6319            source dependent responses   \n",
              "4606            source dependent responses   \n",
              "4393            source dependent responses   \n",
              "3404  persuasive / narrative  / expository   \n",
              "\n",
              "                                         tokenized_text  \n",
              "4999  [in, the, towns, that, the, cyclist, arrived, ...  \n",
              "6319  [the, author, concludes, in, the, story, that,...  \n",
              "4606  [the, features, of, the, setting, affected, th...  \n",
              "4393  [in, the, story, ‘, do, not, exceed, posted, s...  \n",
              "3404  [should, materials, such, as, books, music, mo...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2564cb0d-c715-453b-8634-8572ca8964d3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay Set</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Essay Type</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4999</th>\n",
              "      <td>7398</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>in the towns that the cyclist arrived at were ...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[in, the, towns, that, the, cyclist, arrived, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6319</th>\n",
              "      <td>9876</td>\n",
              "      <td>4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>the author concludes in the story that saeng f...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[the, author, concludes, in, the, story, that,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4606</th>\n",
              "      <td>7004</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>the features of the setting affected the cycli...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[the, features, of, the, setting, affected, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4393</th>\n",
              "      <td>6790</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>in the story ‘do not exceed posted speed limit...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[in, the, story, ‘, do, not, exceed, posted, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3404</th>\n",
              "      <td>4599</td>\n",
              "      <td>2</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>should materials  such as books  music  movies...</td>\n",
              "      <td>10</td>\n",
              "      <td>persuasive / narrative  / expository</td>\n",
              "      <td>[should, materials, such, as, books, music, mo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2564cb0d-c715-453b-8634-8572ca8964d3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2564cb0d-c715-453b-8634-8572ca8964d3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2564cb0d-c715-453b-8634-8572ca8964d3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def para_to_sent(paragraph):\n",
        "    sentences = nltk.sent_tokenize(paragraph)\n",
        "    return sentences\n",
        "\n",
        "# Apply function to 'Essay' column of the dataframe\n",
        "df_train['Essay Sentences'] = df_train['Preprocessed_Essay'].apply(para_to_sent)"
      ],
      "metadata": {
        "id": "RraloOIq_abF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzgtDmch0dVE",
        "outputId": "8207220b-f44a-46a4-b93b-4346cc048506"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12978, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Essay Sentences']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOjWTpIGNaBY",
        "outputId": "275cd9b3-388d-4626-dc89-35f5af5a6d24"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [dear local newspaper  i think effects compute...\n",
              "1        [dear i believe that using computers will bene...\n",
              "2        [dear  more and more people use computers  but...\n",
              "3        [dear local newspaper  i have found that many ...\n",
              "4        [dear i know having computers has a positive e...\n",
              "                               ...                        \n",
              "12973    [ in most stories mothers and daughters are ei...\n",
              "12974    [ i never understood the meaning laughter is t...\n",
              "12975    [when you laugh  is out of habit  or is cause ...\n",
              "12976    [                               trippin  on fe...\n",
              "12977    [ many people believe that laughter can improv...\n",
              "Name: Essay Sentences, Length: 12978, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(\"Dataset.csv\")"
      ],
      "metadata": {
        "id": "DNy6RguIRLLM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**\n",
        "Note: Change scaling type to something more inclined with non-linear data type and, remove NaNs from essay set04"
      ],
      "metadata": {
        "id": "AJTAFn6Wgb9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the number of missing values in dataset\n",
        "missing = df_train.isnull().sum()\n",
        "print(missing)\n",
        "# Finding percentage of missing value\n",
        "total_cells = np.product(df_train.shape)\n",
        "percent = (missing.sum() / total_cells)*100\n",
        "percent  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VygHu8AdsGij",
        "outputId": "bc02cfbb-6450-4be9-9f6c-9787d2587cf0"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                    0\n",
            "Essay Set             0\n",
            "Total Score           1\n",
            "Preprocessed_Essay    0\n",
            "Grade                 0\n",
            "Essay Type            0\n",
            "tokenized_text        0\n",
            "Essay Sentences       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0009631684388965943"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.dropna()"
      ],
      "metadata": {
        "id": "STwNpgdV0EOh"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrj3V3jT0mdk",
        "outputId": "0f9c33dc-e28b-499a-9b79-234e6a8d36fa"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12977, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the number of missing values in dataset\n",
        "missing = df_train.isnull().sum()\n",
        "print(missing)\n",
        "# Finding percentage of missing value\n",
        "total_cells = np.product(df_train.shape)\n",
        "percent = (missing.sum() / total_cells)*100\n",
        "percent  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcz33TRR_MHM",
        "outputId": "5741c90c-8601-40d6-c248-8bbb5abea039"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                    0\n",
            "Essay Set             0\n",
            "Total Score           0\n",
            "Preprocessed_Essay    0\n",
            "Grade                 0\n",
            "Essay Type            0\n",
            "tokenized_text        0\n",
            "Essay Sentences       0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Embedding of Preprocessed Essay**\n",
        "\n"
      ],
      "metadata": {
        "id": "oGZehdxOgvTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model = api.load(\"glove-wiki-gigaword-100\")"
      ],
      "metadata": {
        "id": "HY627c_FLLf7"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_glove_embeddings(text_data):\n",
        "    # Tokenize the text data\n",
        "    tokenized_data = [sentence.split() for sentence in text_data]\n",
        "\n",
        "    # Obtain the GloVe embeddings\n",
        "    embeddings = np.zeros((len(text_data), 100))\n",
        "\n",
        "    for i, sentence in enumerate(tokenized_data):\n",
        "        print(i  , sentence)\n",
        "        break\n",
        "        for word in sentence:\n",
        "            if word in glove_model.key_to_index:\n",
        "                embeddings[i] += glove_model[word]\n",
        "        embeddings[i] /= len(sentence)\n",
        "    return embeddings\n",
        "\n",
        "# Obtain the GloVe embeddings for the text data\n",
        "glove_embeddings = get_glove_embeddings(df['Preprocessed_Essay'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_irgyVvxOXO7",
        "outputId": "9be46898-0d6b-4e00-d4ac-be957a4f673d"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['a', 'long', 'time', 'ago', 'when', 'i', 'was', 'in', 'third', 'grade', 'i', 'had', 'a', 'friend', 'who', 's', 'mom', 'was', 'in', 'a', 'bad', 'mood', 'she', 'never', 'laughed', 'and', 'she', 'never', 'smiled', 'every', 'time', 'i', 'saw', 'her', 'i', 'would', 'smile', 'at', 'her', 'and', 'all', 'she', 'would', 'do', 'was', 'frown', 'and', 'keep', 'walking', 'at', 'first', 'i', 'didn', 't', 'know', 'she', 'was', 'a', 'grouch', 'i', 'just', 'thought', 'she', 'didn', 't', 'like', 'me', 'or', 'something', 'when', 'told', 'me', 'his', 'mom', 'was', 'a', 'grouch', 'i', 'started', 'to', 'laugh', 'and', 'laugh', 'he', 'asked', 'me', 'what', 'was', 'so', 'funny', 'i', 'told', 'him', 'that', 'i', 'thought', 'his', 'mom', 'didn', 't', 'like', 'me', 'or', 'something', 'because', 'every', 'time', 'i', 'see', 'his', 'mom', 'i', 'would', 'smile', 'at', 'her', 'and', 'all', 'she', 'will', 'do', 'is', 'frown', 'and', 'walk', 'away', 'that', 'made', 'my', 'friend', 'laugh', 'we', 'were', 'cracking', 'up', 'so', 'hard', 'that', 'we', 'got', 'in', 'trouble', 'in', 'class', 'the', 'next', 'day', 'and', 'i', 'were', 'eating', 'lunch', 'at', 'school', 'when', 'he', 'says', 'to', 'me', 'lt', 'hey', 'your', 'pretty', 'good', 'at', 'making', 'people', 'laugh', 'gt', 'i', 'said', 'lt', 'no', 'i', 'am', 'not', 'my', 'jokesare', 'horrible', 'gt', 'he', 'said', 'lt', 'caps', 'lets', 'put', 'them', 'to', 'the', 'test', 'go', 'up', 'to', 'some', 'one', 'new', 'to', 'this', 'school', 'gt', 'i', 'said', 'so', 'we', 'went', 'around', 'the', 'whole', 'school', 'looking', 'for', 'a', 'new', 'student', 'unfortunately', 'we', 'couldn', 't', 'find', 'one', 'we', 'heard', 'the', 'bell', 'ring', 'and', 'we', 'ran', 'to', 'our', 'class', 'we', 'sat', 'in', 'the', 'back', 'of', 'the', 'classroom', 'its', 'only', 'and', 'i', 'and', 'anempty', 'seat', 'between', 'us', 'we', 'were', 'excited', 'because', 'our', 'teacher', 'was', 'going', 'to', 'show', 'us', 'a', 'movie', 'got', 'the', 'front', 'of', 'the', 'room', 'andclass', 'today', 'i', 'have', 'an', 'announcement', 'we', 'have', 'a', 'new', 'student', 'in', 'our', 'class', 'say', 'hello', 'to', 'walked', 'through', 'the', 'door', 'told', 'shecould', 'sit', 'in', 'the', 'back', 'in', 'between', 'and', 'i', 'she', 'sat', 'down', 'turned', 'to', 'the', 'both', 'of', 'us', 'and', 'said', 'hello', 'gave', 'me', 'a', 'look', 'that', 'said', 'tell', 'her', 'the', 'joke', 'and', 'him', 'a', 'thumbs', 'up', 'i', 'turned', 'to', 'and', 'said', 'hi', 'i', 'm', 'do', 'you', 'want', 'to', 'hear', 'a', 'joke', 'said', 'yeah', 'sure', 'i', 'started', 'lt', 'caps', 'knockshe', 'said', 'lt', 'who', 's', 'therei', 'said', 'lt', 'booshe', 'said', 'lt', 'boo', 'who', 'i', 'said', 'lt', 'oh', 'don', 't', 'cry', 'i', 'am', 'right', 'here', 'gt', 'at', 'first', 'she', 'didn', 't', 'laugh', 'because', 'she', 'didn', 't', 'get', 'it', 'but', 'duringthe', 'middle', 'of', 'the', 'movie', 'she', 'said', 'lt', 'ohhhh', 'i', 'get', 'itand', 'she', 'started', 'to', 'laugh', 'turned', 'to', 'me', 'and', 'said', 'lt', 'i', 'told', 'you', 'so', 'gt', 'got', 'this', 'crazy', 'idea', 'that', 'if', 'i', 'spent', 'the', 'night', 'at', 'his', 'house', 'that', 'i', 'could', 'make', 'his', 'mom', 'laugh', 'or', 'at', 'least', 'make', 'her', 'smile', 'i', 'said', 'lt', 'caps', 'sounds', 'like', 'a', 'plan', 'gt', 'i', 'asked', 'mt', 'mom', 'if', 'it', 'was', 'if', 'i', 'could', 'spend', 'the', 'night', 'at', 'house', 'she', 'said', 'lt', 'yeah', 'just', 'make', 'sure', 'its', 'with', 'his', 'mom', 'gt', 'asked', 'his', 'mom', 'she', 'said', 'it', 'was', 'when', 'i', 'got', 'to', 'house', 'the', 'first', 'thing', 'we', 'did', 'was', 'play', 'video', 'games', 'when', 'it', 'was', 'dinner', 'time', 'we', 'all', 'sat', 'down', 'at', 'the', 'table', 'to', 'eat', 'and', 'i', 'were', 'on', 'one', 'side', 'and', 'his', 'parents', 'on', 'the', 'other', 'when', 'we', 'started', 'eating', 'told', 'me', 'to', 'tell', 'the', 'joke', 'to', 'his', 'parents', 'i', 'said', 'so', 'i', 'said', 'to', 'them', 'lt', 'caps', 'replied', 'lt', 'who', 's', 'therei', 'said', 'lt', 'boothey', 'said', 'lt', 'boo', 'who', 'i', 'said', 'lt', 'oh', 'don', 't', 'cry', 'i', 'am', 'right', 'here', 'gt', 'his', 'parents', 'started', 'to', 'laugh', 'and', 'laugh', 'and', 'they', 'keptlaughing', 'for', 'like', 'five', 'minutes', 'turned', 'to', 'me', 'and', 'yelled', 'it', 'worked', 'his', 'mom', 'asked', 'what', 'worked', 'explained', 'everything', 'to', 'them', 'his', 'mom', 'told', 'usthat', 'her', 'mom', 'had', 'recently', 'died', 'and', 'that', 's', 'why', 'she', 'was', 'in', 'a', 'bad', 'mood', 'after', 'dinner', 'we', 'went', 'to', 'bed', 'and', 'fell', 'asleep', 'the', 'next', 'morning', 'when', 'my', 'mom', 'came', 'to', 'pick', 'me', 'up', 'she', 'asked', 'me', 'how', 'the', 'sleep', 'over', 'went', 'i', 'said', 'it', 'was', 'fun', 'i', 'made', 'people', 'laugh', 'she', 'said', 'but', 'laughter', 'isn', 't', 'going', 'to', 'help', 'you', 'clean', 'your', 'roomall', 'i', 'could', 'say', 'was', 'gosh', 'darn', 'it', 'fin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings.shape"
      ],
      "metadata": {
        "id": "xbXSQpZAOlS_",
        "outputId": "9bfac6bd-c84d-4a16-860b-0ee8b1a3e2e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to obtain the GloVe embeddings\n",
        "def get_glove_embeddings(text_data):\n",
        "    # Flatten the list of lists\n",
        "    flattened_data = [sentence for sublist in text_data for sentence in sublist]\n",
        "    \n",
        "    # Join the sentences with a space character\n",
        "    joined_data = [' '.join(sentence) for sentence in flattened_data]\n",
        "\n",
        "    # Obtain the GloVe embeddings\n",
        "    embeddings = np.zeros((len(joined_data), 100))  \n",
        "\n",
        "    for i, sentence in enumerate(joined_data):\n",
        "        for word in sentence.split():\n",
        "            if word in glove_model.key_to_index:\n",
        "                embeddings[i] += glove_model[word]\n",
        "        embeddings[i] /= len(sentence.split())\n",
        "    return embeddings\n",
        "\n",
        "# Obtain the GloVe embeddings for the text data\n",
        "glove_embeddings = get_glove_embeddings(df['Preprocessed_Essay'])\n"
      ],
      "metadata": {
        "id": "jK3Emdu2aiju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8185e0e-2db9-4346-80fb-f8ecd88313e5"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-49-3133353da120>:16: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embeddings[i] /= len(sentence.split())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssafoaANSIV",
        "outputId": "11c6f119-f390-4c54-d267-2f0394899597"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2163263, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Categorical Features Encoding**"
      ],
      "metadata": {
        "id": "5dCJ_9jA2IW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 for persuasive / narrative / expository and 1 for source dependent responses\n",
        "df_train['Essay Type'] = df_train['Essay Type'].str.replace(\n",
        "    'persuasive / narrative  / expository', '0', case=True, regex=False)\n",
        "\n",
        "df_train['Essay Type'] = df_train['Essay Type'].str.replace(\n",
        "    'source dependent responses', '1', case=True, regex=False)\n",
        "\n",
        "# Ordinal Encoding\n",
        "oe = OrdinalEncoder(categories=[['7', '8', '10']])   # encoded as 0, 1 and 2\n",
        "df_train['Grade'] = oe.fit_transform(df_train[['Grade']]).astype(int)"
      ],
      "metadata": {
        "id": "bRmLxSbe2Qlm"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "id": "eVJtvhCY9x7h",
        "outputId": "e7dfcb3a-ff18-438a-8514-358f10986027"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID  Essay Set  Total Score  \\\n",
              "11438  18676          7     1.000000   \n",
              "11167  18373          7     0.545455   \n",
              "5100    7500          3     0.333333   \n",
              "7006   10567          4     0.000000   \n",
              "2383    3578          2     0.600000   \n",
              "\n",
              "                                      Preprocessed_Essay  Grade Essay Type  \\\n",
              "11438  i have been a patient man in my life  an examp...      0          0   \n",
              "11167  one day i was looking at a catalog in a store ...      0          0   \n",
              "5100   how the features of the setting affected the c...      2          1   \n",
              "7006   i think  the author concluded the story like t...      2          1   \n",
              "2383   today in society there are many things people ...      2          0   \n",
              "\n",
              "                                          tokenized_text  \\\n",
              "11438  [i, have, been, a, patient, man, in, my, life,...   \n",
              "11167  [one, day, i, was, looking, at, a, catalog, in...   \n",
              "5100   [how, the, features, of, the, setting, affecte...   \n",
              "7006   [i, think, the, author, concluded, the, story,...   \n",
              "2383   [today, in, society, there, are, many, things,...   \n",
              "\n",
              "                                         Essay Sentences  \n",
              "11438  [i have been a patient man in my life  an exam...  \n",
              "11167  [one day i was looking at a catalog in a store...  \n",
              "5100   [how the features of the setting affected the ...  \n",
              "7006   [i think  the author concluded the story like ...  \n",
              "2383   [today in society there are many things people...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-22b46614-9c8c-496b-89d0-f7d88a346a33\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay Set</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Essay Type</th>\n",
              "      <th>tokenized_text</th>\n",
              "      <th>Essay Sentences</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11438</th>\n",
              "      <td>18676</td>\n",
              "      <td>7</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>i have been a patient man in my life  an examp...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[i, have, been, a, patient, man, in, my, life,...</td>\n",
              "      <td>[i have been a patient man in my life  an exam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11167</th>\n",
              "      <td>18373</td>\n",
              "      <td>7</td>\n",
              "      <td>0.545455</td>\n",
              "      <td>one day i was looking at a catalog in a store ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>[one, day, i, was, looking, at, a, catalog, in...</td>\n",
              "      <td>[one day i was looking at a catalog in a store...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5100</th>\n",
              "      <td>7500</td>\n",
              "      <td>3</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>how the features of the setting affected the c...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[how, the, features, of, the, setting, affecte...</td>\n",
              "      <td>[how the features of the setting affected the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7006</th>\n",
              "      <td>10567</td>\n",
              "      <td>4</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>i think  the author concluded the story like t...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[i, think, the, author, concluded, the, story,...</td>\n",
              "      <td>[i think  the author concluded the story like ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2383</th>\n",
              "      <td>3578</td>\n",
              "      <td>2</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>today in society there are many things people ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[today, in, society, there, are, many, things,...</td>\n",
              "      <td>[today in society there are many things people...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-22b46614-9c8c-496b-89d0-f7d88a346a33')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-22b46614-9c8c-496b-89d0-f7d88a346a33 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-22b46614-9c8c-496b-89d0-f7d88a346a33');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybVF8RwlFmR7",
        "outputId": "6da6fb5f-e2c0-4b7b-9ae3-98143830e319"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 12977 entries, 0 to 12977\n",
            "Data columns (total 8 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   ID                  12977 non-null  int64  \n",
            " 1   Essay Set           12977 non-null  int64  \n",
            " 2   Total Score         12977 non-null  float64\n",
            " 3   Preprocessed_Essay  12977 non-null  object \n",
            " 4   Grade               12977 non-null  int64  \n",
            " 5   Essay Type          12977 non-null  object \n",
            " 6   tokenized_text      12977 non-null  object \n",
            " 7   Essay Sentences     12977 non-null  object \n",
            "dtypes: float64(1), int64(3), object(4)\n",
            "memory usage: 912.4+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Implementation**"
      ],
      "metadata": {
        "id": "-C2pPnTmgz-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 100  #from 16\n",
        "max_length = 100\n",
        "trunc_type='post' # remove sentences if they reach the max_lenght\n",
        "padding_type='post' #padding after sentences\n",
        "oov_tok = \"<OOV>\"   #placeholder for new words in padding\n",
        "training_size = 20000\n",
        "DROPOUT_RATE = 0.5"
      ],
      "metadata": {
        "id": "4_YHLSyIhAsB"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded Input Text**"
      ],
      "metadata": {
        "id": "SJt8dmb1a3jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(num_words=vocab_size)\n",
        "tokenized_text = df_train['tokenized_text'].values.tolist()\n",
        "flatten_text = [word for sent in tokenized_text for word in sent]\n",
        "joined_text = ' '.join(flatten_text)\n",
        "tk.fit_on_texts([joined_text])\n",
        "\n",
        "encoded_essay_train = tk.texts_to_sequences(tokenized_text)\n",
        "padded_essay_train = pad_sequences(encoded_essay_train, maxlen=max_length, padding=padding_type)   #Input Text"
      ],
      "metadata": {
        "id": "vHt-LmlQldxt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(padded_essay_train.dtype)\n",
        "padded_essay_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZiGMWC42XBgD",
        "outputId": "8e58aeb1-4542-443b-f095-78d8c1bebbd8"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12977, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input Features**"
      ],
      "metadata": {
        "id": "32Z0FDQkB7qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['Essay Set', 'Essay Type','Grade']   #add tf-idf\n",
        "features_df = df_train[feature_cols]\n",
        "# Convert features DataFrame to NumPy array\n",
        "features_train = features_df.values\n",
        "\n",
        "print(features_train.dtype)\n",
        "print(features_train.shape)\n",
        "features_train = features_train.astype('float32')\n",
        "print(features_train.dtype)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcBaIYCiCDjr",
        "outputId": "8177eddf-b975-4d38-f9c9-05e6aa342fbc"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "object\n",
            "(12977, 3)\n",
            "float32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Target Variable**"
      ],
      "metadata": {
        "id": "t7BL4MGxZ1b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_train = df_train['Total Score']\n",
        "print(target_train.dtype)\n",
        "print(target_train.shape)"
      ],
      "metadata": {
        "id": "JowbpGuFZ4r5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec09f9ba-da0b-439d-8603-606e6bbd22b5"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "float64\n",
            "(12977,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vanilla LSTM**"
      ],
      "metadata": {
        "id": "h-Ks12cWg4kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################## Try One ##########################################################\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "#     tf.keras.layers.LSTM(units=64),  #default activation is relu\n",
        "#     tf.keras.layers.Dense(units=1, activation='linear')\n",
        "# ])\n",
        "# model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])"
      ],
      "metadata": {
        "id": "H1tKD2eRi2OP"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################# Try Two #############################################################\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
        "#                     output_dim=EMBEDDING_DIM,\n",
        "#                     weights=[embedding_matrix],\n",
        "#                     input_length=MAX_SEQ_LEN,\n",
        "#                     trainable=False))\n",
        "# model.add(LSTM(units=64, activation='sigmoid'))\n",
        "# model.add(Dropout(rate=DROPOUT_RATE))\n",
        "# model.add(Dense(units=1, activation='linear'))\n"
      ],
      "metadata": {
        "id": "fHql1EhGBXeg"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IF NEEDED\n",
        "def cohen_kappa_with_quadratic_weights(y_true, y_pred):\n",
        "    y_true_classes = tf.round(y_true)\n",
        "    y_pred_classes = tf.round(y_pred)\n",
        "    kappa = cohen_kappa_score(y_true_classes, y_pred_classes, weights='quadratic')\n",
        "    return kappa"
      ],
      "metadata": {
        "id": "ey3c6Q4zpNbS"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Note: Reduced batch size from 2048 to 128.\n",
        "def build_vanilla_lstm(MAX_SEQ_LEN = 100, EMBEDDING_DIM = 100, DROPOUT_RATE = 0.5,EPOCHS = 100, BATCH_SIZE = 128 ,VALIDATION_SPLIT = 0.2,embedding_matrix=None):   \n",
        "# NOTE: Modify the function so it can accept parameters for later use in gridsearch cv  and bayesian and then make one function for bidriectional, add callback line that bahram told and plot the reslts like in tensorflow.ipynb\n",
        " \n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  NUM_FEATURES = len(features_train[0])\n",
        "  # Load pre-trained GloVe embeddings\n",
        "  #embedding_matrix = {} \n",
        "  # Define input layers\n",
        "  input_text = Input(shape=(MAX_SEQ_LEN,), dtype='int32')   # Padded Essay Tokens\n",
        "  input_features = Input(shape=(NUM_FEATURES,), dtype='float32') # Input Features\n",
        "\n",
        "  # Define embedding layer\n",
        "  embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                              output_dim=EMBEDDING_DIM,\n",
        "                              weights=[embedding_matrix],\n",
        "                              input_length=MAX_SEQ_LEN,\n",
        "                              trainable=False)\n",
        "  \n",
        "  # Define LSTM layer\n",
        "  lstm_layer = LSTM(units=64, activation='tanh')\n",
        "  # Connect input layers to embedding and LSTM layers\n",
        "  text_embed = embedding_layer(input_text)\n",
        "  text_lstm = lstm_layer(text_embed)\n",
        "  # Concatenate LSTM output with input features\n",
        "  concat_layer = concatenate([text_lstm, input_features])\n",
        "  # Define dropout layer\n",
        "  dropout_layer = Dropout(rate=DROPOUT_RATE)\n",
        "  # Connect concat layer to dropout layer\n",
        "  dropout_output = dropout_layer(concat_layer)\n",
        "  # Define output layer\n",
        "  output_layer = Dense(units=1, activation='linear')   #try it with sigmoid, relu, and tanh\n",
        "  # Connect dropout output to output layer\n",
        "  output = output_layer(dropout_output)\n",
        "\n",
        "  # Define model with two inputs and one output\n",
        "  model = tf.keras.Model(inputs=[input_text, input_features], outputs=output)\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00000001,clipvalue=1.0),   #try sgd, bgd,RMSprop\n",
        "                loss='mse',\n",
        "                metrics=['mae'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "C_eihi0Mt4MK"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Model**"
      ],
      "metadata": {
        "id": "exzTFpx2cDxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 100 \n",
        "BATCH_SIZE = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "lstm_model = build_vanilla_lstm(MAX_SEQ_LEN = 100, EMBEDDING_DIM = 100, DROPOUT_RATE = 0.5,EPOCHS = 100, BATCH_SIZE = 128 ,VALIDATION_SPLIT = 0.2, embedding_matrix=glove_embeddings)\n",
        "lstm_model.fit([padded_essay_train, features_train], target_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "id": "z_D6a6ZIcHOr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dce32c24-b584-421f-9927-8bb47c3b10cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "82/82 [==============================] - 25s 275ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 2/100\n",
            "82/82 [==============================] - 18s 222ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 3/100\n",
            "82/82 [==============================] - 18s 217ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 4/100\n",
            "82/82 [==============================] - 18s 218ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 5/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 6/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 7/100\n",
            "82/82 [==============================] - 17s 209ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 8/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 9/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 10/100\n",
            "82/82 [==============================] - 17s 204ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 11/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 12/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 13/100\n",
            "82/82 [==============================] - 17s 202ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 14/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 15/100\n",
            "82/82 [==============================] - 18s 217ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 16/100\n",
            "82/82 [==============================] - 17s 213ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 17/100\n",
            "82/82 [==============================] - 18s 223ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 18/100\n",
            "82/82 [==============================] - 17s 207ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 19/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 20/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 21/100\n",
            "82/82 [==============================] - 18s 218ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 22/100\n",
            "82/82 [==============================] - 19s 226ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 23/100\n",
            "82/82 [==============================] - 18s 223ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 24/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 25/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 26/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 27/100\n",
            "82/82 [==============================] - 18s 222ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 28/100\n",
            "82/82 [==============================] - 19s 225ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 29/100\n",
            "82/82 [==============================] - 18s 221ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 30/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 31/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 32/100\n",
            "82/82 [==============================] - 18s 215ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 33/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 34/100\n",
            "82/82 [==============================] - 18s 218ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 35/100\n",
            "82/82 [==============================] - 17s 204ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 36/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 37/100\n",
            "82/82 [==============================] - 18s 217ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 38/100\n",
            "82/82 [==============================] - 18s 224ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 39/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 40/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 41/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 42/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 43/100\n",
            "82/82 [==============================] - 19s 226ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 44/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 45/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 46/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 47/100\n",
            "82/82 [==============================] - 17s 204ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 48/100\n",
            "82/82 [==============================] - 18s 224ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 49/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 50/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 51/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 52/100\n",
            "82/82 [==============================] - 18s 218ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 53/100\n",
            "82/82 [==============================] - 19s 226ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 54/100\n",
            "82/82 [==============================] - 17s 205ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 55/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 56/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 57/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 58/100\n",
            "82/82 [==============================] - 19s 226ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 59/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 60/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 61/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 62/100\n",
            "82/82 [==============================] - 18s 221ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 63/100\n",
            "82/82 [==============================] - 19s 227ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 64/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 65/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 66/100\n",
            "82/82 [==============================] - 17s 204ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 67/100\n",
            "82/82 [==============================] - 18s 223ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 68/100\n",
            "82/82 [==============================] - 19s 225ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 69/100\n",
            "82/82 [==============================] - 17s 204ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 70/100\n",
            "82/82 [==============================] - 18s 221ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 71/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 72/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 73/100\n",
            "82/82 [==============================] - 18s 224ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 74/100\n",
            "82/82 [==============================] - 18s 219ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 75/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 76/100\n",
            "82/82 [==============================] - 18s 218ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 77/100\n",
            "82/82 [==============================] - 19s 226ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 78/100\n",
            "82/82 [==============================] - 17s 206ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 79/100\n",
            "82/82 [==============================] - 18s 220ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 80/100\n",
            "82/82 [==============================] - 18s 222ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 81/100\n",
            "82/82 [==============================] - 18s 221ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 82/100\n",
            "82/82 [==============================] - 18s 223ms/step - loss: nan - mae: nan - val_loss: nan - val_mae: nan\n",
            "Epoch 83/100\n",
            "43/82 [==============>...............] - ETA: 6s - loss: nan - mae: nan"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()   #Confusion: MaxLenght=100 should be dropped? Since words in a sentences/Para can exceed the limit"
      ],
      "metadata": {
        "id": "0zna3Mk-ks_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results Visualization**"
      ],
      "metadata": {
        "id": "FGaWXz-ddjng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.history.history\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot validation loss\n",
        "plt.plot(history['val_loss'], label='val_loss')\n",
        "plt.plot(history['loss'], label='train_loss')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n",
        "# Plot evaluation metrics\n",
        "plt.plot(history['mae'], label='train_mae')\n",
        "plt.plot(history['val_mae'], label='val_mae')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MUHxJAH_mI6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing Model**"
      ],
      "metadata": {
        "id": "cMC5BxtrdumL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = model.evaluate([padded_docs_test, features_test], target_test)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict([padded_docs_test, features_test])\n",
        "\n",
        "# Compute Cohen's kappa score\n",
        "kappa = cohen_kappa_score(np.round(predictions), target_test, weights='quadratic')\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test MAE:', test_mae)\n",
        "print('Cohen\\'s Kappa Score:', kappa)"
      ],
      "metadata": {
        "id": "ql8PHdR4drm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GridSearchCV** (Incomplete)"
      ],
      "metadata": {
        "id": "u5fHbkcqwpqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BiDirectional LSTM** (Incomplete)"
      ],
      "metadata": {
        "id": "weyBDkBMw42s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input, concatenate, Bidirectional\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define model parameters\n",
        "MAX_SEQ_LEN = 100\n",
        "EMBEDDING_DIM = 100\n",
        "DROPOUT_RATE = 0.5\n",
        "NUM_FEATURES = len(features_train[0])\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "embedding_matrix = {} # Load GloVe embeddings here\n",
        "\n",
        "# Define input layers\n",
        "input_text = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
        "input_features = Input(shape=(NUM_FEATURES,), dtype='float32')\n",
        "\n",
        "# Define embedding layer\n",
        "embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                            output_dim=EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQ_LEN,\n",
        "                            trainable=False)\n",
        "\n",
        "# Define bidirectional LSTM layer\n",
        "lstm_layer = Bidirectional(LSTM(units=64, activation='sigmoid'))\n",
        "\n",
        "# Connect input layers to embedding and LSTM layers\n",
        "text_embed = embedding_layer(input_text)\n",
        "text_lstm = lstm_layer(text_embed)\n",
        "\n",
        "# Concatenate LSTM output with input features\n",
        "concat_layer = concatenate([text_lstm, input_features])\n",
        "\n",
        "# Define dropout layer\n",
        "dropout_layer = Dropout(rate=DROPOUT_RATE)\n",
        "\n",
        "# Connect concat layer to dropout layer\n",
        "dropout_output = dropout_layer(concat_layer)\n",
        "\n",
        "# Define output layer\n",
        "output_layer = Dense(units=1, activation='linear')\n",
        "\n",
        "# Connect dropout output to output layer\n",
        "output = output_layer(dropout_output)\n",
        "\n",
        "# Define model with two inputs and one output\n",
        "model = tf.keras.Model(inputs=[input_text, input_features], outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Train model\n",
        "model.fit([padded_docs_train, features_train], target_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_split=VALIDATION_SPLIT)\n"
      ],
      "metadata": {
        "id": "VS2XtKlexpF2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
