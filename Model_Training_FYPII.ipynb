{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Rough Notes: 1-Combined Approach\n",
        "2- Ensemble of models\n",
        "3-Inter Intra Class Approach"
      ],
      "metadata": {
        "id": "0SGsTWX1Sg5n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ToDo:<br/>  1- Add TfIdf scores for prompt relevancy in dataset\n",
        "            2- Change Scaling to a better type\n",
        "            3- Log Model "
      ],
      "metadata": {
        "id": "t1f-zzGbm9t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Importing Packages**"
      ],
      "metadata": {
        "id": "Rvwsev4BDu3n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jZwjcsWDnp2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as ply\n",
        "from scipy.stats import zscore\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "import nltk\n",
        "import gensim.downloader as api\n",
        "from nltk.tokenize import word_tokenize, sent_tokenize\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.losses import mean_squared_error\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding,Masking,LSTM, GRU, Conv1D, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "from keras.preprocessing import sequence\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Embedding, SimpleRNN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Dataset Preparation**"
      ],
      "metadata": {
        "id": "MEeJW8ffGVER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "df_train01 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet01_Features.csv\", index_col =0)\n",
        "df_train02 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet02_Features.csv\", index_col =0)\n",
        "df_train03 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet03_Features.csv\", index_col =0)\n",
        "df_train04 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet04_Features.csv\", index_col =0)\n",
        "df_train05 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet05_Features.csv\", index_col =0)\n",
        "df_train06 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet06_Features.csv\", index_col =0)\n",
        "df_train07 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet07_Features.csv\", index_col =0)\n",
        "df_train08 = pd.read_csv(\"/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet08_Features.csv\", index_col =0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_DM_p6nGTLn",
        "outputId": "c9c232df-01b8-49da-9f46-d441edf938ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dfs = []\n",
        "for i in range(1, 9):\n",
        "    df = pd.read_csv(f'/content/drive/My Drive/IntelliTech-DataSet/Features/EssaySet0{i}_Features.csv')  # assuming the dataframes are stored as CSV files\n",
        "    scores_2d = [[score] for score in df['Total Score']]\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    df['Total Score'] = scaler.fit_transform(scores_2d)   #Changed from z-score to Minmax, z-score was giving negative range\n",
        "    df['Essay Set'] = i\n",
        "    dfs.append(df[['ID', 'Essay Set', 'Total Score', 'Preprocessed_Essay']])  # extract only the ID and Score columns and append to the list\n",
        "\n",
        "# concatenate the dataframes using pd.concat() and the loc accessor\n",
        "df_train = pd.concat(dfs, axis=0).reset_index(drop=True)\n",
        "df_train['Grade'] = df_train['Essay Set'].apply(lambda x: 8 if x == 1 or x == 5 else (7 if x == 7 else 10))\n",
        "df_train['Essay Type'] = df_train['Essay Set'].apply(lambda x: 'source dependent responses' if x in range(3,7) else 'persuasive / narrative  / expository')\n"
      ],
      "metadata": {
        "id": "DVhSCld-OivX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('punkt') \n",
        "#df_train['tokenized_text'] = df_train['Preprocessed_Essay'].apply(lambda x: [word_tokenize(sent.lower()) for sent in sent_tokenize(x)])\n",
        "# df_train['tokenized_text'] = df_train['tokenized_text'].apply(lambda x: ' '.join(x))\n",
        "df_train['tokenized_text'] = df_train['Preprocessed_Essay'].apply(lambda x: word_tokenize(x.lower()))\n",
        "df_train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "r2voIZhUmKR_",
        "outputId": "f4ecd9cd-1360-44f2-f92d-2d07a8d934c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID  Essay Set  Total Score  \\\n",
              "2108    3303          2     0.400000   \n",
              "12955  21603          8     0.500000   \n",
              "6054    9610          4     0.666667   \n",
              "8274   13020          5     0.750000   \n",
              "5589    9144          4     0.333333   \n",
              "\n",
              "                                      Preprocessed_Essay  Grade  \\\n",
              "2108   i m writing this paper today to talk about cen...     10   \n",
              "12955   those eyes  it was like i was looking out int...     10   \n",
              "6054   in the story “winter hibiscus” by minfong ho  ...     10   \n",
              "8274   the mood that the author created in this memoi...      8   \n",
              "5589   the author concludes the story with this parag...     10   \n",
              "\n",
              "                                 Essay Type  \\\n",
              "2108   persuasive / narrative  / expository   \n",
              "12955  persuasive / narrative  / expository   \n",
              "6054             source dependent responses   \n",
              "8274             source dependent responses   \n",
              "5589             source dependent responses   \n",
              "\n",
              "                                          tokenized_text  \n",
              "2108   [i, m, writing, this, paper, today, to, talk, ...  \n",
              "12955  [those, eyes, it, was, like, i, was, looking, ...  \n",
              "6054   [in, the, story, “, winter, hibiscus, ”, by, m...  \n",
              "8274   [the, mood, that, the, author, created, in, th...  \n",
              "5589   [the, author, concludes, the, story, with, thi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8a237b43-82ee-4567-a81f-3496c5640552\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay Set</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Essay Type</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>3303</td>\n",
              "      <td>2</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>i m writing this paper today to talk about cen...</td>\n",
              "      <td>10</td>\n",
              "      <td>persuasive / narrative  / expository</td>\n",
              "      <td>[i, m, writing, this, paper, today, to, talk, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12955</th>\n",
              "      <td>21603</td>\n",
              "      <td>8</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>those eyes  it was like i was looking out int...</td>\n",
              "      <td>10</td>\n",
              "      <td>persuasive / narrative  / expository</td>\n",
              "      <td>[those, eyes, it, was, like, i, was, looking, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6054</th>\n",
              "      <td>9610</td>\n",
              "      <td>4</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>in the story “winter hibiscus” by minfong ho  ...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[in, the, story, “, winter, hibiscus, ”, by, m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8274</th>\n",
              "      <td>13020</td>\n",
              "      <td>5</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>the mood that the author created in this memoi...</td>\n",
              "      <td>8</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[the, mood, that, the, author, created, in, th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5589</th>\n",
              "      <td>9144</td>\n",
              "      <td>4</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>the author concludes the story with this parag...</td>\n",
              "      <td>10</td>\n",
              "      <td>source dependent responses</td>\n",
              "      <td>[the, author, concludes, the, story, with, thi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8a237b43-82ee-4567-a81f-3496c5640552')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8a237b43-82ee-4567-a81f-3496c5640552 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8a237b43-82ee-4567-a81f-3496c5640552');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def para_to_sent(paragraph):\n",
        "    sentences = nltk.sent_tokenize(paragraph)\n",
        "    return sentences\n",
        "\n",
        "# Apply function to 'Essay' column of the dataframe\n",
        "df_train['Essay Sentences'] = df_train['Preprocessed_Essay'].apply(para_to_sent)"
      ],
      "metadata": {
        "id": "RraloOIq_abF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzgtDmch0dVE",
        "outputId": "bc919456-b7f0-4073-f50f-ecb09648c2c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12978, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['Essay Sentences']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOjWTpIGNaBY",
        "outputId": "60efa606-b039-4dd2-f662-05d2f6b80adb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12978,)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.to_csv(\"Dataset.csv\")"
      ],
      "metadata": {
        "id": "DNy6RguIRLLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Cleaning**\n",
        "Note: Change scaling type to something more inclined with non-linear data type and, remove NaNs from essay set04"
      ],
      "metadata": {
        "id": "AJTAFn6Wgb9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Finding the number of missing values in dataset\n",
        "missing = df_train.isnull().sum()\n",
        "print(missing)\n",
        "# Finding percentage of missing value\n",
        "total_cells = np.product(df_train.shape)\n",
        "percent = (missing.sum() / total_cells)*100\n",
        "percent  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VygHu8AdsGij",
        "outputId": "c790edaa-f6b6-42b1-ee8d-fa009b7aa0b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID                    0\n",
            "Essay Set             0\n",
            "Total Score           1\n",
            "Preprocessed_Essay    0\n",
            "Grade                 0\n",
            "Essay Type            0\n",
            "tokenized_text        0\n",
            "dtype: int64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0011007639301675364"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = df_train.dropna()"
      ],
      "metadata": {
        "id": "STwNpgdV0EOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zrj3V3jT0mdk",
        "outputId": "9c2be557-559b-41bf-d173-ae0dcb069332"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12977, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Word Embedding of Preprocessed Essay**\n",
        "\n"
      ],
      "metadata": {
        "id": "oGZehdxOgvTx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "glove_model = api.load(\"glove-wiki-gigaword-300\")"
      ],
      "metadata": {
        "id": "HY627c_FLLf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_glove_embeddings(text_data):\n",
        "    # Tokenize the text data\n",
        "    tokenized_data = [sentence.split() for sentence in text_data]\n",
        "\n",
        "    # Obtain the GloVe embeddings\n",
        "    embeddings = np.zeros((len(text_data), 300))\n",
        "\n",
        "    for i, sentence in enumerate(tokenized_data):\n",
        "        print(i  , sentence)\n",
        "        break\n",
        "        for word in sentence:\n",
        "            if word in glove_model.key_to_index:\n",
        "                embeddings[i] += glove_model[word]\n",
        "        embeddings[i] /= len(sentence)\n",
        "    return embeddings\n",
        "\n",
        "# Obtain the GloVe embeddings for the text data\n",
        "glove_embeddings = get_glove_embeddings(df['Preprocessed_Essay'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_irgyVvxOXO7",
        "outputId": "4eccf95a-e061-4ac4-89af-515e5969797b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 ['a', 'long', 'time', 'ago', 'when', 'i', 'was', 'in', 'third', 'grade', 'i', 'had', 'a', 'friend', 'who', 's', 'mom', 'was', 'in', 'a', 'bad', 'mood', 'she', 'never', 'laughed', 'and', 'she', 'never', 'smiled', 'every', 'time', 'i', 'saw', 'her', 'i', 'would', 'smile', 'at', 'her', 'and', 'all', 'she', 'would', 'do', 'was', 'frown', 'and', 'keep', 'walking', 'at', 'first', 'i', 'didn', 't', 'know', 'she', 'was', 'a', 'grouch', 'i', 'just', 'thought', 'she', 'didn', 't', 'like', 'me', 'or', 'something', 'when', 'told', 'me', 'his', 'mom', 'was', 'a', 'grouch', 'i', 'started', 'to', 'laugh', 'and', 'laugh', 'he', 'asked', 'me', 'what', 'was', 'so', 'funny', 'i', 'told', 'him', 'that', 'i', 'thought', 'his', 'mom', 'didn', 't', 'like', 'me', 'or', 'something', 'because', 'every', 'time', 'i', 'see', 'his', 'mom', 'i', 'would', 'smile', 'at', 'her', 'and', 'all', 'she', 'will', 'do', 'is', 'frown', 'and', 'walk', 'away', 'that', 'made', 'my', 'friend', 'laugh', 'we', 'were', 'cracking', 'up', 'so', 'hard', 'that', 'we', 'got', 'in', 'trouble', 'in', 'class', 'the', 'next', 'day', 'and', 'i', 'were', 'eating', 'lunch', 'at', 'school', 'when', 'he', 'says', 'to', 'me', 'lt', 'hey', 'your', 'pretty', 'good', 'at', 'making', 'people', 'laugh', 'gt', 'i', 'said', 'lt', 'no', 'i', 'am', 'not', 'my', 'jokesare', 'horrible', 'gt', 'he', 'said', 'lt', 'caps', 'lets', 'put', 'them', 'to', 'the', 'test', 'go', 'up', 'to', 'some', 'one', 'new', 'to', 'this', 'school', 'gt', 'i', 'said', 'so', 'we', 'went', 'around', 'the', 'whole', 'school', 'looking', 'for', 'a', 'new', 'student', 'unfortunately', 'we', 'couldn', 't', 'find', 'one', 'we', 'heard', 'the', 'bell', 'ring', 'and', 'we', 'ran', 'to', 'our', 'class', 'we', 'sat', 'in', 'the', 'back', 'of', 'the', 'classroom', 'its', 'only', 'and', 'i', 'and', 'anempty', 'seat', 'between', 'us', 'we', 'were', 'excited', 'because', 'our', 'teacher', 'was', 'going', 'to', 'show', 'us', 'a', 'movie', 'got', 'the', 'front', 'of', 'the', 'room', 'andclass', 'today', 'i', 'have', 'an', 'announcement', 'we', 'have', 'a', 'new', 'student', 'in', 'our', 'class', 'say', 'hello', 'to', 'walked', 'through', 'the', 'door', 'told', 'shecould', 'sit', 'in', 'the', 'back', 'in', 'between', 'and', 'i', 'she', 'sat', 'down', 'turned', 'to', 'the', 'both', 'of', 'us', 'and', 'said', 'hello', 'gave', 'me', 'a', 'look', 'that', 'said', 'tell', 'her', 'the', 'joke', 'and', 'him', 'a', 'thumbs', 'up', 'i', 'turned', 'to', 'and', 'said', 'hi', 'i', 'm', 'do', 'you', 'want', 'to', 'hear', 'a', 'joke', 'said', 'yeah', 'sure', 'i', 'started', 'lt', 'caps', 'knockshe', 'said', 'lt', 'who', 's', 'therei', 'said', 'lt', 'booshe', 'said', 'lt', 'boo', 'who', 'i', 'said', 'lt', 'oh', 'don', 't', 'cry', 'i', 'am', 'right', 'here', 'gt', 'at', 'first', 'she', 'didn', 't', 'laugh', 'because', 'she', 'didn', 't', 'get', 'it', 'but', 'duringthe', 'middle', 'of', 'the', 'movie', 'she', 'said', 'lt', 'ohhhh', 'i', 'get', 'itand', 'she', 'started', 'to', 'laugh', 'turned', 'to', 'me', 'and', 'said', 'lt', 'i', 'told', 'you', 'so', 'gt', 'got', 'this', 'crazy', 'idea', 'that', 'if', 'i', 'spent', 'the', 'night', 'at', 'his', 'house', 'that', 'i', 'could', 'make', 'his', 'mom', 'laugh', 'or', 'at', 'least', 'make', 'her', 'smile', 'i', 'said', 'lt', 'caps', 'sounds', 'like', 'a', 'plan', 'gt', 'i', 'asked', 'mt', 'mom', 'if', 'it', 'was', 'if', 'i', 'could', 'spend', 'the', 'night', 'at', 'house', 'she', 'said', 'lt', 'yeah', 'just', 'make', 'sure', 'its', 'with', 'his', 'mom', 'gt', 'asked', 'his', 'mom', 'she', 'said', 'it', 'was', 'when', 'i', 'got', 'to', 'house', 'the', 'first', 'thing', 'we', 'did', 'was', 'play', 'video', 'games', 'when', 'it', 'was', 'dinner', 'time', 'we', 'all', 'sat', 'down', 'at', 'the', 'table', 'to', 'eat', 'and', 'i', 'were', 'on', 'one', 'side', 'and', 'his', 'parents', 'on', 'the', 'other', 'when', 'we', 'started', 'eating', 'told', 'me', 'to', 'tell', 'the', 'joke', 'to', 'his', 'parents', 'i', 'said', 'so', 'i', 'said', 'to', 'them', 'lt', 'caps', 'replied', 'lt', 'who', 's', 'therei', 'said', 'lt', 'boothey', 'said', 'lt', 'boo', 'who', 'i', 'said', 'lt', 'oh', 'don', 't', 'cry', 'i', 'am', 'right', 'here', 'gt', 'his', 'parents', 'started', 'to', 'laugh', 'and', 'laugh', 'and', 'they', 'keptlaughing', 'for', 'like', 'five', 'minutes', 'turned', 'to', 'me', 'and', 'yelled', 'it', 'worked', 'his', 'mom', 'asked', 'what', 'worked', 'explained', 'everything', 'to', 'them', 'his', 'mom', 'told', 'usthat', 'her', 'mom', 'had', 'recently', 'died', 'and', 'that', 's', 'why', 'she', 'was', 'in', 'a', 'bad', 'mood', 'after', 'dinner', 'we', 'went', 'to', 'bed', 'and', 'fell', 'asleep', 'the', 'next', 'morning', 'when', 'my', 'mom', 'came', 'to', 'pick', 'me', 'up', 'she', 'asked', 'me', 'how', 'the', 'sleep', 'over', 'went', 'i', 'said', 'it', 'was', 'fun', 'i', 'made', 'people', 'laugh', 'she', 'said', 'but', 'laughter', 'isn', 't', 'going', 'to', 'help', 'you', 'clean', 'your', 'roomall', 'i', 'could', 'say', 'was', 'gosh', 'darn', 'it', 'fin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings.shape"
      ],
      "metadata": {
        "id": "xbXSQpZAOlS_",
        "outputId": "f1b97349-072d-4144-b5b4-eb3ed446de98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to obtain the GloVe embeddings\n",
        "def get_glove_embeddings(text_data):\n",
        "    # Flatten the list of lists\n",
        "    flattened_data = [sentence for sublist in text_data for sentence in sublist]\n",
        "    \n",
        "    # Join the sentences with a space character\n",
        "    joined_data = [' '.join(sentence) for sentence in flattened_data]\n",
        "\n",
        "    # Obtain the GloVe embeddings\n",
        "    embeddings = np.zeros((len(joined_data), 300))  \n",
        "\n",
        "    for i, sentence in enumerate(joined_data):\n",
        "        for word in sentence.split():\n",
        "            if word in glove_model.key_to_index:\n",
        "                embeddings[i] += glove_model[word]\n",
        "        embeddings[i] /= len(sentence.split())\n",
        "    return embeddings\n",
        "\n",
        "# Obtain the GloVe embeddings for the text data\n",
        "glove_embeddings = get_glove_embeddings(df['Preprocessed_Essay'])\n"
      ],
      "metadata": {
        "id": "jK3Emdu2aiju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5eaa30d-546d-412c-a6d9-5393c4b5393a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-eec80bb4efe1>:16: RuntimeWarning: invalid value encountered in true_divide\n",
            "  embeddings[i] /= len(sentence.split())\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "glove_embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xssafoaANSIV",
        "outputId": "ac81d7c1-d44d-4c63-e855-04782e1e1ce0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(723, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Categorical Features Encoding**"
      ],
      "metadata": {
        "id": "5dCJ_9jA2IW9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 0 for persuasive / narrative / expository and 1 for source dependent responses\n",
        "df_train['Essay Type'] = df_train['Essay Type'].str.replace(\n",
        "    'persuasive / narrative  / expository', '0', case=True, regex=False)\n",
        "\n",
        "df_train['Essay Type'] = df_train['Essay Type'].str.replace(\n",
        "    'source dependent responses', '1', case=True, regex=False)\n",
        "\n",
        "# Ordinal Encoding\n",
        "oe = OrdinalEncoder(categories=[['7', '8', '10']])   # encoded as 0, 1 and 2\n",
        "df_train['Grade'] = oe.fit_transform(df_train[['Grade']]).astype(int)"
      ],
      "metadata": {
        "id": "bRmLxSbe2Qlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.sample(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "eVJtvhCY9x7h",
        "outputId": "ba3ce67d-ae0c-439f-8cfd-05beffeaebc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         ID  Essay Set  Total Score  \\\n",
              "8302  13048          5     0.500000   \n",
              "4125   6521          3     0.666667   \n",
              "2779   3974          2     0.200000   \n",
              "7350  12096          5     0.250000   \n",
              "9890  15838          6     0.500000   \n",
              "\n",
              "                                     Preprocessed_Essay  Grade Essay Type  \\\n",
              "8302  the mood that the author was trying to create ...      1          1   \n",
              "4125  the features of the setting affect the cyclist...      2          1   \n",
              "2779  i do not think that censoship has a ightful pl...      2          0   \n",
              "7350  the mood of the story is some what sad and som...      1          1   \n",
              "9890  the architects of the empire state building ra...      2          1   \n",
              "\n",
              "                                         tokenized_text  \n",
              "8302  [the, mood, that, the, author, was, trying, to...  \n",
              "4125  [the, features, of, the, setting, affect, the,...  \n",
              "2779  [i, do, not, think, that, censoship, has, a, i...  \n",
              "7350  [the, mood, of, the, story, is, some, what, sa...  \n",
              "9890  [the, architects, of, the, empire, state, buil...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2372fae1-9863-434f-a29d-bbd3cf844cb7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay Set</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Grade</th>\n",
              "      <th>Essay Type</th>\n",
              "      <th>tokenized_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8302</th>\n",
              "      <td>13048</td>\n",
              "      <td>5</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>the mood that the author was trying to create ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[the, mood, that, the, author, was, trying, to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4125</th>\n",
              "      <td>6521</td>\n",
              "      <td>3</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>the features of the setting affect the cyclist...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[the, features, of, the, setting, affect, the,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2779</th>\n",
              "      <td>3974</td>\n",
              "      <td>2</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>i do not think that censoship has a ightful pl...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>[i, do, not, think, that, censoship, has, a, i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7350</th>\n",
              "      <td>12096</td>\n",
              "      <td>5</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>the mood of the story is some what sad and som...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>[the, mood, of, the, story, is, some, what, sa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9890</th>\n",
              "      <td>15838</td>\n",
              "      <td>6</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>the architects of the empire state building ra...</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>[the, architects, of, the, empire, state, buil...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2372fae1-9863-434f-a29d-bbd3cf844cb7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2372fae1-9863-434f-a29d-bbd3cf844cb7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2372fae1-9863-434f-a29d-bbd3cf844cb7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ybVF8RwlFmR7",
        "outputId": "2bd6fa65-3649-46f1-8350-5e256572b87f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 12978 entries, 0 to 12977\n",
            "Data columns (total 7 columns):\n",
            " #   Column              Non-Null Count  Dtype  \n",
            "---  ------              --------------  -----  \n",
            " 0   ID                  12978 non-null  int64  \n",
            " 1   Essay Set           12978 non-null  int64  \n",
            " 2   Total Score         12977 non-null  float64\n",
            " 3   Preprocessed_Essay  12978 non-null  object \n",
            " 4   Grade               12978 non-null  int64  \n",
            " 5   Essay Type          12978 non-null  object \n",
            " 6   tokenized_text      12978 non-null  object \n",
            "dtypes: float64(1), int64(3), object(3)\n",
            "memory usage: 709.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Implementation**"
      ],
      "metadata": {
        "id": "-C2pPnTmgz-o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 10000\n",
        "embedding_dim = 16\n",
        "max_length = 100\n",
        "trunc_type='post' # remove sentences if they reach the max_lenght\n",
        "padding_type='post' #padding after sentences\n",
        "oov_tok = \"<OOV>\"   #placeholder for new words in padding\n",
        "training_size = 20000\n",
        "DROPOUT_RATE = 0.2"
      ],
      "metadata": {
        "id": "4_YHLSyIhAsB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Encoded Input Text**"
      ],
      "metadata": {
        "id": "SJt8dmb1a3jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tk = Tokenizer(num_words=vocab_size)\n",
        "tokenized_text = df_train['tokenized_text'].values.tolist()\n",
        "flatten_text = [word for sent in tokenized_text for word in sent]\n",
        "joined_text = ' '.join(flatten_text)\n",
        "tk.fit_on_texts([joined_text])\n",
        "\n",
        "encoded_essay_train = tk.texts_to_sequences(tokenized_text)\n",
        "padded_essay_train = pad_sequences(encoded_essay_train, maxlen=max_length, padding=padding_type)   #Input Text"
      ],
      "metadata": {
        "id": "vHt-LmlQldxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Input Features**"
      ],
      "metadata": {
        "id": "32Z0FDQkB7qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "feature_cols = ['Essay Set', 'Essay Type','Grade']   #add tf-idf\n",
        "features_df = df_train[feature_cols]\n",
        "# Convert features DataFrame to NumPy array\n",
        "features_train = features_df.values\n",
        "\n",
        "print(features_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcBaIYCiCDjr",
        "outputId": "9a8ec630-cc37-4d85-8e46-fd650a623b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 '0' 1]\n",
            " [1 '0' 1]\n",
            " [1 '0' 1]\n",
            " ...\n",
            " [8 '0' 2]\n",
            " [8 '0' 2]\n",
            " [8 '0' 2]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Target Variable**"
      ],
      "metadata": {
        "id": "t7BL4MGxZ1b2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "target_train = df_train['Total Score']"
      ],
      "metadata": {
        "id": "JowbpGuFZ4r5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Vanilla LSTM**"
      ],
      "metadata": {
        "id": "h-Ks12cWg4kj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################## Try One ##########################################################\n",
        "\n",
        "# model = tf.keras.Sequential([\n",
        "#     tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
        "#     tf.keras.layers.LSTM(units=64),  #default activation is relu\n",
        "#     tf.keras.layers.Dense(units=1, activation='linear')\n",
        "# ])\n",
        "# model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mae'])"
      ],
      "metadata": {
        "id": "H1tKD2eRi2OP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################# Try Two #############################################################\n",
        "\n",
        "# model = Sequential()\n",
        "# model.add(Embedding(input_dim=embedding_matrix.shape[0],\n",
        "#                     output_dim=EMBEDDING_DIM,\n",
        "#                     weights=[embedding_matrix],\n",
        "#                     input_length=MAX_SEQ_LEN,\n",
        "#                     trainable=False))\n",
        "# model.add(LSTM(units=64, activation='sigmoid'))\n",
        "# model.add(Dropout(rate=DROPOUT_RATE))\n",
        "# model.add(Dense(units=1, activation='linear'))\n"
      ],
      "metadata": {
        "id": "fHql1EhGBXeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IF NEEDED\n",
        "def cohen_kappa_with_quadratic_weights(y_true, y_pred):\n",
        "    y_true_classes = tf.round(y_true)\n",
        "    y_pred_classes = tf.round(y_pred)\n",
        "    kappa = cohen_kappa_score(y_true_classes, y_pred_classes, weights='quadratic')\n",
        "    return kappa"
      ],
      "metadata": {
        "id": "ey3c6Q4zpNbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vanilla_lstm(MAX_SEQ_LEN = 100, EMBEDDING_DIM = 100, DROPOUT_RATE = 0.2,EPOCHS = 200, BATCH_SIZE = 2048 ,VALIDATION_SPLIT = 0.2):   \n",
        "# NOTE: Modify the function so it can accept parameters for later use in gridsearch cv  and bayesian and then make one function for bidriectional, add callback line that bahram told and plot the reslts like in tensorflow.ipynb\n",
        " \n",
        "  np.random.seed(42)\n",
        "  tf.random.set_seed(42)\n",
        "  NUM_FEATURES = len(features_train[0])\n",
        "  # Load pre-trained GloVe embeddings\n",
        "  embedding_matrix = {} \n",
        "  # Define input layers\n",
        "  input_text = Input(shape=(MAX_SEQ_LEN,), dtype='int32')   # Padded Essay Tokens\n",
        "  input_features = Input(shape=(NUM_FEATURES,), dtype='float32') # Input Features\n",
        "\n",
        "  # Define embedding layer\n",
        "  embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                              output_dim=EMBEDDING_DIM,\n",
        "                              weights=[embedding_matrix],\n",
        "                              input_length=MAX_SEQ_LEN,\n",
        "                              trainable=False)\n",
        "  \n",
        "  # Define LSTM layer\n",
        "  lstm_layer = LSTM(units=64, activation='sigmoid')\n",
        "  # Connect input layers to embedding and LSTM layers\n",
        "  text_embed = embedding_layer(input_text)\n",
        "  text_lstm = lstm_layer(text_embed)\n",
        "  # Concatenate LSTM output with input features\n",
        "  concat_layer = concatenate([text_lstm, input_features])\n",
        "  # Define dropout layer\n",
        "  dropout_layer = Dropout(rate=DROPOUT_RATE)\n",
        "  # Connect concat layer to dropout layer\n",
        "  dropout_output = dropout_layer(concat_layer)\n",
        "  # Define output layer\n",
        "  output_layer = Dense(units=1, activation='linear')   #try it with sigmoid, relu, and tanh\n",
        "  # Connect dropout output to output layer\n",
        "  output = output_layer(dropout_output)\n",
        "\n",
        "  # Define model with two inputs and one output\n",
        "  model = tf.keras.Model(inputs=[input_text, input_features], outputs=output)\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(optimizer='adam',   #try sgd, bgd,RMSprop\n",
        "                loss='mse',\n",
        "                metrics=['mae'])\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "C_eihi0Mt4MK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Training Model**"
      ],
      "metadata": {
        "id": "exzTFpx2cDxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 200 \n",
        "BATCH_SIZE = 2048 \n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "lstm_model = build_vanilla_lstm(MAX_SEQ_LEN = 100, EMBEDDING_DIM = 100, DROPOUT_RATE = 0.2,EPOCHS = 200, BATCH_SIZE = 2048 ,VALIDATION_SPLIT = 0.2)\n",
        "lstm_model.fit([padded_essay_train, features_train], target_train,\n",
        "            epochs=EPOCHS,\n",
        "            batch_size=BATCH_SIZE,\n",
        "            validation_split=VALIDATION_SPLIT)"
      ],
      "metadata": {
        "id": "z_D6a6ZIcHOr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_model.summary()   #Confusion: MaxLenght=100 should be dropped? Since words in a sentences/Para can exceed the limit"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zna3Mk-ks_t",
        "outputId": "a862b8b5-30cf-4228-9837-bc30ca205bf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 16)           160000    \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                20736     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 180,801\n",
            "Trainable params: 180,801\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Results Visualization**"
      ],
      "metadata": {
        "id": "FGaWXz-ddjng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = lstm_model.history.history\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot validation loss\n",
        "plt.plot(history['val_loss'], label='val_loss')\n",
        "plt.plot(history['loss'], label='train_loss')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()\n",
        "\n",
        "# Plot evaluation metrics\n",
        "plt.plot(history['mae'], label='train_mae')\n",
        "plt.plot(history['val_mae'], label='val_mae')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MUHxJAH_mI6L",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "48a7ca83-e02d-4532-f737-e216e334303e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-44-05a7a50eb8cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlstm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plot validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'lstm_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Testing Model**"
      ],
      "metadata": {
        "id": "cMC5BxtrdumL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_mae = model.evaluate([padded_docs_test, features_test], target_test)\n",
        "\n",
        "# Make predictions on test data\n",
        "predictions = model.predict([padded_docs_test, features_test])\n",
        "\n",
        "# Compute Cohen's kappa score\n",
        "kappa = cohen_kappa_score(np.round(predictions), target_test, weights='quadratic')\n",
        "\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test MAE:', test_mae)\n",
        "print('Cohen\\'s Kappa Score:', kappa)"
      ],
      "metadata": {
        "id": "ql8PHdR4drm2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **GridSearchCV** (Incomplete)"
      ],
      "metadata": {
        "id": "u5fHbkcqwpqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BiDirectional LSTM** (Incomplete)"
      ],
      "metadata": {
        "id": "weyBDkBMw42s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout, Embedding, Input, concatenate, Bidirectional\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define model parameters\n",
        "MAX_SEQ_LEN = 100\n",
        "EMBEDDING_DIM = 100\n",
        "DROPOUT_RATE = 0.2\n",
        "NUM_FEATURES = len(features_train[0])\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 2048\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# Load pre-trained GloVe embeddings\n",
        "embedding_matrix = {} # Load GloVe embeddings here\n",
        "\n",
        "# Define input layers\n",
        "input_text = Input(shape=(MAX_SEQ_LEN,), dtype='int32')\n",
        "input_features = Input(shape=(NUM_FEATURES,), dtype='float32')\n",
        "\n",
        "# Define embedding layer\n",
        "embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
        "                            output_dim=EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQ_LEN,\n",
        "                            trainable=False)\n",
        "\n",
        "# Define bidirectional LSTM layer\n",
        "lstm_layer = Bidirectional(LSTM(units=64, activation='sigmoid'))\n",
        "\n",
        "# Connect input layers to embedding and LSTM layers\n",
        "text_embed = embedding_layer(input_text)\n",
        "text_lstm = lstm_layer(text_embed)\n",
        "\n",
        "# Concatenate LSTM output with input features\n",
        "concat_layer = concatenate([text_lstm, input_features])\n",
        "\n",
        "# Define dropout layer\n",
        "dropout_layer = Dropout(rate=DROPOUT_RATE)\n",
        "\n",
        "# Connect concat layer to dropout layer\n",
        "dropout_output = dropout_layer(concat_layer)\n",
        "\n",
        "# Define output layer\n",
        "output_layer = Dense(units=1, activation='linear')\n",
        "\n",
        "# Connect dropout output to output layer\n",
        "output = output_layer(dropout_output)\n",
        "\n",
        "# Define model with two inputs and one output\n",
        "model = tf.keras.Model(inputs=[input_text, input_features], outputs=output)\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='mse',\n",
        "              metrics=['mae'])\n",
        "\n",
        "# Train model\n",
        "model.fit([padded_docs_train, features_train], target_train,\n",
        "          epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE,\n",
        "          validation_split=VALIDATION_SPLIT)\n"
      ],
      "metadata": {
        "id": "VS2XtKlexpF2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}