{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## **Installing Packages**"
      ],
      "metadata": {
        "id": "t5wewbNqz8cj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PpP642wc8kXg",
        "outputId": "4a047e47-f019-4312-bb9f-0d2c615cdef0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.7/dist-packages (from textblob) (3.7)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (2022.6.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (4.64.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.97\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.23.1-py3-none-any.whl (5.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.3 MB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.10.0\n",
            "  Downloading huggingface_hub-0.10.1-py3-none-any.whl (163 kB)\n",
            "\u001b[K     |████████████████████████████████| 163 kB 20.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 44.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.10.1 tokenizers-0.13.1 transformers-4.23.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting language-tool-python\n",
            "  Downloading language_tool_python-2.7.1-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from language-tool-python) (4.64.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from language-tool-python) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->language-tool-python) (3.0.4)\n",
            "Installing collected packages: language-tool-python\n",
            "Successfully installed language-tool-python-2.7.1\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob\n",
        "!pip install sentencepiece  \n",
        "!pip install transformers\n",
        "!pip install language-tool-python"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Restart Runtime after installing "
      ],
      "metadata": {
        "id": "oFW9msHtUg-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Importing Packages**"
      ],
      "metadata": {
        "id": "-CLigcFJ0ABg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzNPxq8X8bYG",
        "outputId": "00a72ed8-388d-417f-e346-808a4d7b4403"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "import nltk \n",
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sn \n",
        "from textblob import Word\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from nltk.tag import pos_tag\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "nltk.download('stopwords')\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Reading Data From Google Drive**"
      ],
      "metadata": {
        "id": "B9QmvZ2KGsPO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "I7JhmdSg8swA",
        "outputId": "82c2fb3a-1240-411a-f8c8-dd71cf4154a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                                              Essay  Rater_1 Score  \\\n",
              "0   1  Dear local newspaper, I think effects computer...            4.0   \n",
              "1   2  Dear @CAPS1 @CAPS2, I believe that using compu...            5.0   \n",
              "2   3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...            4.0   \n",
              "3   4  Dear Local Newspaper, @CAPS1 I have found that...            5.0   \n",
              "4   5  Dear @LOCATION1, I know having computers has a...            4.0   \n",
              "\n",
              "   Rater_2 Score  Total Score  \n",
              "0            4.0          8.0  \n",
              "1            4.0          9.0  \n",
              "2            3.0          7.0  \n",
              "3            5.0         10.0  \n",
              "4            4.0          8.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ccb0c39d-4030-40f8-a15d-e414abad1217\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ccb0c39d-4030-40f8-a15d-e414abad1217')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ccb0c39d-4030-40f8-a15d-e414abad1217 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ccb0c39d-4030-40f8-a15d-e414abad1217');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "Data_Essay_01 = pd.read_csv(\"/content/drive/MyDrive/IntelliTech-DataSet/EssaySet01.csv\")\n",
        "Data_Essay_01.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X4CyChIa3hm3"
      },
      "source": [
        "# **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Essay Pre Processing**"
      ],
      "metadata": {
        "id": "0d9vjiulC7aL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Remove_NER(Essay):\n",
        "  \"\"\"\n",
        "    Removes Named Entity Recognition (NER) from each essay\n",
        "\n",
        "    Args:\n",
        "      Sentence: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      String\n",
        "\n",
        "  \"\"\"\n",
        "  return ' '.join (word for word in Essay.split(' ') if not word.startswith('@'))\n",
        "\n",
        "def Remove_Punctuations(sentence):\n",
        "  \"\"\"\n",
        "    Removes punctuations from text\n",
        "    Args:\n",
        "      sentence: Essay of each student\n",
        "    \n",
        "    Returns: \n",
        "      String\n",
        "  \"\"\"\n",
        "  punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
        "  newSentence = \"\"\n",
        "  for word in sentence:\n",
        "      if (word in punctuations):\n",
        "          newSentence = newSentence + \" \"\n",
        "      else: \n",
        "          newSentence = newSentence + word\n",
        "  return newSentence\n",
        "\n",
        "def LowerCase_Words(Essay):\n",
        "  \"\"\"\n",
        "    Lower case all the words in an essay\n",
        "\n",
        "    Args:\n",
        "      Sentence: Essay of each student\n",
        "    \n",
        "    Returns: \n",
        "      String\n",
        "  \"\"\"\n",
        "  return re.sub('[0-9]+','', Essay).lower() \n",
        "\n",
        "def Tokenize_Essay(Essay):\n",
        "    \"\"\"\n",
        "      Create Tokens of each Essay\n",
        "\n",
        "      Args:\n",
        "        Essay: Essay of each student\n",
        "      \n",
        "      Returns: \n",
        "        String\n",
        "    \"\"\"\n",
        "    Preprocessed = Remove_Punctuations(Essay)\n",
        "    return \" \".join(word_tokenize(Preprocessed))\n",
        "\n",
        "def Remove_White_Spaces(Essay):\n",
        "  \"\"\"\n",
        "    Removes Extra White Spaces\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student\n",
        "    \n",
        "    Returns: \n",
        "      String\n",
        "  \"\"\"\n",
        "  return \" \".join(Essay.split())"
      ],
      "metadata": {
        "id": "6qLIKn4LC7-_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Removing NERs, Punctuations and Lower Casing"
      ],
      "metadata": {
        "id": "A0qjHkwRH7FS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01['Preprocessed_Essay'] = Data_Essay_01['Essay'].apply(Remove_NER)\n",
        "Data_Essay_01['Preprocessed_Essay'] = Data_Essay_01['Preprocessed_Essay'].apply(Tokenize_Essay)\n",
        "Data_Essay_01.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "mxsK-yprDcfV",
        "outputId": "dea8be96-834d-4c21-b44d-4332f9cd947f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   ID                                              Essay  Rater_1 Score  \\\n",
              "0   1  Dear local newspaper, I think effects computer...            4.0   \n",
              "1   2  Dear @CAPS1 @CAPS2, I believe that using compu...            5.0   \n",
              "2   3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...            4.0   \n",
              "3   4  Dear Local Newspaper, @CAPS1 I have found that...            5.0   \n",
              "4   5  Dear @LOCATION1, I know having computers has a...            4.0   \n",
              "\n",
              "   Rater_2 Score  Total Score  \\\n",
              "0            4.0          8.0   \n",
              "1            4.0          9.0   \n",
              "2            3.0          7.0   \n",
              "3            5.0         10.0   \n",
              "4            4.0          8.0   \n",
              "\n",
              "                                  Preprocessed_Essay  \n",
              "0  Dear local newspaper I think effects computers...  \n",
              "1  Dear I believe that using computers will benef...  \n",
              "2  Dear More and more people use computers but no...  \n",
              "3  Dear Local Newspaper I have found that many ex...  \n",
              "4  Dear I know having computers has a positive ef...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54ee045b-7104-43ed-85f1-01cfcd2053f0\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear local newspaper I think effects computers...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear I believe that using computers will benef...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear More and more people use computers but no...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear I know having computers has a positive ef...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54ee045b-7104-43ed-85f1-01cfcd2053f0')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54ee045b-7104-43ed-85f1-01cfcd2053f0 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54ee045b-7104-43ed-85f1-01cfcd2053f0');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Basic Count Features**"
      ],
      "metadata": {
        "id": "pmuQWvabiYC-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Counting Sentences per Essay"
      ],
      "metadata": {
        "id": "9jYVbje0Ex_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "nV3ttAkblI57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3a12dcd3-fa6b-402d-e6a1-2c8683cb6397"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID                                              Essay  Rater_1 Score  \\\n",
              "0        1  Dear local newspaper, I think effects computer...            4.0   \n",
              "1        2  Dear @CAPS1 @CAPS2, I believe that using compu...            5.0   \n",
              "2        3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...            4.0   \n",
              "3        4  Dear Local Newspaper, @CAPS1 I have found that...            5.0   \n",
              "4        5  Dear @LOCATION1, I know having computers has a...            4.0   \n",
              "...    ...                                                ...            ...   \n",
              "1778  1783  Dear @CAPS1, @CAPS2 several reasons on way I t...            4.0   \n",
              "1779  1784  Do a adults and kids spend to much time on the...            3.0   \n",
              "1780  1785  My opinion is that people should have computer...            4.0   \n",
              "1781  1786  Dear readers, I think that its good and bad to...            1.0   \n",
              "1782  1787  Dear - Local Newspaper I agree thats computers...            4.0   \n",
              "\n",
              "      Rater_2 Score  Total Score  \\\n",
              "0               4.0          8.0   \n",
              "1               4.0          9.0   \n",
              "2               3.0          7.0   \n",
              "3               5.0         10.0   \n",
              "4               4.0          8.0   \n",
              "...             ...          ...   \n",
              "1778            4.0          8.0   \n",
              "1779            4.0          7.0   \n",
              "1780            4.0          8.0   \n",
              "1781            1.0          2.0   \n",
              "1782            3.0          7.0   \n",
              "\n",
              "                                     Preprocessed_Essay  Sent_Count  \n",
              "0     Dear local newspaper I think effects computers...          16  \n",
              "1     Dear I believe that using computers will benef...          20  \n",
              "2     Dear More and more people use computers but no...          14  \n",
              "3     Dear Local Newspaper I have found that many ex...          27  \n",
              "4     Dear I know having computers has a positive ef...          30  \n",
              "...                                                 ...         ...  \n",
              "1778  Dear several reasons on way I that advances in...          21  \n",
              "1779  Do a adults and kids spend to much time on the...          18  \n",
              "1780  My opinion is that people should have computer...          18  \n",
              "1781  Dear readers I think that its good and bad to ...           1  \n",
              "1782  Dear Local Newspaper I agree thats computers a...          18  \n",
              "\n",
              "[1783 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1b932874-2b20-49ac-b8d3-5bdfcfb0d204\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear local newspaper I think effects computers...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear I believe that using computers will benef...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear More and more people use computers but no...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Dear Local Newspaper I have found that many ex...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear I know having computers has a positive ef...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1778</th>\n",
              "      <td>1783</td>\n",
              "      <td>Dear @CAPS1, @CAPS2 several reasons on way I t...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear several reasons on way I that advances in...</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1779</th>\n",
              "      <td>1784</td>\n",
              "      <td>Do a adults and kids spend to much time on the...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Do a adults and kids spend to much time on the...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1780</th>\n",
              "      <td>1785</td>\n",
              "      <td>My opinion is that people should have computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>My opinion is that people should have computer...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1781</th>\n",
              "      <td>1786</td>\n",
              "      <td>Dear readers, I think that its good and bad to...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>Dear readers I think that its good and bad to ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1782</th>\n",
              "      <td>1787</td>\n",
              "      <td>Dear - Local Newspaper I agree thats computers...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear Local Newspaper I agree thats computers a...</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1783 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1b932874-2b20-49ac-b8d3-5bdfcfb0d204')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1b932874-2b20-49ac-b8d3-5bdfcfb0d204 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1b932874-2b20-49ac-b8d3-5bdfcfb0d204');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "def Sentence_Count(Essay):\n",
        "    \"\"\"\n",
        "    Counts sentences in an essay\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      int\n",
        "      \n",
        "  \"\"\"\n",
        "    sentence_no = nltk.sent_tokenize(Essay)\n",
        "    return len(sentence_no)\n",
        "  \n",
        "Data_Essay_01['Sent_Count'] = Data_Essay_01['Essay'].apply(Sentence_Count)\n",
        "Data_Essay_01"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Counting Words per Essay"
      ],
      "metadata": {
        "id": "6VY92aM5E00E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Observation:** These word count are more than the original count coz of nltk tokenization. Punctations are treated as seperate words.\n"
      ],
      "metadata": {
        "id": "YxGrgzWIFzPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Word_Count(Essay):\n",
        "  \"\"\"\n",
        "    Counts words in an essay\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      int\n",
        "      \n",
        "  \"\"\"\n",
        "  #cleaned_essay = re.sub('[^a-zA-Z]','',essay) \n",
        "  word_no = nltk.word_tokenize(Essay)\n",
        "  return len(word_no)\n",
        " \n",
        "Data_Essay_01['Word_Count'] = Data_Essay_01['Essay'].apply(Word_Count)\n",
        "Data_Essay_01.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7OPVrqpAdLec",
        "outputId": "1fa15d29-0576-47dc-a05e-262185e68ef5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID                                              Essay  Rater_1 Score  \\\n",
              "630  633  Dear local newspaper, Computers have a good ef...            4.0   \n",
              "\n",
              "     Rater_2 Score  Total Score  \\\n",
              "630            4.0          8.0   \n",
              "\n",
              "                                    Preprocessed_Essay  Sent_Count  Word_Count  \n",
              "630  Dear local newspaper Computers have a good eff...          22         436  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-60cbb3b6-5088-4d89-99f0-c7cf85b22921\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>630</th>\n",
              "      <td>633</td>\n",
              "      <td>Dear local newspaper, Computers have a good ef...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear local newspaper Computers have a good eff...</td>\n",
              "      <td>22</td>\n",
              "      <td>436</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-60cbb3b6-5088-4d89-99f0-c7cf85b22921')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-60cbb3b6-5088-4d89-99f0-c7cf85b22921 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-60cbb3b6-5088-4d89-99f0-c7cf85b22921');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Counting Characters per Essay"
      ],
      "metadata": {
        "id": "LCGMHv_yE29j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Char_Count(Essay):\n",
        "  \"\"\"\n",
        "    Counts characters in an essay\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      int\n",
        "      \n",
        "  \"\"\"\n",
        "  #cleaned_essay = re.sub('[^a-zA-Z]',' ',Essay) \n",
        "  return len([character for character in Essay])\n",
        "\n",
        "Data_Essay_01['Char_Count'] = Data_Essay_01['Essay'].apply(Char_Count)\n",
        "Data_Essay_01.sample()"
      ],
      "metadata": {
        "id": "ELmS3Tt-f-nv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "51539a29-0562-4f41-8fbf-4be91fc26ff0"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID                                              Essay  Rater_1 Score  \\\n",
              "186  187  Dear,newspaper I think that people should have...            3.0   \n",
              "\n",
              "     Rater_2 Score  Total Score  \\\n",
              "186            2.0          5.0   \n",
              "\n",
              "                                    Preprocessed_Essay  Sent_Count  \\\n",
              "186  Dear newspaper I think that people should have...           3   \n",
              "\n",
              "     Word_Count  Char_Count  \n",
              "186         116         582  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3e0678f1-38ec-4779-b383-aed241a1f5e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Char_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>187</td>\n",
              "      <td>Dear,newspaper I think that people should have...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Dear newspaper I think that people should have...</td>\n",
              "      <td>3</td>\n",
              "      <td>116</td>\n",
              "      <td>582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e0678f1-38ec-4779-b383-aed241a1f5e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3e0678f1-38ec-4779-b383-aed241a1f5e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3e0678f1-38ec-4779-b383-aed241a1f5e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Average Word Length of Essay"
      ],
      "metadata": {
        "id": "eSWTBDDpizP2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Avg_Word_Count(Essay):\n",
        "  \"\"\"\n",
        "    Calculates Average Word Count In An Essay Set\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      float\n",
        "      \n",
        "  \"\"\"\n",
        "  word_list = nltk.word_tokenize(Essay)\n",
        "  total = sum(map(len, word_list))/len(word_list)\n",
        "  return total\n",
        "\n",
        "Data_Essay_01['Avg_Word_Count'] = Data_Essay_01['Essay'].apply(Avg_Word_Count)\n",
        "Data_Essay_01.sample()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HujBMTSuXxxt",
        "outputId": "d9f0e7b7-f4bc-4f7a-ad1e-fb6d5ece6628"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      ID                                              Essay  Rater_1 Score  \\\n",
              "203  204  You want my opinion on the effects computers h...            5.0   \n",
              "\n",
              "     Rater_2 Score  Total Score  \\\n",
              "203            5.0         10.0   \n",
              "\n",
              "                                    Preprocessed_Essay  Sent_Count  \\\n",
              "203  You want my opinion on the effects computers h...          33   \n",
              "\n",
              "     Word_Count  Char_Count  Avg_Word_Count  \n",
              "203         433        2078        3.951501  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b646b5e1-4f9c-4f5f-8c3e-a15939ef1714\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Avg_Word_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>204</td>\n",
              "      <td>You want my opinion on the effects computers h...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>You want my opinion on the effects computers h...</td>\n",
              "      <td>33</td>\n",
              "      <td>433</td>\n",
              "      <td>2078</td>\n",
              "      <td>3.951501</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b646b5e1-4f9c-4f5f-8c3e-a15939ef1714')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b646b5e1-4f9c-4f5f-8c3e-a15939ef1714 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b646b5e1-4f9c-4f5f-8c3e-a15939ef1714');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Parts Of Speech Counts**"
      ],
      "metadata": {
        "id": "iUMnW4Qm4Vws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Pos_Tag_Count(Essay):\n",
        "  \"\"\"\n",
        "    Counts Parts of Speech in an Essay\n",
        "\n",
        "    Args:\n",
        "      Essay: Essay of each student \n",
        "    \n",
        "    Returns: \n",
        "      int,int,int,int,int,int\n",
        "      \n",
        "  \"\"\"\n",
        "  tagged_doc = nlp(Essay)\n",
        "\n",
        "  adj_count=0\n",
        "  verb_count=0\n",
        "  noun_count=0\n",
        "  pNoun_count=0\n",
        "  adverb_count=0\n",
        "  conj_count=0\n",
        "\n",
        "  for token in tagged_doc:\n",
        "\n",
        "    if(token.pos_ == 'ADJ'):\n",
        "      adj_count+=1\n",
        "    \n",
        "    elif(token.pos_ =='NOUN'):\n",
        "      noun_count+=1\n",
        "\n",
        "    elif (token.pos_ =='PRON'):\n",
        "      pNoun_count+=1\n",
        "\n",
        "    elif (token.pos_ =='VERB'):\n",
        "      verb_count+=1\n",
        "\n",
        "    elif (token.pos_ =='ADV'):\n",
        "      adverb_count+=1\n",
        "    \n",
        "    elif(token.pos_=='CCONJ'):\n",
        "      conj_count+=1\n",
        "\n",
        "  return verb_count,noun_count, adj_count, conj_count, adverb_count,pNoun_count"
      ],
      "metadata": {
        "id": "26j3wRKD4X54"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01['Verb_Count'], Data_Essay_01['Noun_Count'], Data_Essay_01['Adj_Count'], Data_Essay_01['Conj_Count'], Data_Essay_01['Adverb_Count'], Data_Essay_01['pNoun_Count']=zip(*Data_Essay_01[\"Preprocessed_Essay\"].map(Pos_Tag_Count))\n",
        "Data_Essay_01.sample()"
      ],
      "metadata": {
        "id": "W-WSN5Ce85Cu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a9fdf7a4-7c68-48be-83f5-a452a2e20d3a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        ID                                              Essay  Rater_1 Score  \\\n",
              "1445  1450  Click click, another information page opens up...            5.0   \n",
              "\n",
              "      Rater_2 Score  Total Score  \\\n",
              "1445            5.0         10.0   \n",
              "\n",
              "                                     Preprocessed_Essay  Sent_Count  \\\n",
              "1445  Click click another information page opens up ...          21   \n",
              "\n",
              "      Word_Count  Char_Count  Avg_Word_Count  Verb_Count  Noun_Count  \\\n",
              "1445         433        2189        4.177829          37          91   \n",
              "\n",
              "      Adj_Count  Conj_Count  Adverb_Count  pNoun_Count  \n",
              "1445         39          17            22           33  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6e040f70-0ef5-418e-826a-b0f98a192a5d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Avg_Word_Count</th>\n",
              "      <th>Verb_Count</th>\n",
              "      <th>Noun_Count</th>\n",
              "      <th>Adj_Count</th>\n",
              "      <th>Conj_Count</th>\n",
              "      <th>Adverb_Count</th>\n",
              "      <th>pNoun_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1445</th>\n",
              "      <td>1450</td>\n",
              "      <td>Click click, another information page opens up...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Click click another information page opens up ...</td>\n",
              "      <td>21</td>\n",
              "      <td>433</td>\n",
              "      <td>2189</td>\n",
              "      <td>4.177829</td>\n",
              "      <td>37</td>\n",
              "      <td>91</td>\n",
              "      <td>39</td>\n",
              "      <td>17</td>\n",
              "      <td>22</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6e040f70-0ef5-418e-826a-b0f98a192a5d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6e040f70-0ef5-418e-826a-b0f98a192a5d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6e040f70-0ef5-418e-826a-b0f98a192a5d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluating Writing Attributes**"
      ],
      "metadata": {
        "id": "puuRk5EHw8jJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Style**"
      ],
      "metadata": {
        "id": "Id4wN-9AxITZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mechanics**"
      ],
      "metadata": {
        "id": "I6sEA-fCCfmN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Counting Spelling Mistakes"
      ],
      "metadata": {
        "id": "2NgCS1PQZaIJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EW5kZQP-W3CE"
      },
      "outputs": [],
      "source": [
        "def Check_Spelling(Sentence):\n",
        "  \"\"\"\n",
        "    Checks spelling of each word\n",
        "\n",
        "    Args:\n",
        "      word: Words (Tokens) of each essay \n",
        "    \n",
        "    Returns: \n",
        "      int\n",
        "      \n",
        "  \"\"\"\n",
        "  count = 0\n",
        "  Sentence = word_tokenize(Sentence)\n",
        "  for word in Sentence:\n",
        "    word = Word(word)\n",
        "  \n",
        "    result = word.spellcheck()\n",
        "\n",
        "    # result [0][0] contains the bool value if the spelling is correct or not\n",
        "    # result [0][1] contains the confidence for the suggest correct spelling\n",
        "\n",
        "    if word != result[0][0]:\n",
        "      # print(f'Spelling of \"{word}\" is not correct!')\n",
        "      # print(f'Correct spelling of \"{word}\": \"{result[0][0]}\" (with {result[0][1]} confidence).')\n",
        "      count = count + 1\n",
        "\n",
        "  return count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01[\"Preprocessed_Essay\"] = Data_Essay_01[\"Essay\"].apply(Remove_NER)\n",
        "Data_Essay_01[\"Preprocessed_Essay\"] = Data_Essay_01[\"Preprocessed_Essay\"].apply(Remove_Punctuations)"
      ],
      "metadata": {
        "id": "Lhbvn0kuFGnq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01[\"Spelling_Mistakes_Count\"]  = Data_Essay_01[\"Preprocessed_Essay\"].map(Check_Spelling)"
      ],
      "metadata": {
        "id": "u5UO3OIYE-8p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        },
        "outputId": "ec1936cd-b969-4c1d-afeb-5ef51381fa0f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-fa2e31a3e7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Spelling_Mistakes_Count\"\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Preprocessed_Essay\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCheck_Spelling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, arg, na_action)\u001b[0m\n\u001b[1;32m   4159\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4160\u001b[0m         \"\"\"\n\u001b[0;32m-> 4161\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4162\u001b[0m         return self._constructor(new_values, index=self.index).__finalize__(\n\u001b[1;32m   4163\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"map\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/base.py\u001b[0m in \u001b[0;36m_map_values\u001b[0;34m(self, mapper, na_action)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;31m# mapper is a function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m         \u001b[0mnew_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnew_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-12-547a4e1337c7>\u001b[0m in \u001b[0;36mCheck_Spelling\u001b[0;34m(Sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspellcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# result [0][0] contains the bool value if the spelling is correct or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36mspellcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         '''\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/en/__init__.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mspelling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                   \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                   \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m                   \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m_edit2\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;31m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# Only keep candidates that are actually known words (20% speedup).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;31m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# Only keep candidates that are actually known words (20% speedup).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__contains__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__getitem__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m_lazy\u001b[0;34m(self, method, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Punctuation Mistakes **(Incomplete)**"
      ],
      "metadata": {
        "id": "qEPOKuVJRz1-"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CvNFcb7U9c2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification , pipeline\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('oliverguhr/fullstop-punctuation-multilang-large')"
      ],
      "metadata": {
        "id": "Wa2ndqK-T2p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForTokenClassification.from_pretrained('oliverguhr/fullstop-punctuation-multilang-large')"
      ],
      "metadata": {
        "id": "FWtZxZXbU7c8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pun = pipeline('ner' , model = model , tokenizer = tokenizer)"
      ],
      "metadata": {
        "id": "3DCduth1T2Jf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Correcting Spelling Mistakes"
      ],
      "metadata": {
        "id": "EKmSFD923yAp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Correct_Spelling(Sentence):\n",
        "  \"\"\"\n",
        "    Checks spelling of each word\n",
        "\n",
        "    Args:\n",
        "      word: Words (Tokens) of each essay \n",
        "    \n",
        "    Returns: \n",
        "      int\n",
        "      \n",
        "  \"\"\"\n",
        "  Tokens = word_tokenize(Sentence)\n",
        "  newTokens = []\n",
        "  for word in Tokens:\n",
        "    word = Word(word)\n",
        "  \n",
        "    result = word.spellcheck()\n",
        "\n",
        "    # result [0][0] contains the bool value if the spelling is correct or not\n",
        "    # result [0][1] contains the confidence for the suggest correct spelling\n",
        "    \n",
        "    if word != result[0][0]:\n",
        "      if(result[0][1] > 0.9 and not(wordnet.synsets(word)) and not(\"/\" in word) and not(\"@\" in word)):\n",
        "        newTokens.append(result[0][0])\n",
        "        print(word , result[0][0])\n",
        "      else: \n",
        "        newTokens.append(word)\n",
        "    else:\n",
        "      newTokens.append(word)\n",
        "  return ' '.join(newTokens)"
      ],
      "metadata": {
        "id": "6BCrmEOO3vfG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = Correct_Spelling(Remove_White_Spaces(Data_Essay_01[\"Essay\"][1]))"
      ],
      "metadata": {
        "id": "EoZG4g7lR6Rq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cb0aeba-1d73-4d63-a978-27e78692266a"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coordibates coordinate\n",
            "myspace space\n",
            "coordibates coordinate\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "appling applying\n",
            "n't not\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01[\"Essay\"][1] = Correct_Spelling(Remove_White_Spaces(Data_Essay_01[\"Essay\"][1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhkUSthSKC1d",
        "outputId": "e69d03f2-f826-46f5-c0ec-e1328b0fdcc4"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "coordibates coordinate\n",
            "myspace space\n",
            "coordibates coordinate\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "appling applying\n",
            "n't not\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This needs to be executed for complete essay01 ---> Ahsan\n",
        "Data_Essay_01['Essay_NoSpellingMistakes'] = Data_Essay_01['Essay'].apply(Remove_White_Spaces)\n",
        "Data_Essay_01['Essay_NoSpellingMistakes'] = Data_Essay_01['Essay_NoSpellingMistakes'].apply(Correct_Spelling)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "R_8ErHeKAlZ9",
        "outputId": "95328b85-71f1-4cc1-b47d-8e4df0f0bde6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "troble trouble\n",
            "buisness business\n",
            "myspace space\n",
            "If Of\n",
            "isnt isn\n",
            "forbidde forbidden\n",
            "troble trouble\n",
            "coordibates coordinate\n",
            "myspace space\n",
            "coordibates coordinate\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "appling applying\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "benifit benefit\n",
            "studdies studies\n",
            "reasearch research\n",
            "advertisments advertisements\n",
            "imposible impossible\n",
            "commucated communicated\n",
            "reasearch research\n",
            "reasearch research\n",
            "posible possible\n",
            "amagine imagine\n",
            "n't not\n",
            "buissness business\n",
            "catalouge catalogue\n",
            "castomer customer\n",
            "coustomers customers\n",
            "resturant restaurant\n",
            "convinences convinces\n",
            "reaserch research\n",
            "Computors Computers\n",
            "computors computers\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "computors computers\n",
            "If Of\n",
            "convience convince\n",
            "n't not\n",
            "n't not\n",
            "confrence conference\n",
            "parttners partners\n",
            "conviente convient\n",
            "subssiquently subsequently\n",
            "conviente convient\n",
            "camputer computer\n",
            "posibility possibility\n",
            "everthing everything\n",
            "wouldbe would\n",
            "phisically physically\n",
            "ardthritis arthritis\n",
            "myspace space\n",
            "n't not\n",
            "embarrasing embarrassing\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "'re are\n",
            "hand-eye handley\n",
            "If Of\n",
            "hand-eye handley\n",
            "feild field\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "everyones everyone\n",
            "Ther Her\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "atleast least\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "obease obese\n",
            "n't not\n",
            "problum problem\n",
            "n't not\n",
            "n't not\n",
            "socioty society\n",
            "obease obese\n",
            "cumputers computers\n",
            "n't not\n",
            "n't not\n",
            "amarica america\n",
            "n't not\n",
            "n't not\n",
            "exersise exercise\n",
            "computeres computers\n",
            "mealting melting\n",
            "electricty electricity\n",
            "thjen then\n",
            "electrisity electricity\n",
            "If Of\n",
            "happining happening\n",
            "shorline shrine\n",
            "technolagy technology\n",
            "peroson person\n",
            "themselfs themselves\n",
            "conclution conclusion\n",
            "computeres computers\n",
            "amarica america\n",
            "obease obese\n",
            "reson reason\n",
            "califan halifax\n",
            "exirsis exists\n",
            "thrid third\n",
            "reson reason\n",
            "peolpe people\n",
            "exmple example\n",
            "didnt didn\n",
            "didnt didn\n",
            "adout about\n",
            "consiter consider\n",
            "thrie three\n",
            "resons reasons\n",
            "Seconde Second\n",
            "resons reasons\n",
            "postition position\n",
            "bigin begin\n",
            "insted instead\n",
            "insted instead\n",
            "incomputer computer\n",
            "becasue because\n",
            "resons reasons\n",
            "futur future\n",
            "resons reasons\n",
            "bigin begin\n",
            "insted instead\n",
            "abd and\n",
            "insted instead\n",
            "cmputer computer\n",
            "papaer paper\n",
            "resons reasons\n",
            "papaer paper\n",
            "hand-eye handley\n",
            "Thers Hers\n",
            "webcame became\n",
            "n't not\n",
            "interection interaction\n",
            "nessessity necessity\n",
            "soceity society\n",
            "usod used\n",
            "If Of\n",
            "n't not\n",
            "'re are\n",
            "Additionaly Additional\n",
            "If Of\n",
            "reasearch research\n",
            "peole people\n",
            "peole people\n",
            "scaresly scarcely\n",
            "Oviously Obviously\n",
            "foreward forward\n",
            "bility ability\n",
            "technologicall technological\n",
            "belive believe\n",
            "belive believe\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "belive believe\n",
            "n't not\n",
            "n't not\n",
            "exersise exercise\n",
            "belive believe\n",
            "n't not\n",
            "privalges privileges\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "addictted addicted\n",
            "n't not\n",
            "n't not\n",
            "pleanty plenty\n",
            "n't not\n",
            "belive believe\n",
            "n't not\n",
            "centainly certainly\n",
            "joggin join\n",
            "workin working\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "n't not\n",
            "froi from\n",
            "invanyor inventor\n",
            "leki levi\n",
            "mashine machine\n",
            "hand-eye handley\n",
            "reasearch research\n",
            "desiner designer\n",
            "Thats Hats\n",
            "communtiy community\n",
            "dieseases diseases\n",
            "neccessitys necessity\n",
            "myspace space\n",
            "youtube couture\n",
            "recestion reception\n",
            "n't not\n",
            "exersice exercise\n",
            "exersice exercise\n",
            "Thats Hats\n",
            "n't not\n",
            "exersice exercise\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "hand-eye handley\n",
            "foregin foreign\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "tye the\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "If Of\n",
            "hand-eye handley\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "yu you\n",
            "wih with\n",
            "would't would\n",
            "n't not\n",
            "imprdove improve\n",
            "hand-eye handley\n",
            "beileve believe\n",
            "helpfull helpful\n",
            "If Of\n",
            "benifit benefit\n",
            "diffrent different\n",
            "refferances references\n",
            "adicted addicted\n",
            "beleive believe\n",
            "infermation information\n",
            "viris virus\n",
            "If Of\n",
            "infermation information\n",
            "wepons weapons\n",
            "differnt different\n",
            "goind going\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "whats what\n",
            "goind going\n",
            "hand-eye handley\n",
            "n't not\n",
            "computre computer\n",
            "If Of\n",
            "computre computer\n",
            "computres computers\n",
            "infront front\n",
            "computres computers\n",
            "If Of\n",
            "computres computers\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "deffinately definitely\n",
            "webkinz webbing\n",
            "usefull useful\n",
            "invatations invitations\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "colloge college\n",
            "negitive negative\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "myspace space\n",
            "If Of\n",
            "unseatled unsettled\n",
            "friesnd friend\n",
            "If Of\n",
            "If Of\n",
            "understandd understand\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "grew-up grownup\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "becuase because\n",
            "benifit benefit\n",
            "intach intact\n",
            "orginized organized\n",
            "n't not\n",
            "diliberatly deliberately\n",
            "If Of\n",
            "sesonal seasonal\n",
            "thats that\n",
            "intouch touch\n",
            "bestfriend befriend\n",
            "vidio video\n",
            "intouch touch\n",
            "needey needed\n",
            "intouch touch\n",
            "n't not\n",
            "computor computer\n",
            "opition opinion\n",
            "isnt isn\n",
            "havent haven\n",
            "If Of\n",
            "advsnces advances\n",
            "excercising exercising\n",
            "becacuse because\n",
            "nieghborhood neighborhood\n",
            "infront front\n",
            "whats what\n",
            "chuckie chuckle\n",
            "infront front\n",
            "infront front\n",
            "naylor taylor\n",
            "wacth watch\n",
            "belive believe\n",
            "negitive negative\n",
            "taht that\n",
            "likly likely\n",
            "likly likely\n",
            "If Of\n",
            "n't not\n",
            "probibly probably\n",
            "probibly probably\n",
            "excersize excessive\n",
            "n't not\n",
            "If Of\n",
            "likly likely\n",
            "n't not\n",
            "likly likely\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "iTunes tunes\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "defenetly decently\n",
            "sergents sergeants\n",
            "n't not\n",
            "enternet internet\n",
            "myspace space\n",
            "hand-eye handley\n",
            "computeres computers\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "beneifts benefits\n",
            "sosiety society\n",
            "reson reason\n",
            "undersand understand\n",
            "uprizing uprising\n",
            "frends friends\n",
            "reson reason\n",
            "youtube couture\n",
            "obise obese\n",
            "thats that\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "buissness business\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "'re are\n",
            "'re are\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "Celebraties Celebrates\n",
            "'re are\n",
            "If Of\n",
            "n't not\n",
            "probaly probably\n",
            "sconclusion conclusion\n",
            "computor computer\n",
            "n't not\n",
            "havent haven\n",
            "enternet internet\n",
            "havent haven\n",
            "fingure figure\n",
            "beleive believe\n",
            "beleive believe\n",
            "cordonation coronation\n",
            "probobility probability\n",
            "probobility probability\n",
            "vacational vocational\n",
            "machinary machinery\n",
            "buisness business\n",
            "cordonation coronation\n",
            "buisness business\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "wellfare welfare\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "xbox box\n",
            "n't not\n",
            "advanement advancement\n",
            "n't not\n",
            "benifit benefit\n",
            "completly completely\n",
            "definatly defiantly\n",
            "benifits benefits\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "i'ts its\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "acheive achieve\n",
            "n't not\n",
            "completly completely\n",
            "'re are\n",
            "thats that\n",
            "chatins chains\n",
            "labtop labor\n",
            "chatins chains\n",
            "Paretns Parents\n",
            "truely truly\n",
            "possesion possession\n",
            "aperson person\n",
            "concentrat concentrate\n",
            "If Of\n",
            "poppular popular\n",
            "technolgy technology\n",
            "n't not\n",
            "n't not\n",
            "exercis exercise\n",
            "mounthly monthly\n",
            "beleive believe\n",
            "thats that\n",
            "n't not\n",
            "differnt different\n",
            "differnt different\n",
            "n't not\n",
            "differnt different\n",
            "scheduale schedule\n",
            "anytime daytime\n",
            "n't not\n",
            "redecide decide\n",
            "hand-eye handley\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "releave release\n",
            "friendsand friedland\n",
            "n't not\n",
            "thats that\n",
            "peole people\n",
            "'re are\n",
            "theior their\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "didnt didn\n",
            "whats what\n",
            "myspace space\n",
            "thats that\n",
            "excercising exercising\n",
            "coubtries countries\n",
            "n't not\n",
            "'re are\n",
            "excercise exercise\n",
            "curlups curls\n",
            "n't not\n",
            "converstions conversations\n",
            "If Of\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "ooVoo oooh\n",
            "prounociation pronunciation\n",
            "langages languages\n",
            "havent haven\n",
            "memebers members\n",
            "myspace space\n",
            "technologie technology\n",
            "didnt didn\n",
            "technologie technology\n",
            "technologie technology\n",
            "technologie technology\n",
            "Man-kind mankind\n",
            "n't not\n",
            "laplops gallops\n",
            "extbooks ebooks\n",
            "understandds understands\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "groth growth\n",
            "helpul helpful\n",
            "If Of\n",
            "If Of\n",
            "saids said\n",
            "If Of\n",
            "vidieo video\n",
            "insted instead\n",
            "Comuters Computers\n",
            "buissness business\n",
            "uselful useful\n",
            "buissness business\n",
            "n't not\n",
            "comuters computers\n",
            "buissness business\n",
            "becasue because\n",
            "proceeses processes\n",
            "phycologist psychologist\n",
            "speciaizes specialized\n",
            "thant that\n",
            "obesse obese\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "rayfield hayfield\n",
            "n't not\n",
            "arguements arguments\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "thru thou\n",
            "n't not\n",
            "If Of\n",
            "acutually actually\n",
            "n't not\n",
            "Turst Burst\n",
            "benifits benefits\n",
            "efficent efficient\n",
            "arrands errands\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "millons millions\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "If Of\n",
            "Futhermore Furthermore\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "'re are\n",
            "cordination combination\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "intouch touch\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "cordination combination\n",
            "cordination combination\n",
            "n't not\n",
            "cordination combination\n",
            "If Of\n",
            "n't not\n",
            "cordination combination\n",
            "cordination combination\n",
            "If Of\n",
            "n't not\n",
            "cordination combination\n",
            "plummit summit\n",
            "benifited benefited\n",
            "excersice excessive\n",
            "If Of\n",
            "definatelly definitely\n",
            "If Of\n",
            "definately definitely\n",
            "healthey healthy\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "thier their\n",
            "If Of\n",
            "Unfortunatly Unfortunately\n",
            "aspact aspect\n",
            "ethier ether\n",
            "extremly extremely\n",
            "thier their\n",
            "xbox box\n",
            "playstation plantation\n",
            "xbox box\n",
            "psp pp\n",
            "gameboy pageboy\n",
            "xbox box\n",
            "olny only\n",
            "thier their\n",
            "thier their\n",
            "togther together\n",
            "If Of\n",
            "thier their\n",
            "exprience experience\n",
            "oppinion opinion\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "gramar grammar\n",
            "benifical beneficial\n",
            "libary library\n",
            "benifit benefit\n",
            "comunication communication\n",
            "comunication communication\n",
            "benifit benefit\n",
            "benifit benefit\n",
            "cridit credit\n",
            "insted instead\n",
            "outdores outdone\n",
            "passtime pastime\n",
            "oppertunity opportunity\n",
            "understod understood\n",
            "concideration consideration\n",
            "coltures cultures\n",
            "favert avert\n",
            "n't not\n",
            "benifit benefit\n",
            "benifit benefit\n",
            "n't not\n",
            "n't not\n",
            "dieabeties diabetes\n",
            "Thats Hats\n",
            "n't not\n",
            "n't not\n",
            "dissapointed disappointed\n",
            "'re are\n",
            "everthing everything\n",
            "dissapointed disappointed\n",
            "n't not\n",
            "n't not\n",
            "safty safety\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "safty safety\n",
            "thats that\n",
            "'re are\n",
            "n't not\n",
            "safty safety\n",
            "beifit benefit\n",
            "beifit benefit\n",
            "stillis stills\n",
            "benifit benefit\n",
            "comunication communication\n",
            "n't not\n",
            "benifit benefit\n",
            "proffessions professions\n",
            "acessable accessible\n",
            "benifets benefits\n",
            "benifits benefits\n",
            "benifits benefits\n",
            "n't not\n",
            "If Of\n",
            "inbox into\n",
            "priveleges privileges\n",
            "vistoriously victoriously\n",
            "eith with\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "deffinition definition\n",
            "helpfull helpful\n",
            "helpfull helpful\n",
            "helpfull helpful\n",
            "helpfull helpful\n",
            "If Of\n",
            "helpfull helpful\n",
            "vaction action\n",
            "If Of\n",
            "If Of\n",
            "vaction action\n",
            "benifit benefit\n",
            "benifits benefits\n",
            "'re are\n",
            "succesful successful\n",
            "insted instead\n",
            "easilly easily\n",
            "lthat that\n",
            "colege college\n",
            "n't not\n",
            "aol all\n",
            "spo so\n",
            "If Of\n",
            "n't not\n",
            "benifets benefits\n",
            "hand-eye handley\n",
            "esencial essential\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "benificial beneficial\n",
            "If Of\n",
            "goverment government\n",
            "immensly immensely\n",
            "n't not\n",
            "n't not\n",
            "vincinity vicinity\n",
            "If Of\n",
            "hand-eye handley\n",
            "If Of\n",
            "'re are\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "posotive positive\n",
            "othe the\n",
            "n't not\n",
            "incomg income\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "definetly definitely\n",
            "If Of\n",
            "whats what\n",
            "comunication communication\n",
            "If Of\n",
            "'re are\n",
            "buisnoss business\n",
            "n't not\n",
            "hardely hardly\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "ooVoo oooh\n",
            "comunication communication\n",
            "reasearch research\n",
            "youtube couture\n",
            "excersize excessive\n",
            "computors computers\n",
            "computors computers\n",
            "computors computers\n",
            "computors computers\n",
            "anyting anything\n",
            "computors computers\n",
            "computor computer\n",
            "n't not\n",
            "extremly extremely\n",
            "computors computers\n",
            "asword sword\n",
            "computors computers\n",
            "Computors Computers\n",
            "computors computers\n",
            "n't not\n",
            "sexting setting\n",
            "sexting setting\n",
            "n't not\n",
            "goting going\n",
            "goting going\n",
            "childern children\n",
            "childerns children\n",
            "n't not\n",
            "n't not\n",
            "sexting setting\n",
            "childern children\n",
            "Thats Hats\n",
            "eyesit eyes\n",
            "exercis exercise\n",
            "thats that\n",
            "If Of\n",
            "atleast least\n",
            "youtube couture\n",
            "n't not\n",
            "n't not\n",
            "outsite outside\n",
            "re-run return\n",
            "youtube couture\n",
            "n't not\n",
            "becuse because\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "nght night\n",
            "wheter whether\n",
            "effets effects\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "mabey mabel\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "peopl people\n",
            "efficiant efficient\n",
            "n't not\n",
            "'computers computers\n",
            "efficiant efficient\n",
            "n't not\n",
            "efficiant efficient\n",
            "ina in\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "recquire require\n",
            "buisness business\n",
            "useage usage\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "aplications applications\n",
            "commertials commercial\n",
            "avertisements advertisements\n",
            "conclution conclusion\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "expirience experience\n",
            "expirience experience\n",
            "n't not\n",
            "excercising exercising\n",
            "immediatly immediately\n",
            "enviroment environment\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "enviroment environment\n",
            "youtube couture\n",
            "n't not\n",
            "inappronrate inappropriate\n",
            "n't not\n",
            "oppisite opposite\n",
            "verbily verily\n",
            "If Of\n",
            "amarica america\n",
            "batterie batteries\n",
            "Simulaters Simulates\n",
            "controll control\n",
            "intrested interested\n",
            "possitive positive\n",
            "comunicate communicate\n",
            "baout about\n",
            "happended happened\n",
            "n't not\n",
            "n't not\n",
            "sudents students\n",
            "everyones everyone\n",
            "n't not\n",
            "comunicating communicating\n",
            "gratest greatest\n",
            "n't not\n",
            "n't not\n",
            "diffuclty difficulty\n",
            "libery liberty\n",
            "libery liberty\n",
            "libery liberty\n",
            "n't not\n",
            "lvl ll\n",
            "lvl ll\n",
            "n't not\n",
            "hand-eye handley\n",
            "'re are\n",
            "hand-eye handley\n",
            "'re are\n",
            "specil special\n",
            "hand-eye handley\n",
            "benificial beneficial\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "opinions. opinions\n",
            "thngs things\n",
            "ecetra extra\n",
            "'re are\n",
            "posistion position\n",
            "migrane migrate\n",
            "compuer computer\n",
            "satisying satisfying\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "learnen learned\n",
            "mspace space\n",
            "myspace space\n",
            "youtube couture\n",
            "famly family\n",
            "chidren children\n",
            "coumputer computer\n",
            "famly family\n",
            "Youtube Couture\n",
            "asom atom\n",
            "freinds friends\n",
            "famly family\n",
            "chus thus\n",
            "adicted addicted\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "benefiticial beneficial\n",
            "If Of\n",
            "saearch search\n",
            "'re are\n",
            "phnes panes\n",
            "n't not\n",
            "n't not\n",
            "pne one\n",
            "anytime daytime\n",
            "usefull useful\n",
            "n't not\n",
            "helpfull helpful\n",
            "doesnt doesn\n",
            "awsome some\n",
            "helpfull helpful\n",
            "exersising exercising\n",
            "n't not\n",
            "comptuers computers\n",
            "addictied addicted\n",
            "predetors creditors\n",
            "kidnapp kidnap\n",
            "recognation recognition\n",
            "childrens children\n",
            "If Of\n",
            "thats that\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "fantacy fantasy\n",
            "assumtion assumption\n",
            "n't not\n",
            "fantacy fantasy\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "justto justo\n",
            "comminicate communicate\n",
            "incontact contact\n",
            "n't not\n",
            "proposterous preposterous\n",
            "disaters disasters\n",
            "whatevers whatever\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "intervied interview\n",
            "n't not\n",
            "compuer computer\n",
            "n't not\n",
            "controversal controversial\n",
            "enourmous enormous\n",
            "benifits benefits\n",
            "hand-eye handley\n",
            "benefitial beneficial\n",
            "n't not\n",
            "didnt didn\n",
            "scoliousis scoliosis\n",
            "hand-eye handley\n",
            "excercising exercising\n",
            "n't not\n",
            "n't not\n",
            "Thats Hats\n",
            "attracks attacks\n",
            "Thats Hats\n",
            "If Of\n",
            "keepin keeping\n",
            "gyou you\n",
            "eople people\n",
            "exersice exercise\n",
            "needds needs\n",
            "hand-eye handley\n",
            "abile able\n",
            "intouch touch\n",
            "woulde would\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "myspace space\n",
            "aol all\n",
            "resturant restaurant\n",
            "conculsion conclusion\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "ohter other\n",
            "carzy carry\n",
            "mohter mother\n",
            "conclusing concluding\n",
            "multuplication multiplication\n",
            "desaster disaster\n",
            "whats what\n",
            "discusion discussion\n",
            "n't not\n",
            "reconize recognize\n",
            "certin certain\n",
            "voide voice\n",
            "n't not\n",
            "Cybe Be\n",
            "If Of\n",
            "priorites priority\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "thats that\n",
            "homies homes\n",
            "thats that\n",
            "If Of\n",
            "thats that\n",
            "hand-eye handley\n",
            "If Of\n",
            "purphases purchases\n",
            "convinent continent\n",
            "soliders soldiers\n",
            "soliders soldiers\n",
            "usefull useful\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "wasnt want\n",
            "prodject project\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "usinf using\n",
            "n't not\n",
            "expessaly expressly\n",
            "exersizing exercising\n",
            "n't not\n",
            "exersizes exercises\n",
            "n't not\n",
            "possitive positive\n",
            "curcial crucial\n",
            "n't not\n",
            "dependancy dependency\n",
            "ocmputer computer\n",
            "n't not\n",
            "comptuer computer\n",
            "n't not\n",
            "interacte interact\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "exersise exercise\n",
            "hand-eye handley\n",
            "hong long\n",
            "oerson person\n",
            "'re are\n",
            "youtube couture\n",
            "hand-eye handley\n",
            "adminitrating administrating\n",
            "loacl local\n",
            "newapaper newspaper\n",
            "If Of\n",
            "newpaper newspaper\n",
            "govermnet government\n",
            "hignway highway\n",
            "Prctically Practically\n",
            "aol all\n",
            "administrater administrator\n",
            "reseach research\n",
            "assitance assistance\n",
            "ahving having\n",
            "possiblr possible\n",
            "communiacte communicate\n",
            "n't not\n",
            "If Of\n",
            "usieng using\n",
            "becuse because\n",
            "ehey they\n",
            "becuse because\n",
            "eney enemy\n",
            "corect correct\n",
            "becuse because\n",
            "ingriedient ingredient\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "belive believe\n",
            "benifit benefit\n",
            "everywere everywhere\n",
            "expeirences experiences\n",
            "Compuer Computer\n",
            "awsome some\n",
            "freinds friends\n",
            "benifit benefit\n",
            "polution solution\n",
            "n't not\n",
            "benifit benefit\n",
            "benifit benefit\n",
            "resson reason\n",
            "resson reason\n",
            "resson reason\n",
            "myspace space\n",
            "n't not\n",
            "myspace space\n",
            "resson reason\n",
            "somy some\n",
            "canda canada\n",
            "injoy enjoy\n",
            "Inconclusion Conclusion\n",
            "statting starting\n",
            "resson reason\n",
            "effeck effect\n",
            "magnificant magnificent\n",
            "If Of\n",
            "exsist exist\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "x-box box\n",
            "x-box box\n",
            "resomes resumes\n",
            "understeading understanding\n",
            "animales animals\n",
            "anythin anything\n",
            "somethine something\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "vocab vocal\n",
            "vocab vocal\n",
            "privite private\n",
            "n't not\n",
            "infenite infinite\n",
            "nolege college\n",
            "knoledge knowledge\n",
            "n't not\n",
            "n't not\n",
            "socialy social\n",
            "congradulate congratulate\n",
            "cocnclusion conclusion\n",
            "n't not\n",
            "exercing exerting\n",
            "relized realized\n",
            "likly likely\n",
            "hospitial hospital\n",
            "surgen surgeon\n",
            "n't not\n",
            "grammer grammar\n",
            "doesnt doesn\n",
            "n't not\n",
            "internent internet\n",
            "n't not\n",
            "beleive believe\n",
            "benefil benefit\n",
            "buisness business\n",
            "buisness business\n",
            "buisness business\n",
            "buisness business\n",
            "Buisness Business\n",
            "imediately immediately\n",
            "n't not\n",
            "n't not\n",
            "excercise exercise\n",
            "n't not\n",
            "If Of\n",
            "expirience experience\n",
            "indentity identity\n",
            "thats that\n",
            "farmpring farming\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "serch search\n",
            "hand-eye handley\n",
            "serch search\n",
            "If Of\n",
            "n't not\n",
            "texting testing\n",
            "hand-eye handley\n",
            "'re are\n",
            "withb with\n",
            "woithout without\n",
            "whcih which\n",
            "graetly greatly\n",
            "controll control\n",
            "outlowed outlawed\n",
            "exersizing exercising\n",
            "adicted addicted\n",
            "myspace space\n",
            "incroas increase\n",
            "affenders offenders\n",
            "tramendus tremendous\n",
            "n't not\n",
            "Teh Eh\n",
            "comkputer computer\n",
            "suposed supposed\n",
            "n't not\n",
            "hand-eye handley\n",
            "myspace space\n",
            "'re are\n",
            "everday everyday\n",
            "n't not\n",
            "presuade persuade\n",
            "completley completely\n",
            "snowday snowy\n",
            "recive receive\n",
            "usper upper\n",
            "cancled canceled\n",
            "woulde would\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "posative positive\n",
            "avalible available\n",
            "messanger messenger\n",
            "youre your\n",
            "ebay bay\n",
            "alls all\n",
            "recive receive\n",
            "n't not\n",
            "'re are\n",
            "comuter computer\n",
            "camputers computers\n",
            "excersize excessive\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "comuter computer\n",
            "n't not\n",
            "hand-eye handley\n",
            "cordanation coronation\n",
            "compters computers\n",
            "n't not\n",
            "stepdad stepped\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "socity society\n",
            "asignments assignment\n",
            "diffrent different\n",
            "mnake make\n",
            "parrents parents\n",
            "parrents parents\n",
            "ofering offering\n",
            "oppertunities opportunities\n",
            "oppertunities opportunities\n",
            "contraversal controversial\n",
            "adolesents adolescents\n",
            "n't not\n",
            "n't not\n",
            "adavantages advantages\n",
            "exercizing exercising\n",
            "n't not\n",
            "thats that\n",
            "thier their\n",
            "n't not\n",
            "someitmes sometimes\n",
            "n't not\n",
            "would'nt wouldn\n",
            "paidless painless\n",
            "couldent couldn\n",
            "woulden wouldn\n",
            "deppression depression\n",
            "benifit benefit\n",
            "everyting everything\n",
            "somone someone\n",
            "graphis graphics\n",
            "aritist artist\n",
            "acitivitys activity\n",
            "benifits benefits\n",
            "chets chest\n",
            "securty security\n",
            "coumputers computers\n",
            "fourmula formula\n",
            "graphis graphics\n",
            "coumputers computers\n",
            "graphis graphics\n",
            "coumputers computers\n",
            "coumputor computer\n",
            "graphis graphics\n",
            "coumputer computer\n",
            "acivitys activity\n",
            "coumputors computers\n",
            "coumputors computers\n",
            "youtube couture\n",
            "youtube couture\n",
            "coumputor computer\n",
            "coumputors computers\n",
            "bennafit benefit\n",
            "exstent extent\n",
            "'re are\n",
            "collassal colossal\n",
            "definetly definitely\n",
            "If Of\n",
            "n't not\n",
            "possitive positive\n",
            "s'de side\n",
            "myspace space\n",
            "'re are\n",
            "efferct effect\n",
            "If Of\n",
            "cutt cut\n",
            "n't not\n",
            "childre children\n",
            "instintly instantly\n",
            "advanrages advantages\n",
            "imformation information\n",
            "reson reason\n",
            "interfear interfere\n",
            "familliar familiar\n",
            "unpleasent unpleasant\n",
            "imformation information\n",
            "ciber cider\n",
            "imformation information\n",
            "doesnt doesn\n",
            "peole people\n",
            "veiwible visible\n",
            "piont point\n",
            "magnificient magnificent\n",
            "up-sides upside\n",
            "up-sides upside\n",
            "up-sides upside\n",
            "thats that\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "understant understand\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "If Of\n",
            "heldful helpful\n",
            "far-away faraway\n",
            "n't not\n",
            "n't not\n",
            "exercis exercise\n",
            "n't not\n",
            "exercis exercise\n",
            "n't not\n",
            "whats what\n",
            "depresion depression\n",
            "n't not\n",
            "n't not\n",
            "aol all\n",
            "n't not\n",
            "n't not\n",
            "allways always\n",
            "allways always\n",
            "everday everyday\n",
            "ontire entire\n",
            "exerising exercising\n",
            "beacause because\n",
            "myspace space\n",
            "instad instead\n",
            "youtube couture\n",
            "laughin laughing\n",
            "n't not\n",
            "enoughb enough\n",
            "lcomputer computer\n",
            "internent internet\n",
            "Thats Hats\n",
            "youtube couture\n",
            "myspace space\n",
            "reasearch research\n",
            "If Of\n",
            "n't not\n",
            "enywhere anywhere\n",
            "inordre ordre\n",
            "Encouragment Encouragement\n",
            "goverment government\n",
            "If Of\n",
            "n't not\n",
            "relationshops relationships\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "whats what\n",
            "n't not\n",
            "n't not\n",
            "posotive positive\n",
            "hand-eye handley\n",
            "familly family\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "definatly defiantly\n",
            "conveniant convenient\n",
            "If Of\n",
            "helpul helpful\n",
            "faraways faraway\n",
            "n't not\n",
            "If Of\n",
            "relign reign\n",
            "onlinee online\n",
            "helpul helpful\n",
            "ccan can\n",
            "impaced impacted\n",
            "millenium millennium\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "intellegence intelligence\n",
            "hand-eye handley\n",
            "appreciacion appreciation\n",
            "If Of\n",
            "n't not\n",
            "onlr only\n",
            "n't not\n",
            "enbough enough\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "dissapear disappear\n",
            "Reseach Research\n",
            "oppinion opinion\n",
            "If Of\n",
            "allways always\n",
            "lillte little\n",
            "myspace space\n",
            "n't not\n",
            "sutch such\n",
            "mutch much\n",
            "progrem program\n",
            "mutch much\n",
            "thease these\n",
            "n't not\n",
            "necesary necessary\n",
            "If Of\n",
            "'re are\n",
            "If Of\n",
            "If Of\n",
            "theu the\n",
            "-if if\n",
            "all- all\n",
            "greaduate graduate\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "epidemin epidemic\n",
            "anegative negative\n",
            "remeber remember\n",
            "infromation information\n",
            "liesure leisure\n",
            "fogetting forgetting\n",
            "aweful awful\n",
            "experinced experienced\n",
            "adictied addicted\n",
            "n't not\n",
            "faton baton\n",
            "n't not\n",
            "unhealth unhealthy\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "unfortunet unfortunate\n",
            "ourself yourself\n",
            "dilema dilemma\n",
            "othe the\n",
            "proffestional professional\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "coutries countries\n",
            "whats what\n",
            "whats what\n",
            "n't not\n",
            "comunicating communicating\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "'re are\n",
            "invation invasion\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "straightin straighten\n",
            "n't not\n",
            "n't not\n",
            "seperate separate\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "reasearch research\n",
            "n't not\n",
            "n't not\n",
            "excercise exercise\n",
            "'re are\n",
            "beuty beauty\n",
            "n't not\n",
            "truely truly\n",
            "accoding according\n",
            "hunington huntington\n",
            "youself yourself\n",
            "ourside outside\n",
            "Yah Ah\n",
            "screnary secretary\n",
            "youre your\n",
            "'re are\n",
            "disapear disappear\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "Whats Hats\n",
            "sendin sending\n",
            "'re are\n",
            "happends happens\n",
            "hand-writing handwriting\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "promblems problems\n",
            "n't not\n",
            "otherside otherwise\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "peope people\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "troppical tropical\n",
            "thier their\n",
            "resorce resource\n",
            "compoler composer\n",
            "If Of\n",
            "qulities qualities\n",
            "n't not\n",
            "buisness business\n",
            "If Of\n",
            "n't not\n",
            "exersize exercise\n",
            "If Of\n",
            "n't not\n",
            "out-side outside\n",
            "n't not\n",
            "n't not\n",
            "with-out without\n",
            "insed rinsed\n",
            "actultly actually\n",
            "peopel people\n",
            "everday everyday\n",
            "vertual virtual\n",
            "causesan causes\n",
            "diabeaties diabetes\n",
            "canser cancer\n",
            "n't not\n",
            "n't not\n",
            "enouhg enough\n",
            "didi did\n",
            "disappering disappearing\n",
            "envieronmental environmental\n",
            "completly completely\n",
            "caus cause\n",
            "acessive excessive\n",
            "comuters computers\n",
            "reciving receiving\n",
            "everyones everyone\n",
            "anytime daytime\n",
            "fmily family\n",
            "hand-eye handley\n",
            "n't not\n",
            "texting testing\n",
            "texting testing\n",
            "whtm whom\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "karayta karay\n",
            "hand-eye handley\n",
            "hpoe hope\n",
            "n't not\n",
            "hand-eye handley\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "Thats Hats\n",
            "hand-eye handley\n",
            "socia social\n",
            "If Of\n",
            "If Of\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "thier their\n",
            "thier their\n",
            "secend second\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "thats that\n",
            "wouldent wouldn\n",
            "Ccomputers Computers\n",
            "benifit benefit\n",
            "pensil pencil\n",
            "emproved improved\n",
            "magaziene magazine\n",
            "Importan Important\n",
            "sumtimes sometimes\n",
            "wouldent wouldn\n",
            "websights weights\n",
            "uptodate update\n",
            "If Of\n",
            "presedent president\n",
            "couldent couldn\n",
            "vidio video\n",
            "everyware everywhere\n",
            "Emale Male\n",
            "coworkers workers\n",
            "easier. easier\n",
            "seems. seems\n",
            "somthing something\n",
            "amaricans americans\n",
            "exersize exercise\n",
            "n't not\n",
            "exersise exercise\n",
            "arthrities arthritis\n",
            "amke make\n",
            "bacj back\n",
            "cordanation coronation\n",
            "cordanation coronation\n",
            "whats what\n",
            "n't not\n",
            "Coumputers Computers\n",
            "n't not\n",
            "soemone someone\n",
            "cordniation coronation\n",
            "opertunities opportunities\n",
            "and… and\n",
            "n't not\n",
            "excersize excessive\n",
            "fasinate fascinate\n",
            "excersising exercising\n",
            "woudl would\n",
            "sugested suggested\n",
            "If Of\n",
            "n't not\n",
            "anouther another\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "I.ming coming\n",
            "Thats Hats\n",
            "detatched detached\n",
            "'re are\n",
            "If Of\n",
            "'re are\n",
            "'re are\n",
            "convenvent convenient\n",
            "half-way halfway\n",
            "skped sped\n",
            "acctually actually\n",
            "'re are\n",
            "geoagrahy geography\n",
            "voilence violence\n",
            "voilence violence\n",
            "voilence violence\n",
            "concenred concerned\n",
            "voilence violence\n",
            "now-a-days nowadays\n",
            "unnatral unnatural\n",
            "n't not\n",
            "n't not\n",
            "myspace space\n",
            "thats that\n",
            "n't not\n",
            "butey bute\n",
            "n't not\n",
            "n't not\n",
            "soemone someone\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "If Of\n",
            "heppening happening\n",
            "exsistence existence\n",
            "spreding spreading\n",
            "n't not\n",
            "ichat chat\n",
            "n't not\n",
            "n't not\n",
            "istead instead\n",
            "atleast least\n",
            "If Of\n",
            "nuscense suspense\n",
            "n't not\n",
            "n't not\n",
            "Thats Hats\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "texting testing\n",
            "resuraunt restraint\n",
            "n't not\n",
            "n't not\n",
            "computr computer\n",
            "Whilesome Wholesome\n",
            "finiding finding\n",
            "consequencial consequential\n",
            "injoy enjoy\n",
            "vidio video\n",
            "pepole people\n",
            "semplr semple\n",
            "depnding depending\n",
            "secons second\n",
            "deforents deferens\n",
            "informashon information\n",
            "pepol people\n",
            "everiday everyday\n",
            "monrting morning\n",
            "mayself myself\n",
            "pepole people\n",
            "abyous about\n",
            "pepol people\n",
            "importen imported\n",
            "effact effect\n",
            "haus has\n",
            "onlin online\n",
            "weth with\n",
            "frend friend\n",
            "complateley completely\n",
            "newsepaper newspaper\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "shouldnt shouldn\n",
            "dailey daily\n",
            "litsen listen\n",
            "cordination combination\n",
            "cordinations combinations\n",
            "dailey daily\n",
            "havea have\n",
            "shouldnt shouldn\n",
            "elsa else\n",
            "contrey contre\n",
            "Seart Heart\n",
            "exercis exercise\n",
            "youtube couture\n",
            "lison lion\n",
            "musick music\n",
            "thats that\n",
            "If Of\n",
            "must'nt mustn\n",
            "n't not\n",
            "hygene helene\n",
            "hand-eye handley\n",
            "Theese Cheese\n",
            "visiion vision\n",
            "excercize exercise\n",
            "hand-eye handley\n",
            "exercizing exercising\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "bacause because\n",
            "spenfing spending\n",
            "exercis exercise\n",
            "If Of\n",
            "should't should\n",
            "comuter computer\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "waould would\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "assigment assignment\n",
            "wuth with\n",
            "whats what\n",
            "wwe we\n",
            "thnigs things\n",
            "bissy missy\n",
            "n't not\n",
            "advertisment advertisement\n",
            "realiable reliable\n",
            "shoud should\n",
            "attatched attached\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "interasting interesting\n",
            "If Of\n",
            "If Of\n",
            "belive believe\n",
            "If Of\n",
            "If Of\n",
            "'me me\n",
            "kthat that\n",
            "'everything everything\n",
            "If Of\n",
            "imformation information\n",
            "truning turning\n",
            "exerising exercising\n",
            "freish fresh\n",
            "beofre before\n",
            "n't not\n",
            "youre your\n",
            "computres computers\n",
            "myspace space\n",
            "haapy happy\n",
            "reasch reach\n",
            "nooding nodding\n",
            "exericis exercise\n",
            "cordination combination\n",
            "cordination combination\n",
            "vaction action\n",
            "n't not\n",
            "If Of\n",
            "vaction action\n",
            "benifit benefit\n",
            "n't not\n",
            "ah-hah ahahah\n",
            "devastaded devastated\n",
            "ohter other\n",
            "futur future\n",
            "solitare solitary\n",
            "peole people\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "benifit benefit\n",
            "Somethings Something\n",
            "meebo meet\n",
            "n't not\n",
            "purchesed purchased\n",
            "pently gently\n",
            "benifit benefit\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "obise obese\n",
            "If Of\n",
            "Commmunities Communities\n",
            "commputer computer\n",
            "unneccessary unnecessary\n",
            "inf in\n",
            "talknig talking\n",
            "n't not\n",
            "devorce divorce\n",
            "excercising exercising\n",
            "n't not\n",
            "If Of\n",
            "'re are\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "buit but\n",
            "soceiety society\n",
            "troble trouble\n",
            "thease these\n",
            "n't not\n",
            "culters cutters\n",
            "n't not\n",
            "n't not\n",
            "obeast beast\n",
            "unhealth unhealthy\n",
            "whatch watch\n",
            "atleast least\n",
            "n't not\n",
            "whatch watch\n",
            "n't not\n",
            "whatch watch\n",
            "n't not\n",
            "n't not\n",
            "familiy family\n",
            "If Of\n",
            "ethier ether\n",
            "aol all\n",
            "myspace space\n",
            "n't not\n",
            "thats that\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "freind friend\n",
            "freind friend\n",
            "bestfriend befriend\n",
            "thats that\n",
            "thats that\n",
            "waisting waiting\n",
            "n't not\n",
            "compter computer\n",
            "excersising exercising\n",
            "n't not\n",
            "excersising exercising\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "atleast least\n",
            "buttox button\n",
            "youtube couture\n",
            "excercise exercise\n",
            "n't not\n",
            "preditors creditors\n",
            "If Of\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "useage usage\n",
            "isee see\n",
            "infront front\n",
            "opinon opinion\n",
            "n't not\n",
            "If Of\n",
            "myspace space\n",
            "internent internet\n",
            "internent internet\n",
            "myspace space\n",
            "carryied carried\n",
            "shoud should\n",
            "internent internet\n",
            "earlyier earlier\n",
            "earlyier earlier\n",
            "internent internet\n",
            "elimate climate\n",
            "internent internet\n",
            "internent internet\n",
            "earlyier earlier\n",
            "quility quality\n",
            "interraction interaction\n",
            "additon addition\n",
            "hatefull hateful\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "excersice excessive\n",
            "grown-ups grownup\n",
            "acumulate accumulate\n",
            "excersice excessive\n",
            "asures assures\n",
            "n't not\n",
            "themsleves themselves\n",
            "excersice excessive\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "Thats Hats\n",
            "If Of\n",
            "imense immense\n",
            "'re are\n",
            "convinent continent\n",
            "asigns signs\n",
            "n't not\n",
            "convinent continent\n",
            "convinent continent\n",
            "convinent continent\n",
            "n't not\n",
            "n't not\n",
            "enteratinment entertainment\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "succesful successful\n",
            "conlude conclude\n",
            "evoloution evolution\n",
            "hand-eye handley\n",
            "ordinarilly ordinarily\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "'addicted addicted\n",
            "Insteed Instead\n",
            "myspace space\n",
            "youtube couture\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "cutt cut\n",
            "myspace space\n",
            "n't not\n",
            "interseted interested\n",
            "strints strings\n",
            "cordination combination\n",
            "n't not\n",
            "newpapers newspapers\n",
            "n't not\n",
            "cordination combination\n",
            "n't not\n",
            "exsample example\n",
            "thats that\n",
            "exsample example\n",
            "sosme some\n",
            "n't not\n",
            "exsample example\n",
            "lette letter\n",
            "hand-eye handley\n",
            "eveything everything\n",
            "Thats Hats\n",
            "positve positive\n",
            "n't not\n",
            "n't not\n",
            "atleast least\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "whats what\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "freinds friends\n",
            "comercials commercial\n",
            "wernt went\n",
            "theese these\n",
            "whats what\n",
            "scientest scientist\n",
            "thats that\n",
            "memorr memory\n",
            "relfexes reflexes\n",
            "complexing completing\n",
            "n't not\n",
            "raflexes reflexes\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "hand-eye handley\n",
            "Now-a iowa\n",
            "-days days\n",
            "If Of\n",
            "encouregement encouragement\n",
            "thw the\n",
            "obiese obese\n",
            "If Of\n",
            "cna can\n",
            "n't not\n",
            "If Of\n",
            "bettre better\n",
            "heloing helping\n",
            "tecnology technology\n",
            "simpiler simpler\n",
            "If Of\n",
            "simpling dimpling\n",
            "knowlage knowledge\n",
            "hand-eye handley\n",
            "knowlage knowledge\n",
            "allready already\n",
            "hand-eye handley\n",
            "knowlage knowledge\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "hows how\n",
            "If Of\n",
            "hand-eye handley\n",
            "posotive positive\n",
            "hand-eye handley\n",
            "usefull useful\n",
            "hand-eye handley\n",
            "vocab vocal\n",
            "hand-eye handley\n",
            "n't not\n",
            "accesible accessible\n",
            "n't not\n",
            "exersise exercise\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "necissary necessary\n",
            "accross across\n",
            "accross across\n",
            "accross across\n",
            "buisness business\n",
            "n't not\n",
            "n't not\n",
            "privlages privileges\n",
            "thats that\n",
            "lof of\n",
            "hand-eye handley\n",
            "If Of\n",
            "comptuer computer\n",
            "n't not\n",
            "If Of\n",
            "helpul helpful\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "myspace space\n",
            "naother another\n",
            "If Of\n",
            "helpul helpful\n",
            "samething something\n",
            "clastering clattering\n",
            "smaler smaller\n",
            "n't not\n",
            "definetly definitely\n",
            "n't not\n",
            "If Of\n",
            "isnt isn\n",
            "n't not\n",
            "youtube couture\n",
            "waterski waters\n",
            "lthink think\n",
            "If Of\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "benifit benefit\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "horriable horrible\n",
            "moneged moneyed\n",
            "termendous tremendous\n",
            "hand-eye handley\n",
            "termendous tremendous\n",
            "wpould would\n",
            "n't not\n",
            "thats that\n",
            "n't not\n",
            "n't not\n",
            "gracous gracious\n",
            "hand-eye handley\n",
            "exausted exhausted\n",
            "n't not\n",
            "exercizing exercising\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "exercize exercise\n",
            "thier their\n",
            "insteads instead\n",
            "If Of\n",
            "hand-eye handley\n",
            "communicte communicate\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thinkgs things\n",
            "n't not\n",
            "comuputers computers\n",
            "n't not\n",
            "soemone someone\n",
            "privalige privilege\n",
            "othe the\n",
            "expiriment experiment\n",
            "acurate accurate\n",
            "therew there\n",
            "positivly positively\n",
            "positivley positively\n",
            "If Of\n",
            "symtom symptom\n",
            "If Of\n",
            "asignments assignment\n",
            "inhance enhance\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "excrise excise\n",
            "depating departing\n",
            "thrie three\n",
            "childern children\n",
            "thatn that\n",
            "n't not\n",
            "childern children\n",
            "thier their\n",
            "sosial social\n",
            "recuar recur\n",
            "If Of\n",
            "n't not\n",
            "childern children\n",
            "ablt able\n",
            "compter computer\n",
            "comuncation communication\n",
            "apointment appointment\n",
            "societey society\n",
            "sociatey society\n",
            "If Of\n",
            "'re are\n",
            "beautful beautiful\n",
            "n't not\n",
            "itto into\n",
            "publushers publishers\n",
            "sociatey society\n",
            "socitey society\n",
            "communicat communicate\n",
            "sociatey society\n",
            "excercising exercising\n",
            "lettng letting\n",
            "micht might\n",
            "nonsens nonsense\n",
            "excercise exercise\n",
            "ahppen happen\n",
            "excercise exercise\n",
            "If Of\n",
            "usefull useful\n",
            "certian certain\n",
            "usefull useful\n",
            "lopez lope\n",
            "n't not\n",
            "helpfull helpful\n",
            "myspace space\n",
            "n't not\n",
            "addrees address\n",
            "usefull useful\n",
            "boest best\n",
            "n't not\n",
            "internat internal\n",
            "benifits benefits\n",
            "ebay bay\n",
            "Thats Hats\n",
            "thab that\n",
            "accorucy accuracy\n",
            "hand-eye handley\n",
            "coorination combination\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "thats that\n",
            "Thats Hats\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "compouters computers\n",
            "excersising exercising\n",
            "'re are\n",
            "n't not\n",
            "scenary scenery\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "copmuters computers\n",
            "'re are\n",
            "n't not\n",
            "beatiful beautiful\n",
            "'re are\n",
            "'re are\n",
            "Thats Hats\n",
            "unactive inactive\n",
            "myspace space\n",
            "havent haven\n",
            "hows how\n",
            "fashoned fashioned\n",
            "Thats Hats\n",
            "myspace space\n",
            "acroos across\n",
            "conslusion conclusion\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "aquiring acquiring\n",
            "terribele terrible\n",
            "n't not\n",
            "belive believe\n",
            "exersizing exercising\n",
            "If Of\n",
            "didnt didn\n",
            "languege language\n",
            "isnt isn\n",
            "youre your\n",
            "excersize excessive\n",
            "thats that\n",
            "verry very\n",
            "especialy especially\n",
            "'re are\n",
            "excersize excessive\n",
            "If Of\n",
            "belive believe\n",
            "n't not\n",
            "warcraft warrant\n",
            "'re are\n",
            "n't not\n",
            "hand-eye handley\n",
            "teamate teamster\n",
            "n't not\n",
            "hand-eye handley\n",
            "wouldnt wouldn\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "furter further\n",
            "splittling splitting\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "comuter computer\n",
            "n't not\n",
            "emeil email\n",
            "websit west\n",
            "websit west\n",
            "enythiny anything\n",
            "inportent important\n",
            "websit west\n",
            "n't not\n",
            "benifit benefit\n",
            "rember member\n",
            "werent weren\n",
            "diffrent different\n",
            "mainiy mainly\n",
            "benifit benefit\n",
            "ahmazing amazing\n",
            "becaus because\n",
            "relize realize\n",
            "thats that\n",
            "somtim sometime\n",
            "ofs of\n",
            "benifit benefit\n",
            "socity society\n",
            "definatly defiantly\n",
            "benifit benefit\n",
            "socity society\n",
            "comunications communications\n",
            "redily readily\n",
            "avalible available\n",
            "nessesary necessary\n",
            "souly soul\n",
            "commputer computer\n",
            "relible reliable\n",
            "relible reliable\n",
            "benifit benefit\n",
            "socity society\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "evrywhere everywhere\n",
            "n't not\n",
            "evrything everything\n",
            "If Of\n",
            "paragrahs paragraphs\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "myspace space\n",
            "n't not\n",
            "'re are\n",
            "adicted addicted\n",
            "n't not\n",
            "thier their\n",
            "'re are\n",
            "'re are\n",
            "abandonned abandoned\n",
            "alchohol alcohol\n",
            "youre your\n",
            "youre your\n",
            "webking webbing\n",
            "heathy healthy\n",
            "restaraunts restraints\n",
            "playstation plantation\n",
            "libary library\n",
            "bounddries boundaries\n",
            "i'ts its\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "cordination combination\n",
            "n't not\n",
            "nearily nearly\n",
            "writting writing\n",
            "inlike unlike\n",
            "I-chat chat\n",
            "If Of\n",
            "practic practice\n",
            "importan important\n",
            "belive believe\n",
            "knowlege knowledge\n",
            "knowlege knowledge\n",
            "knowlege knowledge\n",
            "availible available\n",
            "knowlege knowledge\n",
            "exencise exercise\n",
            "knowlege knowledge\n",
            "desasters disasters\n",
            "If Of\n",
            "was't wast\n",
            "knowlege knowledge\n",
            "knowlege knowledge\n",
            "knowlege knowledge\n",
            "aldults adults\n",
            "especialy especially\n",
            "penale penal\n",
            "disaprove disapprove\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "somthing something\n",
            "were'nt weren\n",
            "hand-eye handley\n",
            "stairring stirring\n",
            "durectly directly\n",
            "n't not\n",
            "studees studies\n",
            "withoout without\n",
            "libary library\n",
            "thats that\n",
            "logon login\n",
            "libary library\n",
            "Thats Hats\n",
            "fundimg funding\n",
            "imparing impairing\n",
            "reconect recollect\n",
            "unwadged unwanted\n",
            "n't not\n",
            "eartquake earthquake\n",
            "accross across\n",
            "n't not\n",
            "deffinition definition\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "passtime pastime\n",
            "acually actually\n",
            "teachees teachers\n",
            "hand-eye handley\n",
            "passtimes pastime\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "do'nt dont\n",
            "thje the\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "Futhermore Furthermore\n",
            "If Of\n",
            "cerrect correct\n",
            "If Of\n",
            "n't not\n",
            "hand-eye handley\n",
            "Tecenology Technology\n",
            "benifits benefits\n",
            "iportant important\n",
            "swiching swishing\n",
            "econimy economy\n",
            "cordination combination\n",
            "athe the\n",
            "freinds friends\n",
            "myspace space\n",
            "exacte exact\n",
            "goto got\n",
            "educatinola educational\n",
            "possitive positive\n",
            "possitive positive\n",
            "Thiss Hiss\n",
            "n't not\n",
            "dagerous dangerous\n",
            "excersising exercising\n",
            "Excercising Exercising\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "'re are\n",
            "somthing something\n",
            "'re are\n",
            "If Of\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "cluter cluster\n",
            "'re are\n",
            "bestfriend befriend\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "Compaines Companies\n",
            "n't not\n",
            "n't not\n",
            "curent current\n",
            "coment moment\n",
            "thats that\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "myspace space\n",
            "n't not\n",
            "n't not\n",
            "activites activities\n",
            "goto got\n",
            "n't not\n",
            "sititng sitting\n",
            "excercising exercising\n",
            "wih with\n",
            "excersising exercising\n",
            "n't not\n",
            "leaguges leagues\n",
            "n't not\n",
            "greastest greatest\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "exerise exercise\n",
            "If Of\n",
            "If Of\n",
            "doesnt doesn\n",
            "anywere anywhere\n",
            "actully actually\n",
            "didnt didn\n",
            "simpole simple\n",
            "affectde affected\n",
            "convienet convient\n",
            "reasearch research\n",
            "adverage average\n",
            "reasearch research\n",
            "If Of\n",
            "benifit benefit\n",
            "reasearch research\n",
            "insted instead\n",
            "extreamly extremely\n",
            "insted instead\n",
            "happpier happier\n",
            "aganist against\n",
            "aganist against\n",
            "thats that\n",
            "myspace space\n",
            "myspace space\n",
            "myspace space\n",
            "hookbag workbag\n",
            "myspace space\n",
            "myspace space\n",
            "bieng being\n",
            "thats that\n",
            "myspace space\n",
            "acident accident\n",
            "n't not\n",
            "scammed slammed\n",
            "'re are\n",
            "'doing doing\n",
            "n't not\n",
            "n't not\n",
            "upgrage upgrade\n",
            "Itunes Tunes\n",
            "youtube couture\n",
            "thats that\n",
            "If Of\n",
            "n't not\n",
            "exersis exercise\n",
            "comsuming consuming\n",
            "withour without\n",
            "lesieure leisure\n",
            "ifl if\n",
            "n't not\n",
            "imposible impossible\n",
            "keepng keeping\n",
            "buisness business\n",
            "n't not\n",
            "benifit benefit\n",
            "benifits benefits\n",
            "benifit benefit\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "benifit benefit\n",
            "n't not\n",
            "freinds friends\n",
            "atleast least\n",
            "inportant important\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "obsity ossify\n",
            "n't not\n",
            "abesity ability\n",
            "intresting interesting\n",
            "schedul schedule\n",
            "myspace space\n",
            "aol all\n",
            "cand and\n",
            "peolple people\n",
            "sucessful successful\n",
            "avalible available\n",
            "conected connected\n",
            "wi-fi wife\n",
            "'re are\n",
            "n't not\n",
            "If Of\n",
            "modernly modern\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "innapropriate inappropriate\n",
            "rif if\n",
            "well- well\n",
            "n't not\n",
            "If Of\n",
            "beuatiful beautiful\n",
            "diffrent different\n",
            "planin plain\n",
            "strugle struggle\n",
            "If Of\n",
            "n't not\n",
            "vactions actions\n",
            "tikets tickets\n",
            "wateing watering\n",
            "incible incise\n",
            "enternet internet\n",
            "belive believe\n",
            "cholersterol cholestrol\n",
            "diabities diabetes\n",
            "ejoyable enjoyable\n",
            "jogg ogg\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "homwork homework\n",
            "n't not\n",
            "could't couldst\n",
            "omputers computers\n",
            "n't not\n",
            "diferent different\n",
            "acidents accidents\n",
            "sedual sexual\n",
            "presantation presentation\n",
            "n't not\n",
            "acidents accidents\n",
            "practily practice\n",
            "piolot pilot\n",
            "completly completely\n",
            "completly completely\n",
            "asist assist\n",
            "insision incision\n",
            "acurate accurate\n",
            "sergons sermons\n",
            "completly completely\n",
            "sterial sternal\n",
            "benifit benefit\n",
            "acidents accidents\n",
            "garenteed guaranteed\n",
            "n't not\n",
            "outsid outside\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "wiil will\n",
            "excplain explain\n",
            "diffrent different\n",
            "n't not\n",
            "helsp help\n",
            "compter computer\n",
            "n't not\n",
            "oponion opinion\n",
            "alternitives alternatives\n",
            "Thats Hats\n",
            "n't not\n",
            "If Of\n",
            "likley likely\n",
            "haedaches headache\n",
            "excersize excessive\n",
            "exercize exercise\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "youre your\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "terriable terrible\n",
            "opinon opinion\n",
            "everyon everyone\n",
            "n't not\n",
            "comunicate communicate\n",
            "fron from\n",
            "knowlage knowledge\n",
            "diffrerent different\n",
            "anytime daytime\n",
            "If Of\n",
            "If Of\n",
            "If Of\n",
            "diffrent different\n",
            "thse the\n",
            "comunicate communicate\n",
            "completly completely\n",
            "convienient convenient\n",
            "firsty first\n",
            "conveinient convenient\n",
            "conveinient convenient\n",
            "If Of\n",
            "apreciate appreciate\n",
            "n't not\n",
            "conveinent convenient\n",
            "n't not\n",
            "wana want\n",
            "n't not\n",
            "If Of\n",
            "myspace space\n",
            "diffrent different\n",
            "opionion opinion\n",
            "typr type\n",
            "cordination combination\n",
            "extreene extreme\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "extreemly extremely\n",
            "optinions opinions\n",
            "expenencing experiencing\n",
            "abrubt abrupt\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "cordination combination\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "taht that\n",
            "n't not\n",
            "n't not\n",
            "vurtual virtual\n",
            "probally probably\n",
            "thats that\n",
            "dargerous dangerous\n",
            "n't not\n",
            "n't not\n",
            "unappropriate inappropriate\n",
            "'re are\n",
            "would'nt wouldn\n",
            "n't not\n",
            "n't not\n",
            "re-search research\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "thse the\n",
            "edvance advance\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "acknoowledge acknowledge\n",
            "n't not\n",
            "n't not\n",
            "anytime daytime\n",
            "definetly definitely\n",
            "bada bad\n",
            "bada bad\n",
            "'re are\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "conact contact\n",
            "myspace space\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "anytime daytime\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "extremly extremely\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "'re are\n",
            "pobably probably\n",
            "n't not\n",
            "n't not\n",
            "gois goes\n",
            "completly completely\n",
            "dropeed dropped\n",
            "belive believe\n",
            "wanied wanted\n",
            "n't not\n",
            "thier their\n",
            "exhaused exhausted\n",
            "shuld should\n",
            "shuld should\n",
            "secon second\n",
            "n't not\n",
            "wana want\n",
            "n't not\n",
            "n't not\n",
            "belive believe\n",
            "wana want\n",
            "abot about\n",
            "exercite exercise\n",
            "thats that\n",
            "exercite exercise\n",
            "portant portent\n",
            "exspert expert\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "goverment government\n",
            "exersicing exercising\n",
            "comouter computer\n",
            "If Of\n",
            "predetors creditors\n",
            "tougeled tousled\n",
            "saftey safety\n",
            "inappopriate inappropriate\n",
            "youtube couture\n",
            "n't not\n",
            "myspace space\n",
            "kiddnappings kidnapping\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "ansuer answer\n",
            "ath at\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "myspace space\n",
            "assasinated assassinated\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "Lila Sila\n",
            "withour without\n",
            "isnt isn\n",
            "If Of\n",
            "benifit benefit\n",
            "n't not\n",
            "lknow know\n",
            "n't not\n",
            "n't not\n",
            "adicted addicted\n",
            "sericuse serious\n",
            "lazyness laziness\n",
            "intrest interest\n",
            "n't not\n",
            "globaly global\n",
            "imensely immensely\n",
            "werent weren\n",
            "everyones everyone\n",
            "entertanment entertainment\n",
            "n't not\n",
            "n't not\n",
            "benifit benefit\n",
            "If Of\n",
            "If Of\n",
            "negitive negative\n",
            "conclution conclusion\n",
            "possitive positive\n",
            "'re are\n",
            "If Of\n",
            "'re are\n",
            "freinds friends\n",
            "hand-eye handley\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "thats that\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "espicially especially\n",
            "oppurtunity opportunity\n",
            "immeadiatly immediately\n",
            "belive believe\n",
            "foreigh foreign\n",
            "eghty eighty\n",
            "If Of\n",
            "wil will\n",
            "If Of\n",
            "If Of\n",
            "myspace space\n",
            "exercize exercise\n",
            "If Of\n",
            "seperating separating\n",
            "horrable horrible\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "comunicate communicate\n",
            "hand-eye handley\n",
            "myspace space\n",
            "quichest quickest\n",
            "muchn much\n",
            "hand-eye handley\n",
            "n't not\n",
            "normaly normal\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "convinent continent\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "definatly defiantly\n",
            "vertual virtual\n",
            "comunication communication\n",
            "n't not\n",
            "extremly extremely\n",
            "enviroment environment\n",
            "'re are\n",
            "alternitive alternative\n",
            "n't not\n",
            "alternitive alternative\n",
            "'re are\n",
            "alternitive alternative\n",
            "proffesor professor\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "freind friend\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "greately greatly\n",
            "n't not\n",
            "Thas Has\n",
            "n't not\n",
            "excaise excise\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "enjoiying enjoying\n",
            "yoo you\n",
            "computurs computers\n",
            "succesful successful\n",
            "Anthor Author\n",
            "excersize excessive\n",
            "obessed obsessed\n",
            "mcdoanld macdonald\n",
            "n't not\n",
            "n't not\n",
            "usally usually\n",
            "goign going\n",
            "Conclesively Conclusively\n",
            "puxh push\n",
            "obessed obsessed\n",
            "myspace space\n",
            "somewhre somewhere\n",
            "myspace space\n",
            "n't not\n",
            "n't not\n",
            "agian again\n",
            "enviorment environment\n",
            "enternet internet\n",
            "enternet internet\n",
            "enternet internet\n",
            "alson also\n",
            "enternet internet\n",
            "n't not\n",
            "enternet internet\n",
            "n't not\n",
            "enternet internet\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "enternet internet\n",
            "agian again\n",
            "anthing anything\n",
            "enternet internet\n",
            "soceity society\n",
            "n't not\n",
            "'re are\n",
            "atleast least\n",
            "atleast least\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "innappropriate inappropriate\n",
            "atracious atrocious\n",
            "If Of\n",
            "excercising exercising\n",
            "constanly constantly\n",
            "'re are\n",
            "excersize excessive\n",
            "definitley definitely\n",
            "beautifuly beautiful\n",
            "excersize excessive\n",
            "cuntups cutup\n",
            "disapper disappear\n",
            "techology technology\n",
            "neccesity necessity\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "advenced advanced\n",
            "simplier simpler\n",
            "inso into\n",
            "'re are\n",
            "oppurtunity opportunity\n",
            "edattor editor\n",
            "computors computers\n",
            "Exersise Exercise\n",
            "frends friends\n",
            "thats that\n",
            "littile little\n",
            "exersise exercise\n",
            "thats that\n",
            "thats that\n",
            "exellent excellent\n",
            "cordnation coronation\n",
            "comunicate communicate\n",
            "cordination combination\n",
            "cordination combination\n",
            "cordination combination\n",
            "n't not\n",
            "benifit benefit\n",
            "cordnation coronation\n",
            "concideration consideration\n",
            "posotive positive\n",
            "posotive positive\n",
            "n't not\n",
            "freind friend\n",
            "thats that\n",
            "somthing something\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "Vidios Idiot\n",
            "If Of\n",
            "benifit benefit\n",
            "n't not\n",
            "If Of\n",
            "couldnt couldn\n",
            "benifit benefit\n",
            "newthings nestlings\n",
            "couldnt couldn\n",
            "benifit benefit\n",
            "soctity society\n",
            "posotive positive\n",
            "posotive positive\n",
            "n't not\n",
            "posotive positive\n",
            "buisness business\n",
            "n't not\n",
            "peole people\n",
            "n't not\n",
            "myspace space\n",
            "n't not\n",
            "hand-eye handley\n",
            "abour about\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "samee same\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "advencing advancing\n",
            "wtih with\n",
            "loaction location\n",
            "n't not\n",
            "taht that\n",
            "hand-eye handley\n",
            "famimely family\n",
            "Frist Wrist\n",
            "'re are\n",
            "shildren children\n",
            "evryday everyday\n",
            "n't not\n",
            "comput compute\n",
            "n't not\n",
            "stundent student\n",
            "teh the\n",
            "aroun around\n",
            "'re are\n",
            "youre your\n",
            "allways always\n",
            "comput compute\n",
            "friemds friends\n",
            "othe the\n",
            "'re are\n",
            "you\\re your\n",
            "n't not\n",
            "massy mass\n",
            "commicity community\n",
            "servic service\n",
            "hand-eye handley\n",
            "If Of\n",
            "n't not\n",
            "hand-eye handley\n",
            "n't not\n",
            "If Of\n",
            "negitive negative\n",
            "'re are\n",
            "exerciceing exercising\n",
            "possably possibly\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "If Of\n",
            "If Of\n",
            "somthing something\n",
            "werent weren\n",
            "isnt isn\n",
            "cootraptions contractions\n",
            "beleive believe\n",
            "n't not\n",
            "n't not\n",
            "anytime daytime\n",
            "depleeting deflecting\n",
            "If Of\n",
            "asign sign\n",
            "somethings something\n",
            "mroe more\n",
            "reasearch research\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "othe the\n",
            "poeple people\n",
            "importent important\n",
            "possitive positive\n",
            "thereself herself\n",
            "melestor elector\n",
            "possitive positive\n",
            "drasticly drastic\n",
            "n't not\n",
            "n't not\n",
            "probley problem\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "actuvate activate\n",
            "restarunts restraints\n",
            "workinh working\n",
            "agin again\n",
            "n't not\n",
            "enought enough\n",
            "thek the\n",
            "communy commune\n",
            "pplaeces places\n",
            "educatiional educational\n",
            "entetainment entertainment\n",
            "infront front\n",
            "infront front\n",
            "devistation devastation\n",
            "diffrent different\n",
            "knolege knowledge\n",
            "hand-eye handley\n",
            "cordanation coronation\n",
            "myspace space\n",
            "myspace space\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "whats what\n",
            "hand-eye handley\n",
            "cordination combination\n",
            "basiclly basically\n",
            "dictionay dictionary\n",
            "belive believe\n",
            "n't not\n",
            "obssesed obsessed\n",
            "iteract interact\n",
            "If Of\n",
            "n't not\n",
            "becuse because\n",
            "n't not\n",
            "agood good\n",
            "n't not\n",
            "cordination combination\n",
            "restraunt restraint\n",
            "cordination combination\n",
            "cordination combination\n",
            "cordination combination\n",
            "thats that\n",
            "desision decision\n",
            "n't not\n",
            "exersize exercise\n",
            "exersize exercise\n",
            "exmaple example\n",
            "exersize exercise\n",
            "postive positive\n",
            "convieniant convenient\n",
            "If Of\n",
            "werent weren\n",
            "n't not\n",
            "lightining lightning\n",
            "n't not\n",
            "If Of\n",
            "helpl help\n",
            "n't not\n",
            "n't not\n",
            "out-side outside\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "myspace space\n",
            "'re are\n",
            "'re are\n",
            "mof of\n",
            "n't not\n",
            "excercising exercising\n",
            "myspace space\n",
            "'re are\n",
            "dinnder dinner\n",
            "n't not\n",
            "glitenes glistened\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "definetly definitely\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "reasearch research\n",
            "n't not\n",
            "n't not\n",
            "myspace space\n",
            "ohvoo ohio\n",
            "n't not\n",
            "distanceis distances\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "computors computers\n",
            "If Of\n",
            "computor computer\n",
            "wastedon wasted\n",
            "computors computers\n",
            "computors computers\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "exercuse exercise\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "socia social\n",
            "n't not\n",
            "exersising exercising\n",
            "n't not\n",
            "divices devices\n",
            "helpfull helpful\n",
            "comunication communication\n",
            "signts signs\n",
            "childrens children\n",
            "n't not\n",
            "If Of\n",
            "ofour four\n",
            "If Of\n",
            "competer computer\n",
            "texting testing\n",
            "palan plan\n",
            "If Of\n",
            "probuly probably\n",
            "n't not\n",
            "exersize exercise\n",
            "exersizing exercising\n",
            "exersizing exercising\n",
            "exersize exercise\n",
            "If Of\n",
            "inless unless\n",
            "texting testing\n",
            "sertain certain\n",
            "fron from\n",
            "ollways always\n",
            "beileve believe\n",
            "somtimes sometimes\n",
            "socilizing mobilizing\n",
            "saftely safely\n",
            "ahold hold\n",
            "awsome some\n",
            "everone everyone\n",
            "whats what\n",
            "buetiful beautiful\n",
            "somthing something\n",
            "intresting interesting\n",
            "youre your\n",
            "absoltly absolutely\n",
            "comfortble comfortable\n",
            "absoutly absolutely\n",
            "acountant accountant\n",
            "n't not\n",
            "comptuer computer\n",
            "hand-eye handley\n",
            "thier their\n",
            "exerciszes exercises\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "exersize exercise\n",
            "If Of\n",
            "n't not\n",
            "exersize exercise\n",
            "If Of\n",
            "didnt didn\n",
            "exersising exercising\n",
            "n't not\n",
            "myspace space\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "extinced extended\n",
            "comming coming\n",
            "If Of\n",
            "newist newest\n",
            "n't not\n",
            "n't not\n",
            "anthing anything\n",
            "onley only\n",
            "n't not\n",
            "danerous dangerous\n",
            "electrion election\n",
            "pof of\n",
            "fughting fighting\n",
            "tecongly secondly\n",
            "n't not\n",
            "safty safety\n",
            "soomeone someone\n",
            "kiddnapped kidnapped\n",
            "anyting anything\n",
            "n't not\n",
            "n't not\n",
            "Thats Hats\n",
            "wouldnt wouldn\n",
            "If Of\n",
            "If Of\n",
            "wouldnt wouldn\n",
            "alowd aloud\n",
            "n't not\n",
            "n't not\n",
            "Copmputers Computers\n",
            "n't not\n",
            "frustated frustrated\n",
            "n't not\n",
            "If Of\n",
            "realiable reliable\n",
            "n't not\n",
            "n't not\n",
            "posible possible\n",
            "benifits benefits\n",
            "cordination combination\n",
            "cordination combination\n",
            "cordination combination\n",
            "imprtant important\n",
            "intelegence intelligence\n",
            "n't not\n",
            "continous continuous\n",
            "controveries controversies\n",
            "scientis scientist\n",
            "co-owner coroner\n",
            "buisness business\n",
            "succesful successful\n",
            "Frist Wrist\n",
            "myspace space\n",
            "n't not\n",
            "diebeties diabetes\n",
            "comitt comite\n",
            "suicside suicide\n",
            "n't not\n",
            "extremly extremely\n",
            "definetely definitely\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "often. often\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "seperate separate\n",
            "seperate separate\n",
            "high- high\n",
            "sbrics serics\n",
            "desprately desperately\n",
            "specturm spectrum\n",
            "culturaly cultural\n",
            "becomming becoming\n",
            "If Of\n",
            "capibility capability\n",
            "Thats Hats\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "thats that\n",
            "thats that\n",
            "thrid third\n",
            "comuters computers\n",
            "n't not\n",
            "etheir their\n",
            "n't not\n",
            "If Of\n",
            "compuers computers\n",
            "n't not\n",
            "htem them\n",
            "n't not\n",
            "'re are\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "atleast least\n",
            "n't not\n",
            "n't not\n",
            "websit west\n",
            "youtube couture\n",
            "vactions actions\n",
            "welmart welfare\n",
            "htem them\n",
            "n't not\n",
            "whne when\n",
            "Ther Her\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "croaden broaden\n",
            "'re are\n",
            "n't not\n",
            "harrassed harassed\n",
            "inapropriate inappropriate\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "everday everyday\n",
            "spendiong spending\n",
            "comptuer computer\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "intouch touch\n",
            "resaerch research\n",
            "matchmakeing matchmaking\n",
            "n't not\n",
            "reaserch research\n",
            "previusly previously\n",
            "saftey safety\n",
            "intinse intense\n",
            "saftey safety\n",
            "belive believe\n",
            "souce source\n",
            "drasticly drastic\n",
            "stomache stomach\n",
            "coffe coffee\n",
            "n't not\n",
            "Youtube Couture\n",
            "n't not\n",
            "youtube couture\n",
            "soarces sources\n",
            "definetly definitely\n",
            "definetly definitely\n",
            "benifit benefit\n",
            "definetly definitely\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "reson reason\n",
            "projet project\n",
            "n't not\n",
            "n't not\n",
            "everday everyday\n",
            "biult built\n",
            "swith with\n",
            "yoou you\n",
            "comuters computers\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "labtop labor\n",
            "everday everyday\n",
            "everday everyday\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "posative positive\n",
            "'re are\n",
            "posative positive\n",
            "'re are\n",
            "homless homeless\n",
            "does'ent descent\n",
            "hopps hopes\n",
            "n't not\n",
            "negleck neglect\n",
            "credting creating\n",
            "belifs beliefs\n",
            "modre more\n",
            "over- over\n",
            "ssays says\n",
            "concideration consideration\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "hand-eye handley\n",
            "necesity necessity\n",
            "'re are\n",
            "myspace space\n",
            "n't not\n",
            "necesity necessity\n",
            "radther rather\n",
            "patato potato\n",
            "'re are\n",
            "befor before\n",
            "n't not\n",
            "troble trouble\n",
            "n't not\n",
            "n't not\n",
            "If Of\n",
            "damiges damages\n",
            "n't not\n",
            "soemtimes sometimes\n",
            "diferent different\n",
            "chunck chuck\n",
            "n't not\n",
            "becaose because\n",
            "n't not\n",
            "If Of\n",
            "'re are\n",
            "n't not\n",
            "postive positive\n",
            "acidemic academic\n",
            "enernet internet\n",
            "fam'us famous\n",
            "benfit benefit\n",
            "socity society\n",
            "becuse because\n",
            "acidimic academic\n",
            "benfit benefit\n",
            "famuse amuse\n",
            "rember member\n",
            "becuse because\n",
            "If Of\n",
            "diffrent different\n",
            "proffser profuse\n",
            "becuse because\n",
            "teenangers teenager\n",
            "honsest honest\n",
            "scrach scratch\n",
            "'re are\n",
            "'re are\n",
            "thier their\n",
            "generaal general\n",
            "excersize excessive\n",
            "benefitial beneficial\n",
            "benefitial beneficial\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "If Of\n",
            "'re are\n",
            "anytime daytime\n",
            "ichat chat\n",
            "instantely instantly\n",
            "n't not\n",
            "exersise exercise\n",
            "'re are\n",
            "n't not\n",
            "n't not\n",
            "headachs headache\n",
            "myspace space\n",
            "youtube couture\n",
            "n't not\n",
            "neccessary necessary\n",
            "If Of\n",
            "n't not\n",
            "releived received\n",
            "helpfull helpful\n",
            "If Of\n",
            "entertianment entertainment\n",
            "helpfull helpful\n",
            "If Of\n",
            "detialed detailed\n",
            "discriptions descriptions\n",
            "destianation destination\n",
            "If Of\n",
            "execpt except\n",
            "languege language\n",
            "n't not\n",
            "n't not\n",
            "corodination coronation\n",
            "enteritaining entertaining\n",
            "youtube couture\n",
            "helpfull helpful\n",
            "entertianing entertaining\n",
            "ayou you\n",
            "n't not\n",
            "n't not\n",
            "frustated frustrated\n",
            "thats that\n",
            "echnology technology\n",
            "communcation communication\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "dissagree disagree\n",
            "indentification identification\n",
            "screeen screen\n",
            "innapropriate inappropriate\n",
            "Overell Overall\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "reccomend recommend\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "n't not\n",
            "snowhall snowballs\n",
            "'re are\n",
            "n't not\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "'re are\n",
            "n't not\n",
            "Mydad Dad\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "exersice exercise\n",
            "n't not\n",
            "quater quarter\n",
            "obiese obese\n",
            "exersise exercise\n",
            "n't not\n",
            "exersise exercise\n",
            "n't not\n",
            "htink think\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "everyway everyday\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "lieve live\n",
            "obise obese\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "obeast beast\n",
            "n't not\n",
            "sooo soon\n",
            "peole people\n",
            "n't not\n",
            "bopard board\n",
            "n't not\n",
            "intead instead\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "negitive negative\n",
            "n't not\n",
            "espicially especially\n",
            "parrents parents\n",
            "comunication communication\n",
            "texbooks ebooks\n",
            "busnesses burgesses\n",
            "busnesses burgesses\n",
            "busnes bushes\n",
            "espically especially\n",
            "busness business\n",
            "busnesses burgesses\n",
            "comppare compare\n",
            "cobinet cabinet\n",
            "buseness business\n",
            "busnesses burgesses\n",
            "emall small\n",
            "impertant important\n",
            "wnet went\n",
            "cleen clean\n",
            "cleener cleaner\n",
            "If Of\n",
            "didnt didn\n",
            "coputers computers\n",
            "afect affect\n",
            "n't not\n",
            "If Of\n",
            "If Of\n",
            "mannor manner\n",
            "would'nt wouldn\n",
            "thats that\n",
            "rember member\n",
            "eitner either\n",
            "stairys stairs\n",
            "didnt didn\n",
            "caliores calibres\n",
            "dibietes diabetes\n",
            "rember member\n",
            "sofeware software\n",
            "compueters computers\n",
            "n't not\n",
            "innapropriate inappropriate\n",
            "If Of\n",
            "innapropriate inappropriate\n",
            "n't not\n",
            "n't not\n",
            "sicko sick\n",
            "innapropriate inappropriate\n",
            "untill until\n",
            "thats that\n",
            "probally probably\n",
            "n't not\n",
            "n't not\n",
            "innapropriate inappropriate\n",
            "belive believe\n",
            "benifit benefit\n",
            "comunicat communicate\n",
            "n't not\n",
            "n't not\n",
            "tikets tickets\n",
            "n't not\n",
            "If Of\n",
            "contry country\n",
            "peresident president\n",
            "interent interest\n",
            "arctech arctic\n",
            "ofice office\n",
            "goverment government\n",
            "secet secret\n",
            "becose become\n",
            "n't not\n",
            "myspace space\n",
            "divertion diversion\n",
            "excersice excessive\n",
            "n't not\n",
            "exersize exercise\n",
            "n't not\n",
            "excersice excessive\n",
            "bobies bodies\n",
            "diease disease\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "lpaper paper\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "muchtime lunchtime\n",
            "obeast beast\n",
            "now-a-days nowadays\n",
            "myspace space\n",
            "newpaper newspaper\n",
            "n't not\n",
            "concideration consideration\n",
            "kiods kinds\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "acually actually\n",
            "'re are\n",
            "exercing exerting\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "n't not\n",
            "'re are\n",
            "n't not\n",
            "If Of\n",
            "n't not\n",
            "'re are\n",
            "probebly probably\n",
            "n't not\n",
            "n't not\n",
            "acually actually\n",
            "n't not\n",
            "exercing exerting\n",
            "n't not\n",
            "throughh through\n",
            "n't not\n",
            "hand-eye handley\n",
            "up-dated updated\n",
            "hand-eye handley\n",
            "apend spend\n",
            "hand-eye handley\n",
            "presision precision\n",
            "n't not\n",
            "n't not\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-29d70f55e7ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Essay_NoSpellingMistakes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Essay'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRemove_White_Spaces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Essay_NoSpellingMistakes'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mData_Essay_01\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Essay_NoSpellingMistakes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCorrect_Spelling\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4355\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfloat64\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4356\u001b[0m         \"\"\"\n\u001b[0;32m-> 4357\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSeriesApply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4358\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4359\u001b[0m     def _reduce(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1099\u001b[0m                     \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                     \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# type: ignore[arg-type]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m                     \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m                 )\n\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-d2f202d79d7a>\u001b[0m in \u001b[0;36mCorrect_Spelling\u001b[0;34m(Sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mword\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspellcheck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;31m# result [0][0] contains the bool value if the spelling is correct or not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/blob.py\u001b[0m in \u001b[0;36mspellcheck\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mversionadded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;36m.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         '''\n\u001b[0;32m--> 119\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcorrect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/en/__init__.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(w)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \"\"\" Returns a list of (word, confidence)-tuples of spelling corrections.\n\u001b[1;32m    122\u001b[0m     \"\"\"\n\u001b[0;32m--> 123\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mspelling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36msuggest\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1396\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1397\u001b[0m                   \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1398\u001b[0;31m                   \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1399\u001b[0m                   \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1400\u001b[0m         \u001b[0mcandidates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcandidates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m_edit2\u001b[0;34m(self, w)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;31m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# Only keep candidates that are actually known words (20% speedup).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1373\u001b[0m         \u001b[0;31m# Of all spelling errors, 99% is covered by edit distance 2.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1374\u001b[0m         \u001b[0;31m# Only keep candidates that are actually known words (20% speedup).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1375\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_edit1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0me2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1377\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m__contains__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__iter__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__contains__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__contains__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lazy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"__getitem__\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/textblob/_text.py\u001b[0m in \u001b[0;36m_lazy\u001b[0;34m(self, method, *args)\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMethodType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDITKFui_Slb",
        "outputId": "f9d4f056-122b-41fe-eb65-41bcf790c465"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear @ CAPS1 @ CAPS2 , I believe that using computers will benefit us in many ways like talking and becoming friends will others through websites like facebook and mysace . Using computers can help us find coordinate , locations , and able ourselfs to millions of information . Also computers will benefit us by helping with jobs as in planning a house plan and typing a @ NUM1 page report for one of our jobs in less than writing it . Now lets go into the wonder world of technology . Using a computer will help us in life by talking or making friends on line . Many people have space , facebooks , aim , these all benefit us by having conversations with one another . Many people believe computers are bad but how can you make friends if you can never talk to them ? I am very fortunate for having a computer that can help with not only school work but my social life and how I make friends . Computers help us with finding our locations , coordinate and millions of information online . Of we did not go on the internet a lot we would not know how to go onto websites that @ MONTH1 help us with locations and coordinates like @ LOCATION1 . Would you rather use a computer or be in @ LOCATION3 . When your supposed to be vacationing in @ LOCATION2 . Million of information is found on the internet . You can as almost every question and a computer will have it . Would you rather easily draw up a house plan on the computers or take @ NUM1 hours doing one by hand with ugly erazer marks all over it , you are garrenteed that to find a job with a drawing like that . Also when applying for a job many workers must write very long papers like a @ NUM3 word essay on why this job fits you the most , and many people I know do not like writing @ NUM3 words non-stopp for hours when it could take them I hav an a computer . That is why computers we needed a lot now adays . I hope this essay has impacted your descion on computers because they are great machines to work with . The other day I showed my mom how to use a computer and she said it was the greatest invention sense sliced bread ! Now go out and buy a computer to help you chat online with friends , find locations and millions of information on one click of the button and help your self with getting a job with neat , prepared , printed work that your boss will love .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking Punctuation Mistakes"
      ],
      "metadata": {
        "id": "N2BerbAju6gw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = pun(text)"
      ],
      "metadata": {
        "id": "fyXxGcm_TY7I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_string = ''\n",
        "\n",
        "for n in output:\n",
        "  result = n['word'].replace('▁' , ' ') + n['entity'].replace('0', '')\n",
        "  new_string += result\n",
        "\n",
        "new_string"
      ],
      "metadata": {
        "id": "xPtYWtMyVRux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Capitalization Mistakes"
      ],
      "metadata": {
        "id": "3mZ9RfrmQwpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "cWZDfpuUZ97N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tag import pos_tag\n",
        "def Check_Captialization(Essay):\n",
        "  \"\"\"\n",
        "    Checks capitalization in each sentence of an essay\n",
        "\n",
        "    Args:\n",
        "    Essay: Words (Tokens) of each essay \n",
        "\n",
        "    Returns: \n",
        "    int\n",
        "\n",
        "  \"\"\"\n",
        "  count = 0\n",
        "\n",
        "  words = word_tokenize(Essay)\n",
        "\n",
        "  # Checking Capital Letters in start of every sentence & start of every quote\n",
        "  for i in range(len(words) - 1):\n",
        "    \n",
        "    if words[i] == '.' or words[i] == '\"':\n",
        "        match = words[i+1]\n",
        "        if match != words[i+1].title():\n",
        "          count = count + 1\n",
        "\n",
        "  # Checking if all proper nouns are capital or not\n",
        "  tagged_sent = pos_tag(words)\n",
        "\n",
        "  for word,pos in tagged_sent:\n",
        "    if(pos == 'NNP'):\n",
        "      if word != word.title():\n",
        "        count = count + 1\n",
        "\n",
        "  return count"
      ],
      "metadata": {
        "id": "IP6L-cA7SArH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Check_Captialization(Remove_NER(Data_Essay_01[\"Essay\"][9]))"
      ],
      "metadata": {
        "id": "AOma5U8XSBBn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Remove_NER(Data_Essay_01[\"Essay\"][12])"
      ],
      "metadata": {
        "id": "0K9iZpWFSBTY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking Spelling Mistakes via Language Tool"
      ],
      "metadata": {
        "id": "AVjkY_Qs0Vk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Spelling_Error_Correct(essays):\n",
        "    \n",
        "    matches = tool.check(essays)\n",
        "    is_bad_rule = lambda rule: rule.category == 'GRAMMAR'\n",
        "    matches = [rule for rule in matches if not is_bad_rule(rule)]\n",
        "    # print(matches[0].category)\n",
        "    language_tool_python.utils.correct(essays, matches)   # to correct it\n",
        "    return essays"
      ],
      "metadata": {
        "id": "eT8DQXg00lUo"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01['essayWithoutSpellingMistakes'] = Data_Essay_01['Essay'].apply(Spelling_Error_Correct)"
      ],
      "metadata": {
        "id": "QjVNL9xM5aJ0"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Grammar Error Detection**"
      ],
      "metadata": {
        "id": "kZEkV3-ruDBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from nltk.translate.bleu_score import sentence_bleu\n",
        "# reference = result.text.split()\n",
        "\n",
        "# candidate = 'Dear local newspaper, @CAPS1 best friend, @LOCATION2, was once a nerd with no hand-eye coordination, @CAPS2, he started to use a computer and now he has better hand-eye coordination than me.'.split()\n",
        "# print('BLEU score -> {}'.format(sentence_bleu(reference, candidate )))"
      ],
      "metadata": {
        "id": "dxk_61AvuGQq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = Data_Essay_01[['Essay', 'Sent_Count']]\n",
        "df1.head()"
      ],
      "metadata": {
        "id": "x2Y4N0k4uLKw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "7517769d-95dd-4e3d-eaaf-d7251147104c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               Essay  Sent_Count\n",
              "0  Dear local newspaper, I think effects computer...          16\n",
              "1  Dear @CAPS1 @CAPS2, I believe that using compu...          20\n",
              "2  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...          14\n",
              "3  Dear Local Newspaper, @CAPS1 I have found that...          27\n",
              "4  Dear @LOCATION1, I know having computers has a...          30"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-24a32223-96b4-40d2-b562-490953d9d7ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-24a32223-96b4-40d2-b562-490953d9d7ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-24a32223-96b4-40d2-b562-490953d9d7ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-24a32223-96b4-40d2-b562-490953d9d7ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Grammar Error via CFG\n",
        "\n",
        "# def grammar_error(essays_1,sent_count):\n",
        "#     sentences = nltk.sent_tokenize(essays_1[1])\n",
        "#     for sent in range(0,sent_count):\n",
        "#        wrong =1\n",
        "#        sent_split = sentences[sent].split()  \n",
        "#        tagged = nltk.pos_tag(sent_split) \n",
        "#        tags = [x[1].lower() for x in tagged] \n",
        "\n",
        "#        try:\n",
        "#         parser = nltk.RecursiveDescentParser(grammar)\n",
        "        \n",
        "#         for tree in parser.parse(tags):\n",
        "#             s = tree\n",
        "#             wrong =0\n",
        "#             print(\"Correct Grammar!!!!\")\n",
        "#             print(\"*\"*20)\n",
        "        \n",
        "#         if wrong ==1:\n",
        "#             print(\"Wrong Grammar!!!\")\n",
        "#             print(\"*\"*20)\n",
        "    \n",
        "#        except ValueError:\n",
        "#         print(\"Sorry! Some words are not covered in the grammar yet :)\")\n",
        "\n",
        "    \n",
        "# essays_1 = df1['Essay_Clean'].tolist()\n",
        "# sent_count = df1['Clean_Sent_Count'].tolist()\n",
        "# grammar_error(essays_1,sent_count[1])"
      ],
      "metadata": {
        "id": "XNwkbsDFuOWw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import language_tool_python\n",
        "tool = language_tool_python.LanguageTool('en-US')"
      ],
      "metadata": {
        "id": "6nYGovM1uPu_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b02da5-d672-41c4-a18a-259841af9084"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading LanguageTool 5.7: 100%|██████████| 225M/225M [00:04<00:00, 49.3MB/s]\n",
            "INFO:language_tool_python.download_lt:Unzipping /tmp/tmpi8eljz8g.zip to /root/.cache/language_tool_python.\n",
            "INFO:language_tool_python.download_lt:Downloaded https://www.languagetool.org/download/LanguageTool-5.7.zip to /root/.cache/language_tool_python.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = Data_Essay_01[['Essay', 'Sent_Count']]\n",
        "df1['Essay'] = df1['Essay'].apply(Remove_White_Spaces)   # to avoid whitespace error\n",
        "df1['Essay']"
      ],
      "metadata": {
        "id": "3CrujkhOuQ_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c801414-ac86-404d-ba71-51febdf508c4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       Dear local newspaper, I think effects computer...\n",
              "1       Dear @CAPS1 @CAPS2, I believe that using compu...\n",
              "2       Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...\n",
              "3       Dear Local Newspaper, @CAPS1 I have found that...\n",
              "4       Dear @LOCATION1, I know having computers has a...\n",
              "                              ...                        \n",
              "1778    Dear @CAPS1, @CAPS2 several reasons on way I t...\n",
              "1779    Do a adults and kids spend to much time on the...\n",
              "1780    My opinion is that people should have computer...\n",
              "1781    Dear readers, I think that its good and bad to...\n",
              "1782    Dear - Local Newspaper I agree thats computers...\n",
              "Name: Essay, Length: 1783, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Grammar_Errors(essays):\n",
        "    \n",
        "    matches = tool.check(essays)\n",
        "    is_bad_rule = lambda rule: rule.category == 'GRAMMAR'\n",
        "    matches = [rule for rule in matches if is_bad_rule(rule)]\n",
        "    # print(matches[0].category)\n",
        "    errors = []\n",
        "    #language_tool_python.utils.correct(text, matches)   # to correct it\n",
        "    for i in range(0, len(matches)):\n",
        "      errors.append(matches[i].ruleId)  # or category of the error (Misc, Whitespace, Typography)\n",
        "    return len(matches), errors"
      ],
      "metadata": {
        "id": "2kdFSdAfuSWo"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Grammar_Errors(\"Dear local newspaper, I think effects computers have on people are great learning skills/affects because they give us time to chat with friends/new people, helps us learn about the globe(astronomy) and keeps us out of troble! Thing about! Dont you think so? How would you feel if your teenager is always on the phone with friends! Do you ever time to chat with your friends or buisness partner about things. Well now - there's a new way to chat the computer, theirs plenty of sites on the internet to do so: @ORGANIZATION1, @ORGANIZATION2, @CAPS1, facebook, myspace ect. Just think now while your setting up meeting with your boss on the computer, your teenager is having fun on the phone not rushing to get off cause you want to use it. How did you learn about other countrys/states outside of yours? Well I have by computer/internet, it's a new way to learn about what going on in our time! You might think your child spends a lot of time on the computer, but ask them so question about the economy, sea floor spreading or even about the @DATE1's you'll be surprise at how much he/she knows. Believe it or not the computer is much interesting then in class all day reading out of books. If your child is home on your computer or at a local library, it's better than being out with friends being fresh, or being perpressured to doing something they know isnt right. You might not know where your child is, @CAPS2 forbidde in a hospital bed because of a drive-by. Rather than your child on the computer learning, chatting or just playing games, safe and sound in your home or community place. Now I hope you have reached a point to understand and agree with me, because computers can have great effects on you or child because it gives us time to chat with friends/new people, helps us learn about the globe and believe or not keeps us out of troble. Thank you for listening.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWFfTjKG5817",
        "outputId": "d83b87df-e6b6-49d7-ecae-a68852607cdc"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GRAMMAR\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, ['CAUSE_BECAUSE', 'BE_VBP_IN'])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = Grammar_Errors(Correct_Spelling(Remove_White_Spaces(Data_Essay_01[\"Essay\"][3])))\n",
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22OtIoMDKlV6",
        "outputId": "2d0b12d7-b5f8-4de5-8e78-fa910e2924b4"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "benifit benefit\n",
            "studdies studies\n",
            "reasearch research\n",
            "advertisments advertisements\n",
            "imposible impossible\n",
            "commucated communicated\n",
            "reasearch research\n",
            "reasearch research\n",
            "posible possible\n",
            "amagine imagine\n",
            "n't not\n",
            "buissness business\n",
            "catalouge catalogue\n",
            "castomer customer\n",
            "coustomers customers\n",
            "resturant restaurant\n",
            "convinences convinces\n",
            "reaserch research\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0, [])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data_Essay_01['Grammar_Errors'], Data_Essay_01['Grammar_Error_List'] = zip(*df1_copy['Essay'].map(grammar_errors))\n",
        "Data_Essay_01['Grammar_Errors'], Data_Essay_01['Grammar_Error_List'] = zip(*df1['Essay'].map(Grammar_Errors))"
      ],
      "metadata": {
        "id": "UCNsXW7MuToX"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RiBhtPxlQ2IM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Data_Essay_01.head(20)"
      ],
      "metadata": {
        "id": "qby9k_DduUsX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7323778a-dfa8-437f-abcb-bf828717def2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    ID                                              Essay  Rater_1 Score  \\\n",
              "0    1  Dear local newspaper, I think effects computer...            4.0   \n",
              "1    2  Dear @CAPS1 @CAPS2, I believe that using compu...            5.0   \n",
              "2    3  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...            4.0   \n",
              "3    4  Dear Local Newspaper, @CAPS1 I have found that...            5.0   \n",
              "4    5  Dear @LOCATION1, I know having computers has a...            4.0   \n",
              "5    6  Dear @LOCATION1, I think that computers have a...            4.0   \n",
              "6    7  Did you know that more and more people these d...            5.0   \n",
              "7    8  @PERCENT1 of people agree that computers make ...            5.0   \n",
              "8    9  Dear reader, @ORGANIZATION1 has had a dramatic...            4.0   \n",
              "9   10  In the @LOCATION1 we have the technology of a ...            5.0   \n",
              "10  11  Dear @LOCATION1, @CAPS1 people acknowledge the...            4.0   \n",
              "11  12  Dear @CAPS1 @CAPS2 I feel that computers do ta...            4.0   \n",
              "12  13  Dear local newspaper I raed ur argument on the...            4.0   \n",
              "13  14  My three detaileds for this news paper article...            3.0   \n",
              "14  15  Dear, In this world today we should have every...            3.0   \n",
              "15  16  Dear @ORGANIZATION1, The computer blinked to l...            6.0   \n",
              "16  17  Dear Local Newspaper, I belive that computers ...            4.0   \n",
              "17  18  Dear Local Newspaper, I must admit that the ex...            4.0   \n",
              "18  19  I aegre waf the evansmant ov tnachnolage. The ...            2.0   \n",
              "19  20  Well computers can be a good or a bad thing. I...            3.0   \n",
              "\n",
              "    Rater_2 Score  Total Score  \\\n",
              "0             4.0          8.0   \n",
              "1             4.0          9.0   \n",
              "2             3.0          7.0   \n",
              "3             5.0         10.0   \n",
              "4             4.0          8.0   \n",
              "5             4.0          8.0   \n",
              "6             5.0         10.0   \n",
              "7             5.0         10.0   \n",
              "8             5.0          9.0   \n",
              "9             4.0          9.0   \n",
              "10            4.0          8.0   \n",
              "11            4.0          8.0   \n",
              "12            3.0          7.0   \n",
              "13            3.0          6.0   \n",
              "14            3.0          6.0   \n",
              "15            6.0         12.0   \n",
              "16            4.0          8.0   \n",
              "17            4.0          8.0   \n",
              "18            2.0          4.0   \n",
              "19            3.0          6.0   \n",
              "\n",
              "                                   Preprocessed_Essay  Sent_Count  Word_Count  \\\n",
              "0   Dear local newspaper  I think effects computer...          16         386   \n",
              "1   Dear I believe that using computers will benef...          20         464   \n",
              "2   Dear  More and more people use computers  but ...          14         313   \n",
              "3   Dear Local Newspaper  I have found that many e...          27         611   \n",
              "4   Dear I know having computers has a positive ef...          30         517   \n",
              "5   Dear I think that computers have a negative af...          15         274   \n",
              "6   Did you know that more and more people these d...          30         580   \n",
              "7   of people agree that computers make life less ...          39         556   \n",
              "8   Dear reader  has had a dramatic effect on huma...          35         512   \n",
              "9   In the we have the technology of a computer  S...          26         561   \n",
              "10  Dear people acknowledge the great advances tha...          22         373   \n",
              "11  Dear I feel that computers do take away from p...          25         435   \n",
              "12  Dear local newspaper I raed ur argument on the...           6         211   \n",
              "13  My three detaileds for this news paper article...          25         332   \n",
              "14  Dear  In this world today we should have every...          13         197   \n",
              "15  Dear The computer blinked to life and an image...          35         605   \n",
              "16  Dear Local Newspaper  I belive that computers ...          18         385   \n",
              "17  Dear Local Newspaper  I must admit that the ex...          15         420   \n",
              "18  I aegre waf the evansmant ov tnachnolage  The ...           7          72   \n",
              "19  Well computers can be a good or a bad thing  I...          11         181   \n",
              "\n",
              "    Char_Count  Avg_Word_Count  Verb_Count  Noun_Count  Adj_Count  Conj_Count  \\\n",
              "0         1875        3.984456          55          74         18          14   \n",
              "1         2288        4.030172          71          97         19          18   \n",
              "2         1541        4.035144          42          69         17          16   \n",
              "3         3165        4.328969          71         126         39          17   \n",
              "4         2569        4.071567          61         107         30          15   \n",
              "5         1276        3.762774          42          37          9           9   \n",
              "6         2808        3.982759          69         115         23          16   \n",
              "7         2724        4.037770          88         120         35          20   \n",
              "8         2402        3.833984          70          95         31          22   \n",
              "9         2632        3.798574          77          93         37          26   \n",
              "10        1963        4.394102          48          73         29           9   \n",
              "11        2182        4.117241          58          88         31          13   \n",
              "12        1007        3.810427          32          40         13          12   \n",
              "13        1618        3.948795          40          86         27          17   \n",
              "14         991        4.142132          27          46         13           8   \n",
              "15        3168        4.368595          90         139         38          20   \n",
              "16        1804        3.818182          55          64         15          14   \n",
              "17        1959        3.795238          65          60         20          24   \n",
              "18         362        4.125000           8           9          6           1   \n",
              "19         868        3.939227          23          43         12           8   \n",
              "\n",
              "    Adverb_Count  pNoun_Count  Grammar_Errors  \\\n",
              "0             15           48               2   \n",
              "1             19           49               4   \n",
              "2             11           25               5   \n",
              "3             21           33               0   \n",
              "4             34           41               1   \n",
              "5             18           41               3   \n",
              "6             34           73               1   \n",
              "7             26           59               0   \n",
              "8             30           56               4   \n",
              "9             31           67               4   \n",
              "10            18           33               0   \n",
              "11            30           33               4   \n",
              "12             6           33               2   \n",
              "13            11           35              15   \n",
              "14            11           18               2   \n",
              "15            16           41               0   \n",
              "16            15           61               4   \n",
              "17            33           58               2   \n",
              "18             0            4               0   \n",
              "19             5           15               2   \n",
              "\n",
              "                                   Grammar_Error_List  \n",
              "0                          [CAUSE_BECAUSE, BE_VBP_IN]  \n",
              "1          [ON_COMPOUNDS, NODT_DOZEN, YOU_HAV, DT_DT]  \n",
              "2   [THE_SUPERLATIVE, PHRASE_REPETITION, ITS_TO_IT...  \n",
              "3                                                  []  \n",
              "4                                             [ARN_T]  \n",
              "5       [BEEN_PART_AGREEMENT, PRP_PAST_PART, PRP_THE]  \n",
              "6                                 [PROGRESSIVE_VERBS]  \n",
              "7                                                  []  \n",
              "8   [DOSNT, SINGULAR_VERB_AFTER_THESE_OR_THOSE, SI...  \n",
              "9   [CYBER_COMPOUNDS, TOO_ADJECTIVE_TO, PRONOUN_NO...  \n",
              "10                                                 []  \n",
              "11         [AS_ADJ_AS, ARN_T, ARN_T, THE_SUPERLATIVE]  \n",
              "12                  [MD_BE_NON_VBP, WRITER_COMPOUNDS]  \n",
              "13  [NEWS_COMPOUNDS, THIS_NNS, PLURAL_VERB_AFTER_T...  \n",
              "14                     [WORLDS_BEST, THE_SUPERLATIVE]  \n",
              "15                                                 []  \n",
              "16  [BELIVE_BELIEVE, BELIVE_BELIEVE, BELIVE_BELIEV...  \n",
              "17                  [CAUSE_BECAUSE, MOST_COMPARATIVE]  \n",
              "18                                                 []  \n",
              "19                   [AGREEMENT_SENT_START, BUNCH_OF]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc08fb34-2771-49a6-a039-a0040ca36040\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>Essay</th>\n",
              "      <th>Rater_1 Score</th>\n",
              "      <th>Rater_2 Score</th>\n",
              "      <th>Total Score</th>\n",
              "      <th>Preprocessed_Essay</th>\n",
              "      <th>Sent_Count</th>\n",
              "      <th>Word_Count</th>\n",
              "      <th>Char_Count</th>\n",
              "      <th>Avg_Word_Count</th>\n",
              "      <th>Verb_Count</th>\n",
              "      <th>Noun_Count</th>\n",
              "      <th>Adj_Count</th>\n",
              "      <th>Conj_Count</th>\n",
              "      <th>Adverb_Count</th>\n",
              "      <th>pNoun_Count</th>\n",
              "      <th>Grammar_Errors</th>\n",
              "      <th>Grammar_Error_List</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>Dear local newspaper, I think effects computer...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear local newspaper  I think effects computer...</td>\n",
              "      <td>16</td>\n",
              "      <td>386</td>\n",
              "      <td>1875</td>\n",
              "      <td>3.984456</td>\n",
              "      <td>55</td>\n",
              "      <td>74</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>48</td>\n",
              "      <td>2</td>\n",
              "      <td>[CAUSE_BECAUSE, BE_VBP_IN]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear I believe that using computers will benef...</td>\n",
              "      <td>20</td>\n",
              "      <td>464</td>\n",
              "      <td>2288</td>\n",
              "      <td>4.030172</td>\n",
              "      <td>71</td>\n",
              "      <td>97</td>\n",
              "      <td>19</td>\n",
              "      <td>18</td>\n",
              "      <td>19</td>\n",
              "      <td>49</td>\n",
              "      <td>4</td>\n",
              "      <td>[ON_COMPOUNDS, NODT_DOZEN, YOU_HAV, DT_DT]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear  More and more people use computers  but ...</td>\n",
              "      <td>14</td>\n",
              "      <td>313</td>\n",
              "      <td>1541</td>\n",
              "      <td>4.035144</td>\n",
              "      <td>42</td>\n",
              "      <td>69</td>\n",
              "      <td>17</td>\n",
              "      <td>16</td>\n",
              "      <td>11</td>\n",
              "      <td>25</td>\n",
              "      <td>5</td>\n",
              "      <td>[THE_SUPERLATIVE, PHRASE_REPETITION, ITS_TO_IT...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Dear Local Newspaper  I have found that many e...</td>\n",
              "      <td>27</td>\n",
              "      <td>611</td>\n",
              "      <td>3165</td>\n",
              "      <td>4.328969</td>\n",
              "      <td>71</td>\n",
              "      <td>126</td>\n",
              "      <td>39</td>\n",
              "      <td>17</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear I know having computers has a positive ef...</td>\n",
              "      <td>30</td>\n",
              "      <td>517</td>\n",
              "      <td>2569</td>\n",
              "      <td>4.071567</td>\n",
              "      <td>61</td>\n",
              "      <td>107</td>\n",
              "      <td>30</td>\n",
              "      <td>15</td>\n",
              "      <td>34</td>\n",
              "      <td>41</td>\n",
              "      <td>1</td>\n",
              "      <td>[ARN_T]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>6</td>\n",
              "      <td>Dear @LOCATION1, I think that computers have a...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear I think that computers have a negative af...</td>\n",
              "      <td>15</td>\n",
              "      <td>274</td>\n",
              "      <td>1276</td>\n",
              "      <td>3.762774</td>\n",
              "      <td>42</td>\n",
              "      <td>37</td>\n",
              "      <td>9</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>41</td>\n",
              "      <td>3</td>\n",
              "      <td>[BEEN_PART_AGREEMENT, PRP_PAST_PART, PRP_THE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7</td>\n",
              "      <td>Did you know that more and more people these d...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Did you know that more and more people these d...</td>\n",
              "      <td>30</td>\n",
              "      <td>580</td>\n",
              "      <td>2808</td>\n",
              "      <td>3.982759</td>\n",
              "      <td>69</td>\n",
              "      <td>115</td>\n",
              "      <td>23</td>\n",
              "      <td>16</td>\n",
              "      <td>34</td>\n",
              "      <td>73</td>\n",
              "      <td>1</td>\n",
              "      <td>[PROGRESSIVE_VERBS]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>8</td>\n",
              "      <td>@PERCENT1 of people agree that computers make ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>of people agree that computers make life less ...</td>\n",
              "      <td>39</td>\n",
              "      <td>556</td>\n",
              "      <td>2724</td>\n",
              "      <td>4.037770</td>\n",
              "      <td>88</td>\n",
              "      <td>120</td>\n",
              "      <td>35</td>\n",
              "      <td>20</td>\n",
              "      <td>26</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>9</td>\n",
              "      <td>Dear reader, @ORGANIZATION1 has had a dramatic...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Dear reader  has had a dramatic effect on huma...</td>\n",
              "      <td>35</td>\n",
              "      <td>512</td>\n",
              "      <td>2402</td>\n",
              "      <td>3.833984</td>\n",
              "      <td>70</td>\n",
              "      <td>95</td>\n",
              "      <td>31</td>\n",
              "      <td>22</td>\n",
              "      <td>30</td>\n",
              "      <td>56</td>\n",
              "      <td>4</td>\n",
              "      <td>[DOSNT, SINGULAR_VERB_AFTER_THESE_OR_THOSE, SI...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>10</td>\n",
              "      <td>In the @LOCATION1 we have the technology of a ...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>In the we have the technology of a computer  S...</td>\n",
              "      <td>26</td>\n",
              "      <td>561</td>\n",
              "      <td>2632</td>\n",
              "      <td>3.798574</td>\n",
              "      <td>77</td>\n",
              "      <td>93</td>\n",
              "      <td>37</td>\n",
              "      <td>26</td>\n",
              "      <td>31</td>\n",
              "      <td>67</td>\n",
              "      <td>4</td>\n",
              "      <td>[CYBER_COMPOUNDS, TOO_ADJECTIVE_TO, PRONOUN_NO...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>11</td>\n",
              "      <td>Dear @LOCATION1, @CAPS1 people acknowledge the...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear people acknowledge the great advances tha...</td>\n",
              "      <td>22</td>\n",
              "      <td>373</td>\n",
              "      <td>1963</td>\n",
              "      <td>4.394102</td>\n",
              "      <td>48</td>\n",
              "      <td>73</td>\n",
              "      <td>29</td>\n",
              "      <td>9</td>\n",
              "      <td>18</td>\n",
              "      <td>33</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>12</td>\n",
              "      <td>Dear @CAPS1 @CAPS2 I feel that computers do ta...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear I feel that computers do take away from p...</td>\n",
              "      <td>25</td>\n",
              "      <td>435</td>\n",
              "      <td>2182</td>\n",
              "      <td>4.117241</td>\n",
              "      <td>58</td>\n",
              "      <td>88</td>\n",
              "      <td>31</td>\n",
              "      <td>13</td>\n",
              "      <td>30</td>\n",
              "      <td>33</td>\n",
              "      <td>4</td>\n",
              "      <td>[AS_ADJ_AS, ARN_T, ARN_T, THE_SUPERLATIVE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>13</td>\n",
              "      <td>Dear local newspaper I raed ur argument on the...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Dear local newspaper I raed ur argument on the...</td>\n",
              "      <td>6</td>\n",
              "      <td>211</td>\n",
              "      <td>1007</td>\n",
              "      <td>3.810427</td>\n",
              "      <td>32</td>\n",
              "      <td>40</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>33</td>\n",
              "      <td>2</td>\n",
              "      <td>[MD_BE_NON_VBP, WRITER_COMPOUNDS]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>14</td>\n",
              "      <td>My three detaileds for this news paper article...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>My three detaileds for this news paper article...</td>\n",
              "      <td>25</td>\n",
              "      <td>332</td>\n",
              "      <td>1618</td>\n",
              "      <td>3.948795</td>\n",
              "      <td>40</td>\n",
              "      <td>86</td>\n",
              "      <td>27</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>35</td>\n",
              "      <td>15</td>\n",
              "      <td>[NEWS_COMPOUNDS, THIS_NNS, PLURAL_VERB_AFTER_T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>15</td>\n",
              "      <td>Dear, In this world today we should have every...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Dear  In this world today we should have every...</td>\n",
              "      <td>13</td>\n",
              "      <td>197</td>\n",
              "      <td>991</td>\n",
              "      <td>4.142132</td>\n",
              "      <td>27</td>\n",
              "      <td>46</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>11</td>\n",
              "      <td>18</td>\n",
              "      <td>2</td>\n",
              "      <td>[WORLDS_BEST, THE_SUPERLATIVE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>16</td>\n",
              "      <td>Dear @ORGANIZATION1, The computer blinked to l...</td>\n",
              "      <td>6.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Dear The computer blinked to life and an image...</td>\n",
              "      <td>35</td>\n",
              "      <td>605</td>\n",
              "      <td>3168</td>\n",
              "      <td>4.368595</td>\n",
              "      <td>90</td>\n",
              "      <td>139</td>\n",
              "      <td>38</td>\n",
              "      <td>20</td>\n",
              "      <td>16</td>\n",
              "      <td>41</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>17</td>\n",
              "      <td>Dear Local Newspaper, I belive that computers ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear Local Newspaper  I belive that computers ...</td>\n",
              "      <td>18</td>\n",
              "      <td>385</td>\n",
              "      <td>1804</td>\n",
              "      <td>3.818182</td>\n",
              "      <td>55</td>\n",
              "      <td>64</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>15</td>\n",
              "      <td>61</td>\n",
              "      <td>4</td>\n",
              "      <td>[BELIVE_BELIEVE, BELIVE_BELIEVE, BELIVE_BELIEV...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>18</td>\n",
              "      <td>Dear Local Newspaper, I must admit that the ex...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>Dear Local Newspaper  I must admit that the ex...</td>\n",
              "      <td>15</td>\n",
              "      <td>420</td>\n",
              "      <td>1959</td>\n",
              "      <td>3.795238</td>\n",
              "      <td>65</td>\n",
              "      <td>60</td>\n",
              "      <td>20</td>\n",
              "      <td>24</td>\n",
              "      <td>33</td>\n",
              "      <td>58</td>\n",
              "      <td>2</td>\n",
              "      <td>[CAUSE_BECAUSE, MOST_COMPARATIVE]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>19</td>\n",
              "      <td>I aegre waf the evansmant ov tnachnolage. The ...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>I aegre waf the evansmant ov tnachnolage  The ...</td>\n",
              "      <td>7</td>\n",
              "      <td>72</td>\n",
              "      <td>362</td>\n",
              "      <td>4.125000</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>20</td>\n",
              "      <td>Well computers can be a good or a bad thing. I...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>Well computers can be a good or a bad thing  I...</td>\n",
              "      <td>11</td>\n",
              "      <td>181</td>\n",
              "      <td>868</td>\n",
              "      <td>3.939227</td>\n",
              "      <td>23</td>\n",
              "      <td>43</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>15</td>\n",
              "      <td>2</td>\n",
              "      <td>[AGREEMENT_SENT_START, BUNCH_OF]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc08fb34-2771-49a6-a039-a0040ca36040')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc08fb34-2771-49a6-a039-a0040ca36040 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc08fb34-2771-49a6-a039-a0040ca36040');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out = Data_Essay_01['Grammar_Error_List'].explode().value_counts()\n",
        "out"
      ],
      "metadata": {
        "id": "4KttcpfcuV6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fdfd7f2e-e2ef-4e73-a6be-805ce8e67745"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HE_VERB_AGR             228\n",
              "A_NNS                   139\n",
              "ITS_TO_IT_S              96\n",
              "MD_BASEFORM              91\n",
              "BEEN_PART_AGREEMENT      86\n",
              "                       ... \n",
              "SIMPLE_TO_USE_HYPHEN      1\n",
              "GOOD_GOOF                 1\n",
              "DO_YOU_FASCINATED         1\n",
              "DOES_YOU                  1\n",
              "SHUTDOWN                  1\n",
              "Name: Grammar_Error_List, Length: 324, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.to_csv('GrammarErrors.csv')"
      ],
      "metadata": {
        "id": "Mj7LNN5JuW2X"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Lexical Sophistication**"
      ],
      "metadata": {
        "id": "ttyjcisFxNHZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PT5e5b5axQSg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vVX_WRUzxQNg"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LL9lGScHxQFh"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Content**"
      ],
      "metadata": {
        "id": "iNcrlo78xaLJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Latent Semantic Analysis (LSA)**\n",
        "\n",
        "Content analysis generally implies only a high-level semantic analysis and comparison with source text and graded essays"
      ],
      "metadata": {
        "id": "0Mv-IDjowJET"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1gs2o1P6xesp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Semantic**\n",
        "Semantic metrics assess the correctness of content connotation"
      ],
      "metadata": {
        "id": "MSiuF2JzyBWX"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cExW4ZuiyWyx"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Semantic Coherence & Consistency**"
      ],
      "metadata": {
        "id": "jQ--G0SrwJqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "r2-_rC8mwdfQ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Connectivity**"
      ],
      "metadata": {
        "id": "nEFmhVcBwKAq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CYamIfnRwuqD"
      },
      "execution_count": 25,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "pmuQWvabiYC-",
        "iUMnW4Qm4Vws",
        "I6sEA-fCCfmN",
        "2NgCS1PQZaIJ",
        "qEPOKuVJRz1-",
        "3mZ9RfrmQwpQ"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}